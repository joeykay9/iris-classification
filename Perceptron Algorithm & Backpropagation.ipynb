{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random as random\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('iris.data', encoding='utf-8', \n",
    "                 names=['sepal length', 'sepal width', 'petal length', 'petal width', 'variety'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scatter Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "setosa = df[df['variety']=='Iris-setosa']\n",
    "versicolor = df[df['variety']=='Iris-versicolor']\n",
    "virginica = df[df['variety']=='Iris-virginica']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2c29feac348>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x576 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(nrows=2, ncols=3, figsize=(18,8))\n",
    "fig.subplots_adjust(bottom=-0.2)\n",
    "\n",
    "#Petal length vs Petal width\n",
    "ax[0, 0].set_title(\"Petal length vs Petal width\")\n",
    "setosa.plot.scatter(x='petal width', y='petal length', grid=True, color='red', label='setosa', ax=ax[0, 0])\n",
    "versicolor.plot.scatter(x='petal width', y='petal length', grid=True, color='gold', label='versicolor', ax=ax[0, 0])\n",
    "virginica.plot.scatter(x='petal width', y='petal length', grid=True, color='green', label='virginica', ax=ax[0, 0])\n",
    "\n",
    "#Petal length vs Sepal length\n",
    "ax[0, 1].set_title(\"Petal length vs Sepal length\")\n",
    "setosa.plot.scatter(x='sepal length', y='petal length', grid=True, color='red', label='setosa', ax=ax[0, 1])\n",
    "versicolor.plot.scatter(x='sepal length', y='petal length', grid=True, color='gold', label='versicolor', ax=ax[0,1])\n",
    "virginica.plot.scatter(x='sepal length', y='petal length', grid=True, color='green', label='virginica', ax=ax[0,1])\n",
    "\n",
    "#Petal length vs Sepal width\n",
    "ax[0, 2].set_title(\"Petal length vs Sepal width\")\n",
    "setosa.plot.scatter(x='sepal width', y='petal length', grid=True, color='red', label='setosa', ax=ax[0, 2])\n",
    "versicolor.plot.scatter(x='sepal width', y='petal length', grid=True, color='gold', label='versicolor', ax=ax[0,2])\n",
    "virginica.plot.scatter(x='sepal width', y='petal length', grid=True, color='green', label='virginica', ax=ax[0,2])\n",
    "\n",
    "#Sepal length vs Sepal width\n",
    "ax[1, 0].set_title(\"Sepal length vs Sepal width\")\n",
    "setosa.plot.scatter(x='sepal width', y='sepal length', grid=True, color='red', label='setosa', ax=ax[1, 0])\n",
    "versicolor.plot.scatter(x='sepal width', y='sepal length', grid=True, color='gold', label='versicolor', ax=ax[1, 0])\n",
    "virginica.plot.scatter(x='sepal width', y='sepal length', grid=True, color='green', label='virginica', ax=ax[1, 0])\n",
    "\n",
    "\n",
    "#Sepal length vs Petal width\n",
    "ax[1, 1].set_title(\"Sepal length vs Petal width\")\n",
    "setosa.plot.scatter(x='petal width', y='sepal length', grid=True, color='red', label='setosa', ax=ax[1, 1])\n",
    "versicolor.plot.scatter(x='petal width', y='sepal length', grid=True, color='gold', label='versicolor', ax=ax[1, 1])\n",
    "virginica.plot.scatter(x='petal width', y='sepal length', grid=True, color='green', label='virginica', ax=ax[1, 1])\n",
    "\n",
    "#Sepal width vs Petal width\n",
    "ax[1, 2].set_title(\"Sepal width vs Petal width\")\n",
    "setosa.plot.scatter(x='petal width', y='sepal width', grid=True, color='red', label='setosa', ax=ax[1, 2])\n",
    "versicolor.plot.scatter(x='petal width', y='sepal width', grid=True, color='gold', label='versicolor', ax=ax[1, 2])\n",
    "virginica.plot.scatter(x='petal width', y='sepal width', grid=True, color='green', label='virginica', ax=ax[1, 2])\n",
    "\n",
    "#Plotting decision boundaries\n",
    "# x_sepal_width = np.linspace(np.min(df['sepal width']), np.max(df['sepal width']))\n",
    "# x_petal_width = np.linspace(np.min(df['petal width']), np.max(df['petal width']))\n",
    "# x_sepal_length = np.linspace(np.min(df['sepal length']), np.max(df['sepal length']))\n",
    "# y_sepal_length = np.linspace(np.min(df['sepal length']), np.max(df['sepal length']))\n",
    "\n",
    "# ax[0, 0].plot(x_petal_width, 0*x + 2.5, color='black')\n",
    "# ax[0, 1].plot(x_sepal_length, 0*x + 2.5, color='black')\n",
    "# ax[0, 2].plot(x_sepal_width, 0*x + 2.5, color='black')\n",
    "# ax[1, 0].plot(x_sepal_width, 0.8*x + 2.8, color='black')\n",
    "# ax[1, 1].plot(np.linspace(0, 1), -4*np.linspace(0, 1) + 8, color='black')\n",
    "# ax[1, 2].plot((np.linspace(2.0, 4.5) - 0.5)/3, np.linspace(2.0, 4.5), color='black')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perceptron algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron:\n",
    "    def __init__(self, inputs, outputs, learning_rate, num_epochs):\n",
    "        self.train_inputs = inputs[:100]\n",
    "        self.train_outputs = outputs[:100]\n",
    "        self.test_inputs = inputs[100:]\n",
    "        self.test_outputs = outputs[100:]\n",
    "        self.lr = learning_rate\n",
    "        self.num_epochs = num_epochs\n",
    "        self.weights = np.random.rand(self.train_inputs.shape[-1])\n",
    "        \n",
    "    def predict(self, data):\n",
    "        return int(self.weights.dot(data) > 0)\n",
    "    \n",
    "    def fit(self):\n",
    "        print('Training the perceptron')\n",
    "        print('-----------------------')\n",
    "        for epoch in range(num_epochs):\n",
    "            for i, data in enumerate(self.train_inputs):\n",
    "                #Predict output\n",
    "                y = self.predict(data)\n",
    "\n",
    "                #If the prediction is correct\n",
    "                if (self.train_outputs[i] == y):\n",
    "                    continue\n",
    "\n",
    "\n",
    "                if (self.train_outputs[i] == 1 and y == 0): #If misclassified point should be setosa\n",
    "                    d = 1\n",
    "                elif (self.train_outputs[i] == 0 and y == 1): #If misclassified point should be non-setosa\n",
    "                    d = -1\n",
    "\n",
    "                #Update the weights\n",
    "                self.weights += (d * self.lr * data)\n",
    "\n",
    "                print('Epoch: ', epoch+1, 'Step: ', i+1)\n",
    "                print('Weights: ', self.weights)\n",
    "        print('------------------------------------------')\n",
    "        print('Perceptron training successfully completed\\n')\n",
    "        \n",
    "    def test(self):\n",
    "        correct = 0.0\n",
    "        wrong = 0.0\n",
    "        \n",
    "        for i, data in enumerate(self.test_inputs):\n",
    "            if (self.test_outputs[i] == self.predict(data)):\n",
    "                correct += 1\n",
    "            else:\n",
    "                wrong += 1\n",
    "                \n",
    "        accuracy = correct/len(self.test_inputs) *100\n",
    "        print('\\n\\nTesting the perceptron')\n",
    "        print('-----------------------')\n",
    "        print('Correctly classified: ', int(correct), '\\tIncorrectly classified: ', int(wrong))\n",
    "        print('Accuracy: ', accuracy, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_train_data_for_classification(df, classification_type):\n",
    "    # classification_type:\n",
    "    # 1 - setosa vs non-setosa\n",
    "    # 2 - virginica vs non-virginica\n",
    "    # 3 - versicolor vs non-versicolor\n",
    "    \n",
    "    if(classification_type == 1):\n",
    "        iris = 'Iris-setosa'\n",
    "    elif(classification_type == 2):\n",
    "        iris = 'Iris-virginica'\n",
    "    elif(classification_type == 3):\n",
    "        iris = 'Iris-versicolor'\n",
    "    else:\n",
    "        print('Enter appropriate classification type')\n",
    "        return\n",
    "\n",
    "    df['clamped'] = 1\n",
    "    df['output'] = (df.variety == iris).astype(int)\n",
    "    inputs = df[['sepal length', 'sepal width', 'petal length', 'petal width', 'clamped']].values\n",
    "    outputs = df['output'].values\n",
    "    \n",
    "    return inputs, outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('iris.data', encoding='utf-8', \n",
    "                     names=['sepal length', 'sepal width', 'petal length', 'petal width', 'variety'])\n",
    "df = df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setosa vs Non-setosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the perceptron\n",
      "-----------------------\n",
      "Epoch:  1 Step:  1\n",
      "Weights:  [-5.08439079 -2.27438916 -4.83756041 -1.61154631 -0.69248041]\n",
      "Epoch:  1 Step:  5\n",
      "Weights:  [ 0.61560921  2.12561084 -3.33756041 -1.21154631  0.30751959]\n",
      "------------------------------------------\n",
      "Perceptron training successfully completed\n",
      "\n",
      "\n",
      "\n",
      "Testing the perceptron\n",
      "-----------------------\n",
      "Correctly classified:  50 \tIncorrectly classified:  0\n",
      "Accuracy:  100.0 %\n"
     ]
    }
   ],
   "source": [
    "inputs, outputs = prepare_train_data_for_classification(df, 1)\n",
    "\n",
    "#Set learning rate and number of epochs\n",
    "lr = 1\n",
    "num_epochs = 10\n",
    "\n",
    "set_perceptron = Perceptron(inputs, outputs, lr, num_epochs)\n",
    "\n",
    "#Training the perceptron\n",
    "set_perceptron.fit()\n",
    "\n",
    "#Testing the trained perceptron\n",
    "set_perceptron.test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Virginica vs non-virginica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the perceptron\n",
      "-----------------------\n",
      "Epoch:  1 Step:  5\n",
      "Weights:  [ 0.3931343   0.55221801 -0.12002439  0.43424535  0.52069594]\n",
      "Epoch:  1 Step:  6\n",
      "Weights:  [-0.1868657   0.15221801 -0.24002439  0.41424535  0.42069594]\n",
      "Epoch:  1 Step:  10\n",
      "Weights:  [0.4631343  0.45221801 0.33997561 0.63424535 0.52069594]\n",
      "Epoch:  1 Step:  14\n",
      "Weights:  [-0.1468657   0.16221801 -0.13002439  0.49424535  0.42069594]\n",
      "Epoch:  1 Step:  15\n",
      "Weights:  [-0.6068657  -0.19778199 -0.23002439  0.47424535  0.32069594]\n",
      "Epoch:  1 Step:  16\n",
      "Weights:  [0.0831343  0.12221801 0.33997561 0.70424535 0.42069594]\n",
      "Epoch:  1 Step:  18\n",
      "Weights:  [-0.4868657  -0.25778199  0.16997561  0.67424535  0.32069594]\n",
      "Epoch:  1 Step:  19\n",
      "Weights:  [0.2231343  0.04221801 0.75997561 0.88424535 0.42069594]\n",
      "Epoch:  1 Step:  20\n",
      "Weights:  [-0.2768657  -0.30778199  0.62997561  0.85424535  0.32069594]\n",
      "Epoch:  1 Step:  24\n",
      "Weights:  [-0.9368657  -0.60778199  0.18997561  0.71424535  0.22069594]\n",
      "Epoch:  1 Step:  25\n",
      "Weights:  [-0.1468657  -0.22778199  0.82997561  0.91424535  0.32069594]\n",
      "Epoch:  1 Step:  26\n",
      "Weights:  [-0.6568657  -0.47778199  0.52997561  0.80424535  0.22069594]\n",
      "Epoch:  1 Step:  29\n",
      "Weights:  [-0.0268657  -0.14778199  1.12997561  1.05424535  0.32069594]\n",
      "Epoch:  1 Step:  30\n",
      "Weights:  [-0.5768657  -0.40778199  0.68997561  0.93424535  0.22069594]\n",
      "Epoch:  1 Step:  31\n",
      "Weights:  [-1.0968657  -0.67778199  0.29997561  0.79424535  0.12069594]\n",
      "Epoch:  1 Step:  32\n",
      "Weights:  [-0.4468657  -0.35778199  0.80997561  0.99424535  0.22069594]\n",
      "Epoch:  1 Step:  33\n",
      "Weights:  [-1.0968657  -0.63778199  0.34997561  0.84424535  0.12069594]\n",
      "Epoch:  1 Step:  35\n",
      "Weights:  [-0.3268657  -0.33778199  0.95997561  1.07424535  0.22069594]\n",
      "Epoch:  1 Step:  36\n",
      "Weights:  [-1.0168657  -0.64778199  0.46997561  0.92424535  0.12069594]\n",
      "Epoch:  1 Step:  37\n",
      "Weights:  [-0.3868657  -0.35778199  1.02997561  1.10424535  0.22069594]\n",
      "Epoch:  1 Step:  38\n",
      "Weights:  [-0.9868657  -0.62778199  0.51997561  0.94424535  0.12069594]\n",
      "Epoch:  1 Step:  48\n",
      "Weights:  [-0.2668657  -0.32778199  1.09997561  1.10424535  0.22069594]\n",
      "Epoch:  1 Step:  49\n",
      "Weights:  [-0.9268657  -0.61778199  0.63997561  0.97424535  0.12069594]\n",
      "Epoch:  1 Step:  50\n",
      "Weights:  [-0.2768657  -0.31778199  1.15997561  1.17424535  0.22069594]\n",
      "Epoch:  1 Step:  53\n",
      "Weights:  [-0.8268657  -0.56778199  0.75997561  1.04424535  0.12069594]\n",
      "Epoch:  1 Step:  54\n",
      "Weights:  [-0.1868657  -0.25778199  1.30997561  1.22424535  0.22069594]\n",
      "Epoch:  1 Step:  55\n",
      "Weights:  [-0.6468657  -0.56778199  1.15997561  1.20424535  0.12069594]\n",
      "Epoch:  1 Step:  56\n",
      "Weights:  [-1.2168657  -0.84778199  0.70997561  1.07424535  0.02069594]\n",
      "Epoch:  1 Step:  57\n",
      "Weights:  [-0.6568657  -0.56778199  1.19997561  1.27424535  0.12069594]\n",
      "Epoch:  1 Step:  58\n",
      "Weights:  [-1.1568657  -0.79778199  0.86997561  1.17424535  0.02069594]\n",
      "Epoch:  1 Step:  60\n",
      "Weights:  [-0.5168657  -0.47778199  1.39997561  1.40424535  0.12069594]\n",
      "Epoch:  1 Step:  64\n",
      "Weights:  [-1.1268657  -0.77778199  0.93997561  1.26424535  0.02069594]\n",
      "Epoch:  1 Step:  68\n",
      "Weights:  [-0.3968657  -0.48778199  1.56997561  1.44424535  0.12069594]\n",
      "Epoch:  1 Step:  74\n",
      "Weights:  [-0.9668657  -0.78778199  1.14997561  1.32424535  0.02069594]\n",
      "Epoch:  2 Step:  13\n",
      "Weights:  [-0.2768657  -0.47778199  1.65997561  1.55424535  0.12069594]\n",
      "Epoch:  2 Step:  14\n",
      "Weights:  [-0.8868657  -0.76778199  1.18997561  1.41424535  0.02069594]\n",
      "Epoch:  2 Step:  28\n",
      "Weights:  [-1.5568657  -1.06778199  0.68997561  1.24424535 -0.07930406]\n",
      "Epoch:  2 Step:  29\n",
      "Weights:  [-0.9268657  -0.73778199  1.28997561  1.49424535  0.02069594]\n",
      "Epoch:  2 Step:  30\n",
      "Weights:  [-1.4768657  -0.99778199  0.84997561  1.37424535 -0.07930406]\n",
      "Epoch:  2 Step:  32\n",
      "Weights:  [-0.8268657  -0.67778199  1.35997561  1.57424535  0.02069594]\n",
      "Epoch:  2 Step:  33\n",
      "Weights:  [-1.4768657  -0.95778199  0.89997561  1.42424535 -0.07930406]\n",
      "Epoch:  2 Step:  35\n",
      "Weights:  [-0.7068657  -0.65778199  1.50997561  1.65424535  0.02069594]\n",
      "Epoch:  2 Step:  36\n",
      "Weights:  [-1.3968657  -0.96778199  1.01997561  1.50424535 -0.07930406]\n",
      "Epoch:  2 Step:  37\n",
      "Weights:  [-0.7668657  -0.67778199  1.57997561  1.68424535  0.02069594]\n",
      "Epoch:  2 Step:  38\n",
      "Weights:  [-1.3668657  -0.94778199  1.06997561  1.52424535 -0.07930406]\n",
      "Epoch:  2 Step:  48\n",
      "Weights:  [-0.6468657  -0.64778199  1.64997561  1.68424535  0.02069594]\n",
      "Epoch:  2 Step:  49\n",
      "Weights:  [-1.3068657  -0.93778199  1.18997561  1.55424535 -0.07930406]\n",
      "Epoch:  2 Step:  50\n",
      "Weights:  [-0.6568657  -0.63778199  1.70997561  1.75424535  0.02069594]\n",
      "Epoch:  2 Step:  53\n",
      "Weights:  [-1.2068657  -0.88778199  1.30997561  1.62424535 -0.07930406]\n",
      "Epoch:  2 Step:  54\n",
      "Weights:  [-0.5668657  -0.57778199  1.85997561  1.80424535  0.02069594]\n",
      "Epoch:  2 Step:  56\n",
      "Weights:  [-1.1368657  -0.85778199  1.40997561  1.67424535 -0.07930406]\n",
      "Epoch:  2 Step:  67\n",
      "Weights:  [-1.7668657  -1.10778199  0.91997561  1.52424535 -0.17930406]\n",
      "Epoch:  2 Step:  68\n",
      "Weights:  [-1.0368657  -0.81778199  1.54997561  1.70424535 -0.07930406]\n",
      "Epoch:  2 Step:  74\n",
      "Weights:  [-1.6068657  -1.11778199  1.12997561  1.58424535 -0.17930406]\n",
      "Epoch:  2 Step:  76\n",
      "Weights:  [-1.1168657  -0.86778199  1.57997561  1.75424535 -0.07930406]\n",
      "Epoch:  2 Step:  86\n",
      "Weights:  [-1.6768657  -1.13778199  1.15997561  1.62424535 -0.17930406]\n",
      "Epoch:  2 Step:  88\n",
      "Weights:  [-0.9168657  -0.83778199  1.81997561  1.83424535 -0.07930406]\n",
      "Epoch:  2 Step:  89\n",
      "Weights:  [-1.5168657  -1.05778199  1.41997561  1.73424535 -0.17930406]\n",
      "Epoch:  2 Step:  92\n",
      "Weights:  [-0.9368657  -0.78778199  1.92997561  1.92424535 -0.07930406]\n",
      "Epoch:  2 Step:  97\n",
      "Weights:  [-1.5168657  -1.05778199  1.51997561  1.82424535 -0.17930406]\n",
      "Epoch:  2 Step:  99\n",
      "Weights:  [-0.8468657  -0.74778199  2.07997561  2.06424535 -0.07930406]\n",
      "Epoch:  3 Step:  7\n",
      "Weights:  [-1.4768657  -0.97778199  1.63997561  1.93424535 -0.17930406]\n",
      "Epoch:  3 Step:  13\n",
      "Weights:  [-0.7868657  -0.66778199  2.14997561  2.16424535 -0.07930406]\n",
      "Epoch:  3 Step:  14\n",
      "Weights:  [-1.3968657  -0.95778199  1.67997561  2.02424535 -0.17930406]\n",
      "Epoch:  3 Step:  25\n",
      "Weights:  [-0.6068657  -0.57778199  2.31997561  2.22424535 -0.07930406]\n",
      "Epoch:  3 Step:  26\n",
      "Weights:  [-1.1168657  -0.82778199  2.01997561  2.11424535 -0.17930406]\n",
      "Epoch:  3 Step:  27\n",
      "Weights:  [-1.7868657  -1.13778199  1.54997561  1.96424535 -0.27930406]\n",
      "Epoch:  3 Step:  29\n",
      "Weights:  [-1.1568657  -0.80778199  2.14997561  2.21424535 -0.17930406]\n",
      "Epoch:  3 Step:  30\n",
      "Weights:  [-1.7068657  -1.06778199  1.70997561  2.09424535 -0.27930406]\n",
      "Epoch:  3 Step:  32\n",
      "Weights:  [-1.0568657  -0.74778199  2.21997561  2.29424535 -0.17930406]\n",
      "Epoch:  3 Step:  33\n",
      "Weights:  [-1.7068657  -1.02778199  1.75997561  2.14424535 -0.27930406]\n",
      "Epoch:  3 Step:  35\n",
      "Weights:  [-0.9368657  -0.72778199  2.36997561  2.37424535 -0.17930406]\n",
      "Epoch:  3 Step:  36\n",
      "Weights:  [-1.6268657  -1.03778199  1.87997561  2.22424535 -0.27930406]\n",
      "Epoch:  3 Step:  38\n",
      "Weights:  [-2.2268657  -1.30778199  1.36997561  2.06424535 -0.37930406]\n",
      "Epoch:  3 Step:  48\n",
      "Weights:  [-1.5068657  -1.00778199  1.94997561  2.22424535 -0.27930406]\n",
      "Epoch:  3 Step:  67\n",
      "Weights:  [-2.1368657  -1.25778199  1.45997561  2.07424535 -0.37930406]\n",
      "Epoch:  3 Step:  68\n",
      "Weights:  [-1.4068657  -0.96778199  2.08997561  2.25424535 -0.27930406]\n",
      "Epoch:  3 Step:  74\n",
      "Weights:  [-1.9768657  -1.26778199  1.66997561  2.13424535 -0.37930406]\n",
      "Epoch:  3 Step:  76\n",
      "Weights:  [-1.4868657  -1.01778199  2.11997561  2.30424535 -0.27930406]\n",
      "Epoch:  3 Step:  86\n",
      "Weights:  [-2.0468657  -1.28778199  1.69997561  2.17424535 -0.37930406]\n",
      "Epoch:  3 Step:  88\n",
      "Weights:  [-1.2868657  -0.98778199  2.35997561  2.38424535 -0.27930406]\n",
      "Epoch:  3 Step:  89\n",
      "Weights:  [-1.8868657  -1.20778199  1.95997561  2.28424535 -0.37930406]\n",
      "Epoch:  3 Step:  92\n",
      "Weights:  [-1.3068657  -0.93778199  2.46997561  2.47424535 -0.27930406]\n",
      "Epoch:  3 Step:  97\n",
      "Weights:  [-1.8868657  -1.20778199  2.05997561  2.37424535 -0.37930406]\n",
      "Epoch:  3 Step:  100\n",
      "Weights:  [-1.2068657  -0.90778199  2.60997561  2.58424535 -0.27930406]\n",
      "Epoch:  4 Step:  7\n",
      "Weights:  [-1.8368657  -1.13778199  2.16997561  2.45424535 -0.37930406]\n",
      "Epoch:  4 Step:  25\n",
      "Weights:  [-1.0468657  -0.75778199  2.80997561  2.65424535 -0.27930406]\n",
      "Epoch:  4 Step:  26\n",
      "Weights:  [-1.5568657  -1.00778199  2.50997561  2.54424535 -0.37930406]\n",
      "Epoch:  4 Step:  27\n",
      "Weights:  [-2.2268657  -1.31778199  2.03997561  2.39424535 -0.47930406]\n",
      "Epoch:  4 Step:  29\n",
      "Weights:  [-1.5968657  -0.98778199  2.63997561  2.64424535 -0.37930406]\n",
      "Epoch:  4 Step:  30\n",
      "Weights:  [-2.1468657  -1.24778199  2.19997561  2.52424535 -0.47930406]\n",
      "Epoch:  4 Step:  32\n",
      "Weights:  [-1.4968657  -0.92778199  2.70997561  2.72424535 -0.37930406]\n",
      "Epoch:  4 Step:  33\n",
      "Weights:  [-2.1468657  -1.20778199  2.24997561  2.57424535 -0.47930406]\n",
      "Epoch:  4 Step:  35\n",
      "Weights:  [-1.3768657  -0.90778199  2.85997561  2.80424535 -0.37930406]\n",
      "Epoch:  4 Step:  36\n",
      "Weights:  [-2.0668657  -1.21778199  2.36997561  2.65424535 -0.47930406]\n",
      "Epoch:  4 Step:  38\n",
      "Weights:  [-2.6668657  -1.48778199  1.85997561  2.49424535 -0.57930406]\n",
      "Epoch:  4 Step:  48\n",
      "Weights:  [-1.9468657  -1.18778199  2.43997561  2.65424535 -0.47930406]\n",
      "Epoch:  4 Step:  67\n",
      "Weights:  [-2.5768657  -1.43778199  1.94997561  2.50424535 -0.57930406]\n",
      "Epoch:  4 Step:  68\n",
      "Weights:  [-1.8468657  -1.14778199  2.57997561  2.68424535 -0.47930406]\n",
      "Epoch:  4 Step:  75\n",
      "Weights:  [-2.4368657  -1.44778199  2.15997561  2.53424535 -0.57930406]\n",
      "Epoch:  4 Step:  76\n",
      "Weights:  [-1.9468657  -1.19778199  2.60997561  2.70424535 -0.47930406]\n",
      "Epoch:  5 Step:  14\n",
      "Weights:  [-2.5568657  -1.48778199  2.13997561  2.56424535 -0.57930406]\n",
      "Epoch:  5 Step:  16\n",
      "Weights:  [-1.8668657  -1.16778199  2.70997561  2.79424535 -0.47930406]\n",
      "Epoch:  5 Step:  27\n",
      "Weights:  [-2.5368657  -1.47778199  2.23997561  2.64424535 -0.57930406]\n",
      "Epoch:  5 Step:  29\n",
      "Weights:  [-1.9068657  -1.14778199  2.83997561  2.89424535 -0.47930406]\n",
      "Epoch:  5 Step:  30\n",
      "Weights:  [-2.4568657  -1.40778199  2.39997561  2.77424535 -0.57930406]\n",
      "Epoch:  5 Step:  32\n",
      "Weights:  [-1.8068657  -1.08778199  2.90997561  2.97424535 -0.47930406]\n",
      "Epoch:  5 Step:  33\n",
      "Weights:  [-2.4568657  -1.36778199  2.44997561  2.82424535 -0.57930406]\n",
      "Epoch:  5 Step:  35\n",
      "Weights:  [-1.6868657  -1.06778199  3.05997561  3.05424535 -0.47930406]\n",
      "Epoch:  5 Step:  36\n",
      "Weights:  [-2.3768657  -1.37778199  2.56997561  2.90424535 -0.57930406]\n",
      "Epoch:  5 Step:  48\n",
      "Weights:  [-1.6568657  -1.07778199  3.14997561  3.06424535 -0.47930406]\n",
      "Epoch:  5 Step:  49\n",
      "Weights:  [-2.3168657  -1.36778199  2.68997561  2.93424535 -0.57930406]\n",
      "Epoch:  5 Step:  51\n",
      "Weights:  [-1.7168657  -1.06778199  3.16997561  3.11424535 -0.47930406]\n",
      "Epoch:  5 Step:  53\n",
      "Weights:  [-2.2668657  -1.31778199  2.76997561  2.98424535 -0.57930406]\n",
      "Epoch:  6 Step:  38\n",
      "Weights:  [-2.8668657  -1.58778199  2.25997561  2.82424535 -0.67930406]\n",
      "Epoch:  6 Step:  48\n",
      "Weights:  [-2.1468657  -1.28778199  2.83997561  2.98424535 -0.57930406]\n",
      "Epoch:  6 Step:  56\n",
      "Weights:  [-2.7168657  -1.56778199  2.38997561  2.85424535 -0.67930406]\n",
      "Epoch:  6 Step:  57\n",
      "Weights:  [-2.1568657  -1.28778199  2.87997561  3.05424535 -0.57930406]\n",
      "Epoch:  6 Step:  67\n",
      "Weights:  [-2.7868657  -1.53778199  2.38997561  2.90424535 -0.67930406]\n",
      "Epoch:  6 Step:  68\n",
      "Weights:  [-2.0568657  -1.24778199  3.01997561  3.08424535 -0.57930406]\n",
      "Epoch:  6 Step:  74\n",
      "Weights:  [-2.6268657  -1.54778199  2.59997561  2.96424535 -0.67930406]\n",
      "Epoch:  6 Step:  76\n",
      "Weights:  [-2.1368657  -1.29778199  3.04997561  3.13424535 -0.57930406]\n",
      "Epoch:  6 Step:  86\n",
      "Weights:  [-2.6968657  -1.56778199  2.62997561  3.00424535 -0.67930406]\n",
      "Epoch:  6 Step:  88\n",
      "Weights:  [-1.9368657  -1.26778199  3.28997561  3.21424535 -0.57930406]\n",
      "Epoch:  6 Step:  89\n",
      "Weights:  [-2.5368657  -1.48778199  2.88997561  3.11424535 -0.67930406]\n",
      "Epoch:  7 Step:  2\n",
      "Weights:  [-1.9368657  -1.26778199  3.38997561  3.26424535 -0.57930406]\n",
      "Epoch:  7 Step:  7\n",
      "Weights:  [-2.5668657  -1.49778199  2.94997561  3.13424535 -0.67930406]\n",
      "Epoch:  7 Step:  13\n",
      "Weights:  [-1.8768657  -1.18778199  3.45997561  3.36424535 -0.57930406]\n",
      "Epoch:  7 Step:  14\n",
      "Weights:  [-2.4868657  -1.47778199  2.98997561  3.22424535 -0.67930406]\n",
      "Epoch:  7 Step:  25\n",
      "Weights:  [-1.6968657  -1.09778199  3.62997561  3.42424535 -0.57930406]\n",
      "Epoch:  7 Step:  26\n",
      "Weights:  [-2.2068657  -1.34778199  3.32997561  3.31424535 -0.67930406]\n",
      "Epoch:  7 Step:  27\n",
      "Weights:  [-2.8768657  -1.65778199  2.85997561  3.16424535 -0.77930406]\n",
      "Epoch:  7 Step:  32\n",
      "Weights:  [-2.2268657  -1.33778199  3.36997561  3.36424535 -0.67930406]\n",
      "Epoch:  7 Step:  33\n",
      "Weights:  [-2.8768657  -1.61778199  2.90997561  3.21424535 -0.77930406]\n",
      "Epoch:  7 Step:  35\n",
      "Weights:  [-2.1068657  -1.31778199  3.51997561  3.44424535 -0.67930406]\n",
      "Epoch:  7 Step:  36\n",
      "Weights:  [-2.7968657  -1.62778199  3.02997561  3.29424535 -0.77930406]\n",
      "Epoch:  7 Step:  37\n",
      "Weights:  [-2.1668657  -1.33778199  3.58997561  3.47424535 -0.67930406]\n",
      "Epoch:  7 Step:  38\n",
      "Weights:  [-2.7668657  -1.60778199  3.07997561  3.31424535 -0.77930406]\n",
      "Epoch:  7 Step:  48\n",
      "Weights:  [-2.0468657  -1.30778199  3.65997561  3.47424535 -0.67930406]\n",
      "Epoch:  7 Step:  49\n",
      "Weights:  [-2.7068657  -1.59778199  3.19997561  3.34424535 -0.77930406]\n",
      "Epoch:  7 Step:  51\n",
      "Weights:  [-2.1068657  -1.29778199  3.67997561  3.52424535 -0.67930406]\n",
      "Epoch:  7 Step:  53\n",
      "Weights:  [-2.6568657  -1.54778199  3.27997561  3.39424535 -0.77930406]\n",
      "Epoch:  8 Step:  38\n",
      "Weights:  [-3.2568657  -1.81778199  2.76997561  3.23424535 -0.87930406]\n",
      "Epoch:  8 Step:  48\n",
      "Weights:  [-2.5368657  -1.51778199  3.34997561  3.39424535 -0.77930406]\n",
      "Epoch:  8 Step:  67\n",
      "Weights:  [-3.1668657  -1.76778199  2.85997561  3.24424535 -0.87930406]\n",
      "Epoch:  8 Step:  68\n",
      "Weights:  [-2.4368657  -1.47778199  3.48997561  3.42424535 -0.77930406]\n",
      "Epoch:  8 Step:  75\n",
      "Weights:  [-3.0268657  -1.77778199  3.06997561  3.27424535 -0.87930406]\n",
      "Epoch:  8 Step:  76\n",
      "Weights:  [-2.5368657  -1.52778199  3.51997561  3.44424535 -0.77930406]\n",
      "Epoch:  8 Step:  86\n",
      "Weights:  [-3.0968657  -1.79778199  3.09997561  3.31424535 -0.87930406]\n",
      "Epoch:  8 Step:  88\n",
      "Weights:  [-2.3368657  -1.49778199  3.75997561  3.52424535 -0.77930406]\n",
      "Epoch:  8 Step:  89\n",
      "Weights:  [-2.9368657  -1.71778199  3.35997561  3.42424535 -0.87930406]\n",
      "Epoch:  8 Step:  94\n",
      "Weights:  [-2.2668657  -1.41778199  3.87997561  3.65424535 -0.77930406]\n",
      "Epoch:  8 Step:  97\n",
      "Weights:  [-2.8468657  -1.68778199  3.46997561  3.55424535 -0.87930406]\n",
      "Epoch:  9 Step:  25\n",
      "Weights:  [-2.0568657  -1.30778199  4.10997561  3.75424535 -0.77930406]\n",
      "Epoch:  9 Step:  26\n",
      "Weights:  [-2.5668657  -1.55778199  3.80997561  3.64424535 -0.87930406]\n",
      "Epoch:  9 Step:  27\n",
      "Weights:  [-3.2368657  -1.86778199  3.33997561  3.49424535 -0.97930406]\n",
      "Epoch:  9 Step:  32\n",
      "Weights:  [-2.5868657  -1.54778199  3.84997561  3.69424535 -0.87930406]\n",
      "Epoch:  9 Step:  33\n",
      "Weights:  [-3.2368657  -1.82778199  3.38997561  3.54424535 -0.97930406]\n",
      "Epoch:  9 Step:  35\n",
      "Weights:  [-2.4668657  -1.52778199  3.99997561  3.77424535 -0.87930406]\n",
      "Epoch:  9 Step:  36\n",
      "Weights:  [-3.1568657  -1.83778199  3.50997561  3.62424535 -0.97930406]\n",
      "Epoch:  9 Step:  37\n",
      "Weights:  [-2.5268657  -1.54778199  4.06997561  3.80424535 -0.87930406]\n",
      "Epoch:  9 Step:  38\n",
      "Weights:  [-3.1268657  -1.81778199  3.55997561  3.64424535 -0.97930406]\n",
      "Epoch:  9 Step:  48\n",
      "Weights:  [-2.4068657  -1.51778199  4.13997561  3.80424535 -0.87930406]\n",
      "Epoch:  9 Step:  49\n",
      "Weights:  [-3.0668657  -1.80778199  3.67997561  3.67424535 -0.97930406]\n",
      "Epoch:  9 Step:  51\n",
      "Weights:  [-2.4668657  -1.50778199  4.15997561  3.85424535 -0.87930406]\n",
      "Epoch:  9 Step:  53\n",
      "Weights:  [-3.0168657  -1.75778199  3.75997561  3.72424535 -0.97930406]\n",
      "Epoch:  10 Step:  38\n",
      "Weights:  [-3.6168657  -2.02778199  3.24997561  3.56424535 -1.07930406]\n",
      "Epoch:  10 Step:  48\n",
      "Weights:  [-2.8968657  -1.72778199  3.82997561  3.72424535 -0.97930406]\n",
      "Epoch:  10 Step:  67\n",
      "Weights:  [-3.5268657  -1.97778199  3.33997561  3.57424535 -1.07930406]\n",
      "Epoch:  10 Step:  68\n",
      "Weights:  [-2.7968657  -1.68778199  3.96997561  3.75424535 -0.97930406]\n",
      "Epoch:  10 Step:  86\n",
      "Weights:  [-3.3568657  -1.95778199  3.54997561  3.62424535 -1.07930406]\n",
      "Epoch:  10 Step:  88\n",
      "Weights:  [-2.5968657  -1.65778199  4.20997561  3.83424535 -0.97930406]\n",
      "Epoch:  10 Step:  89\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights:  [-3.1968657  -1.87778199  3.80997561  3.73424535 -1.07930406]\n",
      "Epoch:  11 Step:  13\n",
      "Weights:  [-2.5068657  -1.56778199  4.31997561  3.96424535 -0.97930406]\n",
      "Epoch:  11 Step:  14\n",
      "Weights:  [-3.1168657  -1.85778199  3.84997561  3.82424535 -1.07930406]\n",
      "Epoch:  11 Step:  25\n",
      "Weights:  [-2.3268657  -1.47778199  4.48997561  4.02424535 -0.97930406]\n",
      "Epoch:  11 Step:  26\n",
      "Weights:  [-2.8368657  -1.72778199  4.18997561  3.91424535 -1.07930406]\n",
      "Epoch:  11 Step:  27\n",
      "Weights:  [-3.5068657  -2.03778199  3.71997561  3.76424535 -1.17930406]\n",
      "Epoch:  11 Step:  32\n",
      "Weights:  [-2.8568657  -1.71778199  4.22997561  3.96424535 -1.07930406]\n",
      "Epoch:  11 Step:  33\n",
      "Weights:  [-3.5068657  -1.99778199  3.76997561  3.81424535 -1.17930406]\n",
      "Epoch:  11 Step:  35\n",
      "Weights:  [-2.7368657  -1.69778199  4.37997561  4.04424535 -1.07930406]\n",
      "Epoch:  11 Step:  36\n",
      "Weights:  [-3.4268657  -2.00778199  3.88997561  3.89424535 -1.17930406]\n",
      "Epoch:  11 Step:  48\n",
      "Weights:  [-2.7068657  -1.70778199  4.46997561  4.05424535 -1.07930406]\n",
      "Epoch:  11 Step:  49\n",
      "Weights:  [-3.3668657  -1.99778199  4.00997561  3.92424535 -1.17930406]\n",
      "Epoch:  11 Step:  50\n",
      "Weights:  [-2.7168657  -1.69778199  4.52997561  4.12424535 -1.07930406]\n",
      "Epoch:  11 Step:  53\n",
      "Weights:  [-3.2668657  -1.94778199  4.12997561  3.99424535 -1.17930406]\n",
      "Epoch:  12 Step:  38\n",
      "Weights:  [-3.8668657  -2.21778199  3.61997561  3.83424535 -1.27930406]\n",
      "Epoch:  12 Step:  48\n",
      "Weights:  [-3.1468657  -1.91778199  4.19997561  3.99424535 -1.17930406]\n",
      "Epoch:  12 Step:  67\n",
      "Weights:  [-3.7768657  -2.16778199  3.70997561  3.84424535 -1.27930406]\n",
      "Epoch:  12 Step:  68\n",
      "Weights:  [-3.0468657  -1.87778199  4.33997561  4.02424535 -1.17930406]\n",
      "Epoch:  12 Step:  86\n",
      "Weights:  [-3.6068657  -2.14778199  3.91997561  3.89424535 -1.27930406]\n",
      "Epoch:  12 Step:  88\n",
      "Weights:  [-2.8468657  -1.84778199  4.57997561  4.10424535 -1.17930406]\n",
      "Epoch:  12 Step:  89\n",
      "Weights:  [-3.4468657  -2.06778199  4.17997561  4.00424535 -1.27930406]\n",
      "Epoch:  13 Step:  13\n",
      "Weights:  [-2.7568657  -1.75778199  4.68997561  4.23424535 -1.17930406]\n",
      "Epoch:  13 Step:  14\n",
      "Weights:  [-3.3668657  -2.04778199  4.21997561  4.09424535 -1.27930406]\n",
      "Epoch:  13 Step:  25\n",
      "Weights:  [-2.5768657  -1.66778199  4.85997561  4.29424535 -1.17930406]\n",
      "Epoch:  13 Step:  26\n",
      "Weights:  [-3.0868657  -1.91778199  4.55997561  4.18424535 -1.27930406]\n",
      "Epoch:  13 Step:  28\n",
      "Weights:  [-3.7568657  -2.21778199  4.05997561  4.01424535 -1.37930406]\n",
      "Epoch:  13 Step:  32\n",
      "Weights:  [-3.1068657  -1.89778199  4.56997561  4.21424535 -1.27930406]\n",
      "Epoch:  13 Step:  33\n",
      "Weights:  [-3.7568657  -2.17778199  4.10997561  4.06424535 -1.37930406]\n",
      "Epoch:  13 Step:  35\n",
      "Weights:  [-2.9868657  -1.87778199  4.71997561  4.29424535 -1.27930406]\n",
      "Epoch:  13 Step:  36\n",
      "Weights:  [-3.6768657  -2.18778199  4.22997561  4.14424535 -1.37930406]\n",
      "Epoch:  13 Step:  48\n",
      "Weights:  [-2.9568657  -1.88778199  4.80997561  4.30424535 -1.27930406]\n",
      "Epoch:  13 Step:  49\n",
      "Weights:  [-3.6168657  -2.17778199  4.34997561  4.17424535 -1.37930406]\n",
      "Epoch:  13 Step:  50\n",
      "Weights:  [-2.9668657  -1.87778199  4.86997561  4.37424535 -1.27930406]\n",
      "Epoch:  13 Step:  53\n",
      "Weights:  [-3.5168657  -2.12778199  4.46997561  4.24424535 -1.37930406]\n",
      "Epoch:  14 Step:  25\n",
      "Weights:  [-2.7268657  -1.74778199  5.10997561  4.44424535 -1.27930406]\n",
      "Epoch:  14 Step:  26\n",
      "Weights:  [-3.2368657  -1.99778199  4.80997561  4.33424535 -1.37930406]\n",
      "Epoch:  14 Step:  28\n",
      "Weights:  [-3.9068657  -2.29778199  4.30997561  4.16424535 -1.47930406]\n",
      "Epoch:  14 Step:  32\n",
      "Weights:  [-3.2568657  -1.97778199  4.81997561  4.36424535 -1.37930406]\n",
      "Epoch:  14 Step:  33\n",
      "Weights:  [-3.9068657  -2.25778199  4.35997561  4.21424535 -1.47930406]\n",
      "Epoch:  14 Step:  35\n",
      "Weights:  [-3.1368657  -1.95778199  4.96997561  4.44424535 -1.37930406]\n",
      "Epoch:  14 Step:  36\n",
      "Weights:  [-3.8268657  -2.26778199  4.47997561  4.29424535 -1.47930406]\n",
      "Epoch:  14 Step:  48\n",
      "Weights:  [-3.1068657  -1.96778199  5.05997561  4.45424535 -1.37930406]\n",
      "Epoch:  14 Step:  49\n",
      "Weights:  [-3.7668657  -2.25778199  4.59997561  4.32424535 -1.47930406]\n",
      "Epoch:  14 Step:  50\n",
      "Weights:  [-3.1168657  -1.95778199  5.11997561  4.52424535 -1.37930406]\n",
      "Epoch:  14 Step:  53\n",
      "Weights:  [-3.6668657  -2.20778199  4.71997561  4.39424535 -1.47930406]\n",
      "Epoch:  15 Step:  38\n",
      "Weights:  [-4.2668657  -2.47778199  4.20997561  4.23424535 -1.57930406]\n",
      "Epoch:  15 Step:  48\n",
      "Weights:  [-3.5468657  -2.17778199  4.78997561  4.39424535 -1.47930406]\n",
      "Epoch:  15 Step:  67\n",
      "Weights:  [-4.1768657  -2.42778199  4.29997561  4.24424535 -1.57930406]\n",
      "Epoch:  15 Step:  68\n",
      "Weights:  [-3.4468657  -2.13778199  4.92997561  4.42424535 -1.47930406]\n",
      "Epoch:  16 Step:  14\n",
      "Weights:  [-4.0568657  -2.42778199  4.45997561  4.28424535 -1.57930406]\n",
      "Epoch:  16 Step:  16\n",
      "Weights:  [-3.3668657  -2.10778199  5.02997561  4.51424535 -1.47930406]\n",
      "Epoch:  16 Step:  28\n",
      "Weights:  [-4.0368657  -2.40778199  4.52997561  4.34424535 -1.57930406]\n",
      "Epoch:  16 Step:  32\n",
      "Weights:  [-3.3868657  -2.08778199  5.03997561  4.54424535 -1.47930406]\n",
      "Epoch:  16 Step:  33\n",
      "Weights:  [-4.0368657  -2.36778199  4.57997561  4.39424535 -1.57930406]\n",
      "Epoch:  16 Step:  35\n",
      "Weights:  [-3.2668657  -2.06778199  5.18997561  4.62424535 -1.47930406]\n",
      "Epoch:  16 Step:  36\n",
      "Weights:  [-3.9568657  -2.37778199  4.69997561  4.47424535 -1.57930406]\n",
      "Epoch:  16 Step:  48\n",
      "Weights:  [-3.2368657  -2.07778199  5.27997561  4.63424535 -1.47930406]\n",
      "Epoch:  16 Step:  49\n",
      "Weights:  [-3.8968657  -2.36778199  4.81997561  4.50424535 -1.57930406]\n",
      "Epoch:  16 Step:  51\n",
      "Weights:  [-3.2968657  -2.06778199  5.29997561  4.68424535 -1.47930406]\n",
      "Epoch:  16 Step:  53\n",
      "Weights:  [-3.8468657  -2.31778199  4.89997561  4.55424535 -1.57930406]\n",
      "Epoch:  17 Step:  25\n",
      "Weights:  [-3.0568657  -1.93778199  5.53997561  4.75424535 -1.47930406]\n",
      "Epoch:  17 Step:  27\n",
      "Weights:  [-3.7268657  -2.24778199  5.06997561  4.60424535 -1.57930406]\n",
      "Epoch:  17 Step:  38\n",
      "Weights:  [-4.3268657  -2.51778199  4.55997561  4.44424535 -1.67930406]\n",
      "Epoch:  17 Step:  48\n",
      "Weights:  [-3.6068657  -2.21778199  5.13997561  4.60424535 -1.57930406]\n",
      "Epoch:  17 Step:  56\n",
      "Weights:  [-4.1768657  -2.49778199  4.68997561  4.47424535 -1.67930406]\n",
      "Epoch:  17 Step:  57\n",
      "Weights:  [-3.6168657  -2.21778199  5.17997561  4.67424535 -1.57930406]\n",
      "Epoch:  17 Step:  64\n",
      "Weights:  [-4.2268657  -2.51778199  4.71997561  4.53424535 -1.67930406]\n",
      "Epoch:  17 Step:  68\n",
      "Weights:  [-3.4968657  -2.22778199  5.34997561  4.71424535 -1.57930406]\n",
      "Epoch:  17 Step:  75\n",
      "Weights:  [-4.0868657  -2.52778199  4.92997561  4.56424535 -1.67930406]\n",
      "Epoch:  17 Step:  94\n",
      "Weights:  [-3.4168657  -2.22778199  5.44997561  4.79424535 -1.57930406]\n",
      "Epoch:  18 Step:  7\n",
      "Weights:  [-4.0468657  -2.45778199  5.00997561  4.66424535 -1.67930406]\n",
      "Epoch:  18 Step:  13\n",
      "Weights:  [-3.3568657  -2.14778199  5.51997561  4.89424535 -1.57930406]\n",
      "Epoch:  18 Step:  14\n",
      "Weights:  [-3.9668657  -2.43778199  5.04997561  4.75424535 -1.67930406]\n",
      "Epoch:  18 Step:  25\n",
      "Weights:  [-3.1768657  -2.05778199  5.68997561  4.95424535 -1.57930406]\n",
      "Epoch:  18 Step:  27\n",
      "Weights:  [-3.8468657  -2.36778199  5.21997561  4.80424535 -1.67930406]\n",
      "Epoch:  18 Step:  38\n",
      "Weights:  [-4.4468657  -2.63778199  4.70997561  4.64424535 -1.77930406]\n",
      "Epoch:  18 Step:  48\n",
      "Weights:  [-3.7268657  -2.33778199  5.28997561  4.80424535 -1.67930406]\n",
      "Epoch:  18 Step:  56\n",
      "Weights:  [-4.2968657  -2.61778199  4.83997561  4.67424535 -1.77930406]\n",
      "Epoch:  18 Step:  57\n",
      "Weights:  [-3.7368657  -2.33778199  5.32997561  4.87424535 -1.67930406]\n",
      "Epoch:  18 Step:  67\n",
      "Weights:  [-4.3668657  -2.58778199  4.83997561  4.72424535 -1.77930406]\n",
      "Epoch:  18 Step:  68\n",
      "Weights:  [-3.6368657  -2.29778199  5.46997561  4.90424535 -1.67930406]\n",
      "Epoch:  18 Step:  75\n",
      "Weights:  [-4.2268657  -2.59778199  5.04997561  4.75424535 -1.77930406]\n",
      "Epoch:  18 Step:  94\n",
      "Weights:  [-3.5568657  -2.29778199  5.56997561  4.98424535 -1.67930406]\n",
      "Epoch:  19 Step:  7\n",
      "Weights:  [-4.1868657  -2.52778199  5.12997561  4.85424535 -1.77930406]\n",
      "Epoch:  19 Step:  13\n",
      "Weights:  [-3.4968657  -2.21778199  5.63997561  5.08424535 -1.67930406]\n",
      "Epoch:  19 Step:  14\n",
      "Weights:  [-4.1068657  -2.50778199  5.16997561  4.94424535 -1.77930406]\n",
      "Epoch:  19 Step:  25\n",
      "Weights:  [-3.3168657  -2.12778199  5.80997561  5.14424535 -1.67930406]\n",
      "Epoch:  19 Step:  27\n",
      "Weights:  [-3.9868657  -2.43778199  5.33997561  4.99424535 -1.77930406]\n",
      "Epoch:  19 Step:  38\n",
      "Weights:  [-4.5868657  -2.70778199  4.82997561  4.83424535 -1.87930406]\n",
      "Epoch:  19 Step:  48\n",
      "Weights:  [-3.8668657  -2.40778199  5.40997561  4.99424535 -1.77930406]\n",
      "Epoch:  19 Step:  56\n",
      "Weights:  [-4.4368657  -2.68778199  4.95997561  4.86424535 -1.87930406]\n",
      "Epoch:  19 Step:  57\n",
      "Weights:  [-3.8768657  -2.40778199  5.44997561  5.06424535 -1.77930406]\n",
      "Epoch:  19 Step:  67\n",
      "Weights:  [-4.5068657  -2.65778199  4.95997561  4.91424535 -1.87930406]\n",
      "Epoch:  19 Step:  68\n",
      "Weights:  [-3.7768657  -2.36778199  5.58997561  5.09424535 -1.77930406]\n",
      "Epoch:  19 Step:  86\n",
      "Weights:  [-4.3368657  -2.63778199  5.16997561  4.96424535 -1.87930406]\n",
      "Epoch:  19 Step:  94\n",
      "Weights:  [-3.6668657  -2.33778199  5.68997561  5.19424535 -1.77930406]\n",
      "Epoch:  20 Step:  7\n",
      "Weights:  [-4.2968657  -2.56778199  5.24997561  5.06424535 -1.87930406]\n",
      "Epoch:  20 Step:  13\n",
      "Weights:  [-3.6068657  -2.25778199  5.75997561  5.29424535 -1.77930406]\n",
      "Epoch:  20 Step:  14\n",
      "Weights:  [-4.2168657  -2.54778199  5.28997561  5.15424535 -1.87930406]\n",
      "Epoch:  20 Step:  25\n",
      "Weights:  [-3.4268657  -2.16778199  5.92997561  5.35424535 -1.77930406]\n",
      "Epoch:  20 Step:  27\n",
      "Weights:  [-4.0968657  -2.47778199  5.45997561  5.20424535 -1.87930406]\n",
      "Epoch:  20 Step:  38\n",
      "Weights:  [-4.6968657  -2.74778199  4.94997561  5.04424535 -1.97930406]\n",
      "Epoch:  20 Step:  48\n",
      "Weights:  [-3.9768657  -2.44778199  5.52997561  5.20424535 -1.87930406]\n",
      "Epoch:  20 Step:  56\n",
      "Weights:  [-4.5468657  -2.72778199  5.07997561  5.07424535 -1.97930406]\n",
      "Epoch:  20 Step:  57\n",
      "Weights:  [-3.9868657  -2.44778199  5.56997561  5.27424535 -1.87930406]\n",
      "Epoch:  20 Step:  67\n",
      "Weights:  [-4.6168657  -2.69778199  5.07997561  5.12424535 -1.97930406]\n",
      "Epoch:  20 Step:  68\n",
      "Weights:  [-3.8868657  -2.40778199  5.70997561  5.30424535 -1.87930406]\n",
      "Epoch:  20 Step:  86\n",
      "Weights:  [-4.4468657  -2.67778199  5.28997561  5.17424535 -1.97930406]\n",
      "Epoch:  20 Step:  94\n",
      "Weights:  [-3.7768657  -2.37778199  5.80997561  5.40424535 -1.87930406]\n",
      "Epoch:  21 Step:  7\n",
      "Weights:  [-4.4068657  -2.60778199  5.36997561  5.27424535 -1.97930406]\n",
      "Epoch:  21 Step:  13\n",
      "Weights:  [-3.7168657  -2.29778199  5.87997561  5.50424535 -1.87930406]\n",
      "Epoch:  21 Step:  14\n",
      "Weights:  [-4.3268657  -2.58778199  5.40997561  5.36424535 -1.97930406]\n",
      "Epoch:  21 Step:  25\n",
      "Weights:  [-3.5368657  -2.20778199  6.04997561  5.56424535 -1.87930406]\n",
      "Epoch:  21 Step:  27\n",
      "Weights:  [-4.2068657  -2.51778199  5.57997561  5.41424535 -1.97930406]\n",
      "Epoch:  21 Step:  38\n",
      "Weights:  [-4.8068657  -2.78778199  5.06997561  5.25424535 -2.07930406]\n",
      "Epoch:  21 Step:  48\n",
      "Weights:  [-4.0868657  -2.48778199  5.64997561  5.41424535 -1.97930406]\n",
      "Epoch:  21 Step:  56\n",
      "Weights:  [-4.6568657  -2.76778199  5.19997561  5.28424535 -2.07930406]\n",
      "Epoch:  21 Step:  60\n",
      "Weights:  [-4.0168657  -2.44778199  5.72997561  5.51424535 -1.97930406]\n",
      "Epoch:  21 Step:  64\n",
      "Weights:  [-4.6268657  -2.74778199  5.26997561  5.37424535 -2.07930406]\n",
      "Epoch:  21 Step:  68\n",
      "Weights:  [-3.8968657  -2.45778199  5.89997561  5.55424535 -1.97930406]\n",
      "Epoch:  21 Step:  75\n",
      "Weights:  [-4.4868657  -2.75778199  5.47997561  5.40424535 -2.07930406]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  22 Step:  13\n",
      "Weights:  [-3.7968657  -2.44778199  5.98997561  5.63424535 -1.97930406]\n",
      "Epoch:  22 Step:  14\n",
      "Weights:  [-4.4068657  -2.73778199  5.51997561  5.49424535 -2.07930406]\n",
      "Epoch:  22 Step:  25\n",
      "Weights:  [-3.6168657  -2.35778199  6.15997561  5.69424535 -1.97930406]\n",
      "Epoch:  22 Step:  27\n",
      "Weights:  [-4.2868657  -2.66778199  5.68997561  5.54424535 -2.07930406]\n",
      "Epoch:  22 Step:  38\n",
      "Weights:  [-4.8868657  -2.93778199  5.17997561  5.38424535 -2.17930406]\n",
      "Epoch:  22 Step:  48\n",
      "Weights:  [-4.1668657  -2.63778199  5.75997561  5.54424535 -2.07930406]\n",
      "Epoch:  22 Step:  67\n",
      "Weights:  [-4.7968657  -2.88778199  5.26997561  5.39424535 -2.17930406]\n",
      "Epoch:  22 Step:  68\n",
      "Weights:  [-4.0668657  -2.59778199  5.89997561  5.57424535 -2.07930406]\n",
      "Epoch:  22 Step:  86\n",
      "Weights:  [-4.6268657  -2.86778199  5.47997561  5.44424535 -2.17930406]\n",
      "Epoch:  22 Step:  94\n",
      "Weights:  [-3.9568657  -2.56778199  5.99997561  5.67424535 -2.07930406]\n",
      "Epoch:  23 Step:  7\n",
      "Weights:  [-4.5868657  -2.79778199  5.55997561  5.54424535 -2.17930406]\n",
      "Epoch:  23 Step:  13\n",
      "Weights:  [-3.8968657  -2.48778199  6.06997561  5.77424535 -2.07930406]\n",
      "Epoch:  23 Step:  14\n",
      "Weights:  [-4.5068657  -2.77778199  5.59997561  5.63424535 -2.17930406]\n",
      "Epoch:  23 Step:  25\n",
      "Weights:  [-3.7168657  -2.39778199  6.23997561  5.83424535 -2.07930406]\n",
      "Epoch:  23 Step:  27\n",
      "Weights:  [-4.3868657  -2.70778199  5.76997561  5.68424535 -2.17930406]\n",
      "Epoch:  23 Step:  38\n",
      "Weights:  [-4.9868657  -2.97778199  5.25997561  5.52424535 -2.27930406]\n",
      "Epoch:  23 Step:  48\n",
      "Weights:  [-4.2668657  -2.67778199  5.83997561  5.68424535 -2.17930406]\n",
      "Epoch:  23 Step:  67\n",
      "Weights:  [-4.8968657  -2.92778199  5.34997561  5.53424535 -2.27930406]\n",
      "Epoch:  23 Step:  68\n",
      "Weights:  [-4.1668657  -2.63778199  5.97997561  5.71424535 -2.17930406]\n",
      "Epoch:  24 Step:  14\n",
      "Weights:  [-4.7768657  -2.92778199  5.50997561  5.57424535 -2.27930406]\n",
      "Epoch:  24 Step:  16\n",
      "Weights:  [-4.0868657  -2.60778199  6.07997561  5.80424535 -2.17930406]\n",
      "Epoch:  24 Step:  28\n",
      "Weights:  [-4.7568657  -2.90778199  5.57997561  5.63424535 -2.27930406]\n",
      "Epoch:  24 Step:  32\n",
      "Weights:  [-4.1068657  -2.58778199  6.08997561  5.83424535 -2.17930406]\n",
      "Epoch:  24 Step:  33\n",
      "Weights:  [-4.7568657  -2.86778199  5.62997561  5.68424535 -2.27930406]\n",
      "Epoch:  24 Step:  35\n",
      "Weights:  [-3.9868657  -2.56778199  6.23997561  5.91424535 -2.17930406]\n",
      "Epoch:  24 Step:  36\n",
      "Weights:  [-4.6768657  -2.87778199  5.74997561  5.76424535 -2.27930406]\n",
      "Epoch:  24 Step:  38\n",
      "Weights:  [-5.2768657  -3.14778199  5.23997561  5.60424535 -2.37930406]\n",
      "Epoch:  24 Step:  48\n",
      "Weights:  [-4.5568657  -2.84778199  5.81997561  5.76424535 -2.27930406]\n",
      "Epoch:  25 Step:  25\n",
      "Weights:  [-3.7668657  -2.46778199  6.45997561  5.96424535 -2.17930406]\n",
      "Epoch:  25 Step:  27\n",
      "Weights:  [-4.4368657  -2.77778199  5.98997561  5.81424535 -2.27930406]\n",
      "Epoch:  25 Step:  38\n",
      "Weights:  [-5.0368657  -3.04778199  5.47997561  5.65424535 -2.37930406]\n",
      "Epoch:  25 Step:  48\n",
      "Weights:  [-4.3168657  -2.74778199  6.05997561  5.81424535 -2.27930406]\n",
      "Epoch:  25 Step:  56\n",
      "Weights:  [-4.8868657  -3.02778199  5.60997561  5.68424535 -2.37930406]\n",
      "Epoch:  25 Step:  60\n",
      "Weights:  [-4.2468657  -2.70778199  6.13997561  5.91424535 -2.27930406]\n",
      "Epoch:  25 Step:  64\n",
      "Weights:  [-4.8568657  -3.00778199  5.67997561  5.77424535 -2.37930406]\n",
      "Epoch:  25 Step:  68\n",
      "Weights:  [-4.1268657  -2.71778199  6.30997561  5.95424535 -2.27930406]\n",
      "Epoch:  25 Step:  75\n",
      "Weights:  [-4.7168657  -3.01778199  5.88997561  5.80424535 -2.37930406]\n",
      "Epoch:  26 Step:  13\n",
      "Weights:  [-4.0268657  -2.70778199  6.39997561  6.03424535 -2.27930406]\n",
      "Epoch:  26 Step:  14\n",
      "Weights:  [-4.6368657  -2.99778199  5.92997561  5.89424535 -2.37930406]\n",
      "Epoch:  26 Step:  25\n",
      "Weights:  [-3.8468657  -2.61778199  6.56997561  6.09424535 -2.27930406]\n",
      "Epoch:  26 Step:  27\n",
      "Weights:  [-4.5168657  -2.92778199  6.09997561  5.94424535 -2.37930406]\n",
      "Epoch:  26 Step:  38\n",
      "Weights:  [-5.1168657  -3.19778199  5.58997561  5.78424535 -2.47930406]\n",
      "Epoch:  26 Step:  48\n",
      "Weights:  [-4.3968657  -2.89778199  6.16997561  5.94424535 -2.37930406]\n",
      "Epoch:  26 Step:  67\n",
      "Weights:  [-5.0268657  -3.14778199  5.67997561  5.79424535 -2.47930406]\n",
      "Epoch:  26 Step:  68\n",
      "Weights:  [-4.2968657  -2.85778199  6.30997561  5.97424535 -2.37930406]\n",
      "Epoch:  26 Step:  86\n",
      "Weights:  [-4.8568657  -3.12778199  5.88997561  5.84424535 -2.47930406]\n",
      "Epoch:  26 Step:  94\n",
      "Weights:  [-4.1868657  -2.82778199  6.40997561  6.07424535 -2.37930406]\n",
      "Epoch:  27 Step:  7\n",
      "Weights:  [-4.8168657  -3.05778199  5.96997561  5.94424535 -2.47930406]\n",
      "Epoch:  27 Step:  13\n",
      "Weights:  [-4.1268657  -2.74778199  6.47997561  6.17424535 -2.37930406]\n",
      "Epoch:  27 Step:  14\n",
      "Weights:  [-4.7368657  -3.03778199  6.00997561  6.03424535 -2.47930406]\n",
      "Epoch:  27 Step:  25\n",
      "Weights:  [-3.9468657  -2.65778199  6.64997561  6.23424535 -2.37930406]\n",
      "Epoch:  27 Step:  27\n",
      "Weights:  [-4.6168657  -2.96778199  6.17997561  6.08424535 -2.47930406]\n",
      "Epoch:  27 Step:  38\n",
      "Weights:  [-5.2168657  -3.23778199  5.66997561  5.92424535 -2.57930406]\n",
      "Epoch:  27 Step:  48\n",
      "Weights:  [-4.4968657  -2.93778199  6.24997561  6.08424535 -2.47930406]\n",
      "Epoch:  27 Step:  67\n",
      "Weights:  [-5.1268657  -3.18778199  5.75997561  5.93424535 -2.57930406]\n",
      "Epoch:  27 Step:  68\n",
      "Weights:  [-4.3968657  -2.89778199  6.38997561  6.11424535 -2.47930406]\n",
      "Epoch:  28 Step:  14\n",
      "Weights:  [-5.0068657  -3.18778199  5.91997561  5.97424535 -2.57930406]\n",
      "Epoch:  28 Step:  19\n",
      "Weights:  [-4.2968657  -2.88778199  6.50997561  6.18424535 -2.47930406]\n",
      "Epoch:  28 Step:  28\n",
      "Weights:  [-4.9668657  -3.18778199  6.00997561  6.01424535 -2.57930406]\n",
      "Epoch:  28 Step:  32\n",
      "Weights:  [-4.3168657  -2.86778199  6.51997561  6.21424535 -2.47930406]\n",
      "Epoch:  28 Step:  33\n",
      "Weights:  [-4.9668657  -3.14778199  6.05997561  6.06424535 -2.57930406]\n",
      "Epoch:  28 Step:  48\n",
      "Weights:  [-4.2468657  -2.84778199  6.63997561  6.22424535 -2.47930406]\n",
      "Epoch:  28 Step:  53\n",
      "Weights:  [-4.7968657  -3.09778199  6.23997561  6.09424535 -2.57930406]\n",
      "Epoch:  29 Step:  25\n",
      "Weights:  [-4.0068657  -2.71778199  6.87997561  6.29424535 -2.47930406]\n",
      "Epoch:  29 Step:  27\n",
      "Weights:  [-4.6768657  -3.02778199  6.40997561  6.14424535 -2.57930406]\n",
      "Epoch:  29 Step:  38\n",
      "Weights:  [-5.2768657  -3.29778199  5.89997561  5.98424535 -2.67930406]\n",
      "Epoch:  29 Step:  48\n",
      "Weights:  [-4.5568657  -2.99778199  6.47997561  6.14424535 -2.57930406]\n",
      "Epoch:  29 Step:  56\n",
      "Weights:  [-5.1268657  -3.27778199  6.02997561  6.01424535 -2.67930406]\n",
      "Epoch:  29 Step:  60\n",
      "Weights:  [-4.4868657  -2.95778199  6.55997561  6.24424535 -2.57930406]\n",
      "Epoch:  29 Step:  64\n",
      "Weights:  [-5.0968657  -3.25778199  6.09997561  6.10424535 -2.67930406]\n",
      "Epoch:  29 Step:  94\n",
      "Weights:  [-4.4268657  -2.95778199  6.61997561  6.33424535 -2.57930406]\n",
      "Epoch:  30 Step:  7\n",
      "Weights:  [-5.0568657  -3.18778199  6.17997561  6.20424535 -2.67930406]\n",
      "Epoch:  30 Step:  13\n",
      "Weights:  [-4.3668657  -2.87778199  6.68997561  6.43424535 -2.57930406]\n",
      "Epoch:  30 Step:  14\n",
      "Weights:  [-4.9768657  -3.16778199  6.21997561  6.29424535 -2.67930406]\n",
      "Epoch:  30 Step:  25\n",
      "Weights:  [-4.1868657  -2.78778199  6.85997561  6.49424535 -2.57930406]\n",
      "Epoch:  30 Step:  27\n",
      "Weights:  [-4.8568657  -3.09778199  6.38997561  6.34424535 -2.67930406]\n",
      "Epoch:  30 Step:  38\n",
      "Weights:  [-5.4568657  -3.36778199  5.87997561  6.18424535 -2.77930406]\n",
      "Epoch:  30 Step:  48\n",
      "Weights:  [-4.7368657  -3.06778199  6.45997561  6.34424535 -2.67930406]\n",
      "Epoch:  30 Step:  67\n",
      "Weights:  [-5.3668657  -3.31778199  5.96997561  6.19424535 -2.77930406]\n",
      "Epoch:  30 Step:  68\n",
      "Weights:  [-4.6368657  -3.02778199  6.59997561  6.37424535 -2.67930406]\n",
      "Epoch:  31 Step:  14\n",
      "Weights:  [-5.2468657  -3.31778199  6.12997561  6.23424535 -2.77930406]\n",
      "Epoch:  31 Step:  16\n",
      "Weights:  [-4.5568657  -2.99778199  6.69997561  6.46424535 -2.67930406]\n",
      "Epoch:  31 Step:  28\n",
      "Weights:  [-5.2268657  -3.29778199  6.19997561  6.29424535 -2.77930406]\n",
      "Epoch:  31 Step:  32\n",
      "Weights:  [-4.5768657  -2.97778199  6.70997561  6.49424535 -2.67930406]\n",
      "Epoch:  31 Step:  38\n",
      "Weights:  [-5.1768657  -3.24778199  6.19997561  6.33424535 -2.77930406]\n",
      "Epoch:  31 Step:  48\n",
      "Weights:  [-4.4568657  -2.94778199  6.77997561  6.49424535 -2.67930406]\n",
      "Epoch:  31 Step:  53\n",
      "Weights:  [-5.0068657  -3.19778199  6.37997561  6.36424535 -2.77930406]\n",
      "Epoch:  31 Step:  63\n",
      "Weights:  [-4.3968657  -2.89778199  6.86997561  6.54424535 -2.67930406]\n",
      "Epoch:  31 Step:  64\n",
      "Weights:  [-5.0068657  -3.19778199  6.40997561  6.40424535 -2.77930406]\n",
      "Epoch:  32 Step:  25\n",
      "Weights:  [-4.2168657  -2.81778199  7.04997561  6.60424535 -2.67930406]\n",
      "Epoch:  32 Step:  27\n",
      "Weights:  [-4.8868657  -3.12778199  6.57997561  6.45424535 -2.77930406]\n",
      "Epoch:  32 Step:  38\n",
      "Weights:  [-5.4868657  -3.39778199  6.06997561  6.29424535 -2.87930406]\n",
      "Epoch:  32 Step:  48\n",
      "Weights:  [-4.7668657  -3.09778199  6.64997561  6.45424535 -2.77930406]\n",
      "Epoch:  32 Step:  67\n",
      "Weights:  [-5.3968657  -3.34778199  6.15997561  6.30424535 -2.87930406]\n",
      "Epoch:  32 Step:  68\n",
      "Weights:  [-4.6668657  -3.05778199  6.78997561  6.48424535 -2.77930406]\n",
      "Epoch:  33 Step:  14\n",
      "Weights:  [-5.2768657  -3.34778199  6.31997561  6.34424535 -2.87930406]\n",
      "Epoch:  33 Step:  22\n",
      "Weights:  [-4.6468657  -3.09778199  6.81997561  6.53424535 -2.77930406]\n",
      "Epoch:  33 Step:  28\n",
      "Weights:  [-5.3168657  -3.39778199  6.31997561  6.36424535 -2.87930406]\n",
      "Epoch:  33 Step:  32\n",
      "Weights:  [-4.6668657  -3.07778199  6.82997561  6.56424535 -2.77930406]\n",
      "Epoch:  33 Step:  38\n",
      "Weights:  [-5.2668657  -3.34778199  6.31997561  6.40424535 -2.87930406]\n",
      "Epoch:  33 Step:  48\n",
      "Weights:  [-4.5468657  -3.04778199  6.89997561  6.56424535 -2.77930406]\n",
      "Epoch:  33 Step:  53\n",
      "Weights:  [-5.0968657  -3.29778199  6.49997561  6.43424535 -2.87930406]\n",
      "Epoch:  33 Step:  63\n",
      "Weights:  [-4.4868657  -2.99778199  6.98997561  6.61424535 -2.77930406]\n",
      "Epoch:  33 Step:  64\n",
      "Weights:  [-5.0968657  -3.29778199  6.52997561  6.47424535 -2.87930406]\n",
      "Epoch:  34 Step:  13\n",
      "Weights:  [-4.4068657  -2.98778199  7.03997561  6.70424535 -2.77930406]\n",
      "Epoch:  34 Step:  14\n",
      "Weights:  [-5.0168657  -3.27778199  6.56997561  6.56424535 -2.87930406]\n",
      "Epoch:  34 Step:  38\n",
      "Weights:  [-5.6168657  -3.54778199  6.05997561  6.40424535 -2.97930406]\n",
      "Epoch:  34 Step:  48\n",
      "Weights:  [-4.8968657  -3.24778199  6.63997561  6.56424535 -2.87930406]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  34 Step:  67\n",
      "Weights:  [-5.5268657  -3.49778199  6.14997561  6.41424535 -2.97930406]\n",
      "Epoch:  34 Step:  68\n",
      "Weights:  [-4.7968657  -3.20778199  6.77997561  6.59424535 -2.87930406]\n",
      "Epoch:  35 Step:  28\n",
      "Weights:  [-5.4668657  -3.50778199  6.27997561  6.42424535 -2.97930406]\n",
      "Epoch:  35 Step:  32\n",
      "Weights:  [-4.8168657  -3.18778199  6.78997561  6.62424535 -2.87930406]\n",
      "Epoch:  35 Step:  38\n",
      "Weights:  [-5.4168657  -3.45778199  6.27997561  6.46424535 -2.97930406]\n",
      "Epoch:  35 Step:  48\n",
      "Weights:  [-4.6968657  -3.15778199  6.85997561  6.62424535 -2.87930406]\n",
      "Epoch:  35 Step:  56\n",
      "Weights:  [-5.2668657  -3.43778199  6.40997561  6.49424535 -2.97930406]\n",
      "Epoch:  35 Step:  63\n",
      "Weights:  [-4.6568657  -3.13778199  6.89997561  6.67424535 -2.87930406]\n",
      "Epoch:  35 Step:  64\n",
      "Weights:  [-5.2668657  -3.43778199  6.43997561  6.53424535 -2.97930406]\n",
      "Epoch:  35 Step:  94\n",
      "Weights:  [-4.5968657  -3.13778199  6.95997561  6.76424535 -2.87930406]\n",
      "Epoch:  36 Step:  7\n",
      "Weights:  [-5.2268657  -3.36778199  6.51997561  6.63424535 -2.97930406]\n",
      "Epoch:  36 Step:  13\n",
      "Weights:  [-4.5368657  -3.05778199  7.02997561  6.86424535 -2.87930406]\n",
      "Epoch:  36 Step:  14\n",
      "Weights:  [-5.1468657  -3.34778199  6.55997561  6.72424535 -2.97930406]\n",
      "Epoch:  36 Step:  25\n",
      "Weights:  [-4.3568657  -2.96778199  7.19997561  6.92424535 -2.87930406]\n",
      "Epoch:  36 Step:  27\n",
      "Weights:  [-5.0268657  -3.27778199  6.72997561  6.77424535 -2.97930406]\n",
      "Epoch:  36 Step:  38\n",
      "Weights:  [-5.6268657  -3.54778199  6.21997561  6.61424535 -3.07930406]\n",
      "Epoch:  36 Step:  48\n",
      "Weights:  [-4.9068657  -3.24778199  6.79997561  6.77424535 -2.97930406]\n",
      "Epoch:  36 Step:  67\n",
      "Weights:  [-5.5368657  -3.49778199  6.30997561  6.62424535 -3.07930406]\n",
      "Epoch:  36 Step:  68\n",
      "Weights:  [-4.8068657  -3.20778199  6.93997561  6.80424535 -2.97930406]\n",
      "Epoch:  37 Step:  14\n",
      "Weights:  [-5.4168657  -3.49778199  6.46997561  6.66424535 -3.07930406]\n",
      "Epoch:  37 Step:  22\n",
      "Weights:  [-4.7868657  -3.24778199  6.96997561  6.85424535 -2.97930406]\n",
      "Epoch:  37 Step:  28\n",
      "Weights:  [-5.4568657  -3.54778199  6.46997561  6.68424535 -3.07930406]\n",
      "Epoch:  37 Step:  32\n",
      "Weights:  [-4.8068657  -3.22778199  6.97997561  6.88424535 -2.97930406]\n",
      "Epoch:  37 Step:  38\n",
      "Weights:  [-5.4068657  -3.49778199  6.46997561  6.72424535 -3.07930406]\n",
      "Epoch:  37 Step:  48\n",
      "Weights:  [-4.6868657  -3.19778199  7.04997561  6.88424535 -2.97930406]\n",
      "Epoch:  37 Step:  53\n",
      "Weights:  [-5.2368657  -3.44778199  6.64997561  6.75424535 -3.07930406]\n",
      "Epoch:  37 Step:  63\n",
      "Weights:  [-4.6268657  -3.14778199  7.13997561  6.93424535 -2.97930406]\n",
      "Epoch:  37 Step:  64\n",
      "Weights:  [-5.2368657  -3.44778199  6.67997561  6.79424535 -3.07930406]\n",
      "Epoch:  38 Step:  13\n",
      "Weights:  [-4.5468657  -3.13778199  7.18997561  7.02424535 -2.97930406]\n",
      "Epoch:  38 Step:  14\n",
      "Weights:  [-5.1568657  -3.42778199  6.71997561  6.88424535 -3.07930406]\n",
      "Epoch:  38 Step:  25\n",
      "Weights:  [-4.3668657  -3.04778199  7.35997561  7.08424535 -2.97930406]\n",
      "Epoch:  38 Step:  27\n",
      "Weights:  [-5.0368657  -3.35778199  6.88997561  6.93424535 -3.07930406]\n",
      "Epoch:  38 Step:  38\n",
      "Weights:  [-5.6368657  -3.62778199  6.37997561  6.77424535 -3.17930406]\n",
      "Epoch:  38 Step:  48\n",
      "Weights:  [-4.9168657  -3.32778199  6.95997561  6.93424535 -3.07930406]\n",
      "Epoch:  38 Step:  67\n",
      "Weights:  [-5.5468657  -3.57778199  6.46997561  6.78424535 -3.17930406]\n",
      "Epoch:  38 Step:  68\n",
      "Weights:  [-4.8168657  -3.28778199  7.09997561  6.96424535 -3.07930406]\n",
      "Epoch:  39 Step:  14\n",
      "Weights:  [-5.4268657  -3.57778199  6.62997561  6.82424535 -3.17930406]\n",
      "Epoch:  39 Step:  22\n",
      "Weights:  [-4.7968657  -3.32778199  7.12997561  7.01424535 -3.07930406]\n",
      "Epoch:  39 Step:  28\n",
      "Weights:  [-5.4668657  -3.62778199  6.62997561  6.84424535 -3.17930406]\n",
      "Epoch:  39 Step:  32\n",
      "Weights:  [-4.8168657  -3.30778199  7.13997561  7.04424535 -3.07930406]\n",
      "Epoch:  39 Step:  38\n",
      "Weights:  [-5.4168657  -3.57778199  6.62997561  6.88424535 -3.17930406]\n",
      "Epoch:  39 Step:  48\n",
      "Weights:  [-4.6968657  -3.27778199  7.20997561  7.04424535 -3.07930406]\n",
      "Epoch:  39 Step:  53\n",
      "Weights:  [-5.2468657  -3.52778199  6.80997561  6.91424535 -3.17930406]\n",
      "Epoch:  40 Step:  25\n",
      "Weights:  [-4.4568657  -3.14778199  7.44997561  7.11424535 -3.07930406]\n",
      "Epoch:  40 Step:  27\n",
      "Weights:  [-5.1268657  -3.45778199  6.97997561  6.96424535 -3.17930406]\n",
      "Epoch:  40 Step:  38\n",
      "Weights:  [-5.7268657  -3.72778199  6.46997561  6.80424535 -3.27930406]\n",
      "Epoch:  40 Step:  48\n",
      "Weights:  [-5.0068657  -3.42778199  7.04997561  6.96424535 -3.17930406]\n",
      "Epoch:  40 Step:  67\n",
      "Weights:  [-5.6368657  -3.67778199  6.55997561  6.81424535 -3.27930406]\n",
      "Epoch:  40 Step:  68\n",
      "Weights:  [-4.9068657  -3.38778199  7.18997561  6.99424535 -3.17930406]\n",
      "Epoch:  41 Step:  14\n",
      "Weights:  [-5.5168657  -3.67778199  6.71997561  6.85424535 -3.27930406]\n",
      "Epoch:  41 Step:  22\n",
      "Weights:  [-4.8868657  -3.42778199  7.21997561  7.04424535 -3.17930406]\n",
      "Epoch:  41 Step:  28\n",
      "Weights:  [-5.5568657  -3.72778199  6.71997561  6.87424535 -3.27930406]\n",
      "Epoch:  41 Step:  32\n",
      "Weights:  [-4.9068657  -3.40778199  7.22997561  7.07424535 -3.17930406]\n",
      "Epoch:  41 Step:  38\n",
      "Weights:  [-5.5068657  -3.67778199  6.71997561  6.91424535 -3.27930406]\n",
      "Epoch:  41 Step:  48\n",
      "Weights:  [-4.7868657  -3.37778199  7.29997561  7.07424535 -3.17930406]\n",
      "Epoch:  41 Step:  53\n",
      "Weights:  [-5.3368657  -3.62778199  6.89997561  6.94424535 -3.27930406]\n",
      "Epoch:  41 Step:  63\n",
      "Weights:  [-4.7268657  -3.32778199  7.38997561  7.12424535 -3.17930406]\n",
      "Epoch:  41 Step:  64\n",
      "Weights:  [-5.3368657  -3.62778199  6.92997561  6.98424535 -3.27930406]\n",
      "Epoch:  42 Step:  25\n",
      "Weights:  [-4.5468657  -3.24778199  7.56997561  7.18424535 -3.17930406]\n",
      "Epoch:  42 Step:  27\n",
      "Weights:  [-5.2168657  -3.55778199  7.09997561  7.03424535 -3.27930406]\n",
      "Epoch:  42 Step:  38\n",
      "Weights:  [-5.8168657  -3.82778199  6.58997561  6.87424535 -3.37930406]\n",
      "Epoch:  42 Step:  48\n",
      "Weights:  [-5.0968657  -3.52778199  7.16997561  7.03424535 -3.27930406]\n",
      "Epoch:  42 Step:  67\n",
      "Weights:  [-5.7268657  -3.77778199  6.67997561  6.88424535 -3.37930406]\n",
      "Epoch:  42 Step:  68\n",
      "Weights:  [-4.9968657  -3.48778199  7.30997561  7.06424535 -3.27930406]\n",
      "Epoch:  43 Step:  14\n",
      "Weights:  [-5.6068657  -3.77778199  6.83997561  6.92424535 -3.37930406]\n",
      "Epoch:  43 Step:  22\n",
      "Weights:  [-4.9768657  -3.52778199  7.33997561  7.11424535 -3.27930406]\n",
      "Epoch:  43 Step:  28\n",
      "Weights:  [-5.6468657  -3.82778199  6.83997561  6.94424535 -3.37930406]\n",
      "Epoch:  43 Step:  32\n",
      "Weights:  [-4.9968657  -3.50778199  7.34997561  7.14424535 -3.27930406]\n",
      "Epoch:  43 Step:  38\n",
      "Weights:  [-5.5968657  -3.77778199  6.83997561  6.98424535 -3.37930406]\n",
      "Epoch:  43 Step:  48\n",
      "Weights:  [-4.8768657  -3.47778199  7.41997561  7.14424535 -3.27930406]\n",
      "Epoch:  43 Step:  53\n",
      "Weights:  [-5.4268657  -3.72778199  7.01997561  7.01424535 -3.37930406]\n",
      "Epoch:  43 Step:  63\n",
      "Weights:  [-4.8168657  -3.42778199  7.50997561  7.19424535 -3.27930406]\n",
      "Epoch:  43 Step:  64\n",
      "Weights:  [-5.4268657  -3.72778199  7.04997561  7.05424535 -3.37930406]\n",
      "Epoch:  44 Step:  13\n",
      "Weights:  [-4.7368657  -3.41778199  7.55997561  7.28424535 -3.27930406]\n",
      "Epoch:  44 Step:  14\n",
      "Weights:  [-5.3468657  -3.70778199  7.08997561  7.14424535 -3.37930406]\n",
      "Epoch:  44 Step:  25\n",
      "Weights:  [-4.5568657  -3.32778199  7.72997561  7.34424535 -3.27930406]\n",
      "Epoch:  44 Step:  27\n",
      "Weights:  [-5.2268657  -3.63778199  7.25997561  7.19424535 -3.37930406]\n",
      "Epoch:  44 Step:  38\n",
      "Weights:  [-5.8268657  -3.90778199  6.74997561  7.03424535 -3.47930406]\n",
      "Epoch:  44 Step:  48\n",
      "Weights:  [-5.1068657  -3.60778199  7.32997561  7.19424535 -3.37930406]\n",
      "Epoch:  44 Step:  67\n",
      "Weights:  [-5.7368657  -3.85778199  6.83997561  7.04424535 -3.47930406]\n",
      "Epoch:  44 Step:  68\n",
      "Weights:  [-5.0068657  -3.56778199  7.46997561  7.22424535 -3.37930406]\n",
      "Epoch:  45 Step:  14\n",
      "Weights:  [-5.6168657  -3.85778199  6.99997561  7.08424535 -3.47930406]\n",
      "Epoch:  45 Step:  22\n",
      "Weights:  [-4.9868657  -3.60778199  7.49997561  7.27424535 -3.37930406]\n",
      "Epoch:  45 Step:  28\n",
      "Weights:  [-5.6568657  -3.90778199  6.99997561  7.10424535 -3.47930406]\n",
      "Epoch:  45 Step:  32\n",
      "Weights:  [-5.0068657  -3.58778199  7.50997561  7.30424535 -3.37930406]\n",
      "Epoch:  45 Step:  38\n",
      "Weights:  [-5.6068657  -3.85778199  6.99997561  7.14424535 -3.47930406]\n",
      "Epoch:  45 Step:  48\n",
      "Weights:  [-4.8868657  -3.55778199  7.57997561  7.30424535 -3.37930406]\n",
      "Epoch:  45 Step:  53\n",
      "Weights:  [-5.4368657  -3.80778199  7.17997561  7.17424535 -3.47930406]\n",
      "Epoch:  46 Step:  25\n",
      "Weights:  [-4.6468657  -3.42778199  7.81997561  7.37424535 -3.37930406]\n",
      "Epoch:  46 Step:  27\n",
      "Weights:  [-5.3168657  -3.73778199  7.34997561  7.22424535 -3.47930406]\n",
      "Epoch:  46 Step:  38\n",
      "Weights:  [-5.9168657  -4.00778199  6.83997561  7.06424535 -3.57930406]\n",
      "Epoch:  46 Step:  48\n",
      "Weights:  [-5.1968657  -3.70778199  7.41997561  7.22424535 -3.47930406]\n",
      "Epoch:  46 Step:  67\n",
      "Weights:  [-5.8268657  -3.95778199  6.92997561  7.07424535 -3.57930406]\n",
      "Epoch:  46 Step:  68\n",
      "Weights:  [-5.0968657  -3.66778199  7.55997561  7.25424535 -3.47930406]\n",
      "Epoch:  47 Step:  14\n",
      "Weights:  [-5.7068657  -3.95778199  7.08997561  7.11424535 -3.57930406]\n",
      "Epoch:  47 Step:  22\n",
      "Weights:  [-5.0768657  -3.70778199  7.58997561  7.30424535 -3.47930406]\n",
      "Epoch:  47 Step:  28\n",
      "Weights:  [-5.7468657  -4.00778199  7.08997561  7.13424535 -3.57930406]\n",
      "Epoch:  47 Step:  32\n",
      "Weights:  [-5.0968657  -3.68778199  7.59997561  7.33424535 -3.47930406]\n",
      "Epoch:  47 Step:  38\n",
      "Weights:  [-5.6968657  -3.95778199  7.08997561  7.17424535 -3.57930406]\n",
      "Epoch:  47 Step:  48\n",
      "Weights:  [-4.9768657  -3.65778199  7.66997561  7.33424535 -3.47930406]\n",
      "Epoch:  47 Step:  53\n",
      "Weights:  [-5.5268657  -3.90778199  7.26997561  7.20424535 -3.57930406]\n",
      "Epoch:  47 Step:  63\n",
      "Weights:  [-4.9168657  -3.60778199  7.75997561  7.38424535 -3.47930406]\n",
      "Epoch:  47 Step:  64\n",
      "Weights:  [-5.5268657  -3.90778199  7.29997561  7.24424535 -3.57930406]\n",
      "Epoch:  48 Step:  25\n",
      "Weights:  [-4.7368657  -3.52778199  7.93997561  7.44424535 -3.47930406]\n",
      "Epoch:  48 Step:  27\n",
      "Weights:  [-5.4068657  -3.83778199  7.46997561  7.29424535 -3.57930406]\n",
      "Epoch:  48 Step:  38\n",
      "Weights:  [-6.0068657  -4.10778199  6.95997561  7.13424535 -3.67930406]\n",
      "Epoch:  48 Step:  48\n",
      "Weights:  [-5.2868657  -3.80778199  7.53997561  7.29424535 -3.57930406]\n",
      "Epoch:  48 Step:  67\n",
      "Weights:  [-5.9168657  -4.05778199  7.04997561  7.14424535 -3.67930406]\n",
      "Epoch:  48 Step:  68\n",
      "Weights:  [-5.1868657  -3.76778199  7.67997561  7.32424535 -3.57930406]\n",
      "Epoch:  49 Step:  14\n",
      "Weights:  [-5.7968657  -4.05778199  7.20997561  7.18424535 -3.67930406]\n",
      "Epoch:  49 Step:  22\n",
      "Weights:  [-5.1668657  -3.80778199  7.70997561  7.37424535 -3.57930406]\n",
      "Epoch:  49 Step:  28\n",
      "Weights:  [-5.8368657  -4.10778199  7.20997561  7.20424535 -3.67930406]\n",
      "Epoch:  49 Step:  32\n",
      "Weights:  [-5.1868657  -3.78778199  7.71997561  7.40424535 -3.57930406]\n",
      "Epoch:  49 Step:  38\n",
      "Weights:  [-5.7868657  -4.05778199  7.20997561  7.24424535 -3.67930406]\n",
      "Epoch:  49 Step:  48\n",
      "Weights:  [-5.0668657  -3.75778199  7.78997561  7.40424535 -3.57930406]\n",
      "Epoch:  49 Step:  56\n",
      "Weights:  [-5.6368657  -4.03778199  7.33997561  7.27424535 -3.67930406]\n",
      "Epoch:  49 Step:  63\n",
      "Weights:  [-5.0268657  -3.73778199  7.82997561  7.45424535 -3.57930406]\n",
      "Epoch:  49 Step:  64\n",
      "Weights:  [-5.6368657  -4.03778199  7.36997561  7.31424535 -3.67930406]\n",
      "Epoch:  50 Step:  13\n",
      "Weights:  [-4.9468657  -3.72778199  7.87997561  7.54424535 -3.57930406]\n",
      "Epoch:  50 Step:  14\n",
      "Weights:  [-5.5568657  -4.01778199  7.40997561  7.40424535 -3.67930406]\n",
      "Epoch:  50 Step:  25\n",
      "Weights:  [-4.7668657  -3.63778199  8.04997561  7.60424535 -3.57930406]\n",
      "Epoch:  50 Step:  27\n",
      "Weights:  [-5.4368657  -3.94778199  7.57997561  7.45424535 -3.67930406]\n",
      "Epoch:  50 Step:  38\n",
      "Weights:  [-6.0368657  -4.21778199  7.06997561  7.29424535 -3.77930406]\n",
      "Epoch:  50 Step:  48\n",
      "Weights:  [-5.3168657  -3.91778199  7.64997561  7.45424535 -3.67930406]\n",
      "Epoch:  50 Step:  67\n",
      "Weights:  [-5.9468657  -4.16778199  7.15997561  7.30424535 -3.77930406]\n",
      "Epoch:  50 Step:  68\n",
      "Weights:  [-5.2168657  -3.87778199  7.78997561  7.48424535 -3.67930406]\n",
      "------------------------------------------\n",
      "Perceptron training successfully completed\n",
      "\n",
      "\n",
      "\n",
      "Testing the perceptron\n",
      "-----------------------\n",
      "Correctly classified:  47 \tIncorrectly classified:  3\n",
      "Accuracy:  94.0 %\n"
     ]
    }
   ],
   "source": [
    "inputs, outputs = prepare_train_data_for_classification(df, 2)\n",
    "\n",
    "#Set learning rate and number of epochs\n",
    "lr = 0.1\n",
    "num_epochs = 50\n",
    "\n",
    "vir_perceptron = Perceptron(inputs, outputs, lr, num_epochs)\n",
    "\n",
    "#Training the perceptron\n",
    "vir_perceptron.fit()\n",
    "\n",
    "#Testing the trained perceptron\n",
    "vir_perceptron.test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Versicolor vs non-versicolor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the perceptron\n",
      "-----------------------\n",
      "Epoch:  1 Step:  1\n",
      "Weights:  [-0.21142923  0.6271747  -0.07855947  0.71141124  0.78791987]\n",
      "Epoch:  1 Step:  2\n",
      "Weights:  [-0.81142923  0.4071747  -0.57855947  0.56141124  0.68791987]\n",
      "Epoch:  1 Step:  7\n",
      "Weights:  [-0.18142923  0.6371747  -0.13855947  0.69141124  0.78791987]\n",
      "Epoch:  1 Step:  8\n",
      "Weights:  [-0.67142923  0.3271747  -0.28855947  0.68141124  0.68791987]\n",
      "Epoch:  1 Step:  9\n",
      "Weights:  [-0.09142923  0.5971747   0.10144053  0.80141124  0.78791987]\n",
      "Epoch:  1 Step:  10\n",
      "Weights:  [-0.74142923  0.2971747  -0.47855947  0.58141124  0.68791987]\n",
      "Epoch:  1 Step:  14\n",
      "Weights:  [-0.13142923  0.5871747  -0.00855947  0.72141124  0.78791987]\n",
      "Epoch:  1 Step:  15\n",
      "Weights:  [-0.59142923  0.2271747  -0.10855947  0.70141124  0.68791987]\n",
      "Epoch:  1 Step:  24\n",
      "Weights:  [0.06857077 0.5271747  0.33144053 0.84141124 0.78791987]\n",
      "Epoch:  1 Step:  25\n",
      "Weights:  [-0.72142923  0.1471747  -0.30855947  0.64141124  0.68791987]\n",
      "Epoch:  1 Step:  26\n",
      "Weights:  [-0.21142923  0.3971747  -0.00855947  0.75141124  0.78791987]\n",
      "Epoch:  1 Step:  29\n",
      "Weights:  [-0.84142923  0.0671747  -0.60855947  0.50141124  0.68791987]\n",
      "Epoch:  1 Step:  30\n",
      "Weights:  [-0.29142923  0.3271747  -0.16855947  0.62141124  0.78791987]\n",
      "Epoch:  1 Step:  32\n",
      "Weights:  [-0.94142923  0.0071747  -0.67855947  0.42141124  0.68791987]\n",
      "Epoch:  1 Step:  33\n",
      "Weights:  [-0.29142923  0.2871747  -0.21855947  0.57141124  0.78791987]\n",
      "Epoch:  1 Step:  34\n",
      "Weights:  [-0.77142923 -0.0128253  -0.35855947  0.56141124  0.68791987]\n",
      "Epoch:  1 Step:  36\n",
      "Weights:  [-0.08142923  0.2971747   0.13144053  0.71141124  0.78791987]\n",
      "Epoch:  1 Step:  37\n",
      "Weights:  [-0.71142923  0.0071747  -0.42855947  0.53141124  0.68791987]\n",
      "Epoch:  1 Step:  38\n",
      "Weights:  [-0.11142923  0.2771747   0.08144053  0.69141124  0.78791987]\n",
      "Epoch:  1 Step:  39\n",
      "Weights:  [-0.64142923 -0.0928253  -0.06855947  0.67141124  0.68791987]\n",
      "Epoch:  1 Step:  40\n",
      "Weights:  [-0.02142923  0.1271747   0.38144053  0.82141124  0.78791987]\n",
      "Epoch:  1 Step:  46\n",
      "Weights:  [-0.54142923 -0.2828253   0.23144053  0.81141124  0.68791987]\n",
      "Epoch:  1 Step:  49\n",
      "Weights:  [0.11857077 0.0071747  0.69144053 0.94141124 0.78791987]\n",
      "Epoch:  1 Step:  50\n",
      "Weights:  [-0.53142923 -0.2928253   0.17144053  0.74141124  0.68791987]\n",
      "Epoch:  1 Step:  53\n",
      "Weights:  [ 0.01857077 -0.0428253   0.57144053  0.87141124  0.78791987]\n",
      "Epoch:  1 Step:  54\n",
      "Weights:  [-0.62142923 -0.3528253   0.02144053  0.69141124  0.68791987]\n",
      "Epoch:  1 Step:  56\n",
      "Weights:  [-0.05142923 -0.0728253   0.47144053  0.82141124  0.78791987]\n",
      "Epoch:  1 Step:  57\n",
      "Weights:  [-0.61142923 -0.3528253  -0.01855947  0.62141124  0.68791987]\n",
      "Epoch:  1 Step:  58\n",
      "Weights:  [-0.11142923 -0.1228253   0.31144053  0.72141124  0.78791987]\n",
      "Epoch:  1 Step:  60\n",
      "Weights:  [-0.75142923 -0.4428253  -0.21855947  0.49141124  0.68791987]\n",
      "Epoch:  1 Step:  64\n",
      "Weights:  [-0.14142923 -0.1428253   0.24144053  0.63141124  0.78791987]\n",
      "Epoch:  1 Step:  65\n",
      "Weights:  [-0.64142923 -0.4728253   0.10144053  0.61141124  0.68791987]\n",
      "Epoch:  1 Step:  67\n",
      "Weights:  [-0.01142923 -0.2228253   0.59144053  0.76141124  0.78791987]\n",
      "Epoch:  1 Step:  68\n",
      "Weights:  [-0.74142923 -0.5128253  -0.03855947  0.58141124  0.68791987]\n",
      "Epoch:  1 Step:  74\n",
      "Weights:  [-0.17142923 -0.2128253   0.38144053  0.70141124  0.78791987]\n",
      "Epoch:  1 Step:  76\n",
      "Weights:  [-0.66142923 -0.4628253  -0.06855947  0.53141124  0.68791987]\n",
      "Epoch:  1 Step:  84\n",
      "Weights:  [-0.10142923 -0.2128253   0.32144053  0.64141124  0.78791987]\n",
      "Epoch:  1 Step:  85\n",
      "Weights:  [-0.56142923 -0.5328253   0.18144053  0.62141124  0.68791987]\n",
      "Epoch:  1 Step:  86\n",
      "Weights:  [-0.00142923 -0.2628253   0.60144053  0.75141124  0.78791987]\n",
      "Epoch:  1 Step:  88\n",
      "Weights:  [-0.76142923 -0.5628253  -0.05855947  0.54141124  0.68791987]\n",
      "Epoch:  1 Step:  89\n",
      "Weights:  [-0.16142923 -0.3428253   0.34144053  0.64141124  0.78791987]\n",
      "Epoch:  1 Step:  92\n",
      "Weights:  [-0.74142923 -0.6128253  -0.16855947  0.45141124  0.68791987]\n",
      "Epoch:  1 Step:  97\n",
      "Weights:  [-0.16142923 -0.3428253   0.24144053  0.55141124  0.78791987]\n",
      "Epoch:  1 Step:  99\n",
      "Weights:  [-0.83142923 -0.6528253  -0.31855947  0.31141124  0.68791987]\n",
      "Epoch:  2 Step:  7\n",
      "Weights:  [-0.20142923 -0.4228253   0.12144053  0.44141124  0.78791987]\n",
      "Epoch:  2 Step:  9\n",
      "Weights:  [ 0.37857077 -0.1528253   0.51144053  0.56141124  0.88791987]\n",
      "Epoch:  2 Step:  10\n",
      "Weights:  [-0.27142923 -0.4528253  -0.06855947  0.34141124  0.78791987]\n",
      "Epoch:  2 Step:  14\n",
      "Weights:  [ 0.33857077 -0.1628253   0.40144053  0.48141124  0.88791987]\n",
      "Epoch:  2 Step:  15\n",
      "Weights:  [-0.12142923 -0.5228253   0.30144053  0.46141124  0.78791987]\n",
      "Epoch:  2 Step:  16\n",
      "Weights:  [-0.81142923 -0.8428253  -0.26855947  0.23141124  0.68791987]\n",
      "Epoch:  2 Step:  24\n",
      "Weights:  [-0.15142923 -0.5428253   0.17144053  0.37141124  0.78791987]\n",
      "Epoch:  2 Step:  26\n",
      "Weights:  [ 0.35857077 -0.2928253   0.47144053  0.48141124  0.88791987]\n",
      "Epoch:  2 Step:  29\n",
      "Weights:  [-0.27142923 -0.6228253  -0.12855947  0.23141124  0.78791987]\n",
      "Epoch:  2 Step:  30\n",
      "Weights:  [ 0.27857077 -0.3628253   0.31144053  0.35141124  0.88791987]\n",
      "Epoch:  2 Step:  32\n",
      "Weights:  [-0.37142923 -0.6828253  -0.19855947  0.15141124  0.78791987]\n",
      "Epoch:  2 Step:  33\n",
      "Weights:  [ 0.27857077 -0.4028253   0.26144053  0.30141124  0.88791987]\n",
      "Epoch:  2 Step:  34\n",
      "Weights:  [-0.20142923 -0.7028253   0.12144053  0.29141124  0.78791987]\n",
      "Epoch:  2 Step:  36\n",
      "Weights:  [ 0.48857077 -0.3928253   0.61144053  0.44141124  0.88791987]\n",
      "Epoch:  2 Step:  37\n",
      "Weights:  [-0.14142923 -0.6828253   0.05144053  0.26141124  0.78791987]\n",
      "Epoch:  2 Step:  38\n",
      "Weights:  [ 0.45857077 -0.4128253   0.56144053  0.42141124  0.88791987]\n",
      "Epoch:  2 Step:  39\n",
      "Weights:  [-0.07142923 -0.7828253   0.41144053  0.40141124  0.78791987]\n",
      "Epoch:  2 Step:  48\n",
      "Weights:  [-0.79142923 -1.0828253  -0.16855947  0.24141124  0.68791987]\n",
      "Epoch:  2 Step:  49\n",
      "Weights:  [-0.13142923 -0.7928253   0.29144053  0.37141124  0.78791987]\n",
      "Epoch:  2 Step:  53\n",
      "Weights:  [ 0.41857077 -0.5428253   0.69144053  0.50141124  0.88791987]\n",
      "Epoch:  2 Step:  54\n",
      "Weights:  [-0.22142923 -0.8528253   0.14144053  0.32141124  0.78791987]\n",
      "Epoch:  2 Step:  56\n",
      "Weights:  [ 0.34857077 -0.5728253   0.59144053  0.45141124  0.88791987]\n",
      "Epoch:  2 Step:  57\n",
      "Weights:  [-0.21142923 -0.8528253   0.10144053  0.25141124  0.78791987]\n",
      "Epoch:  2 Step:  58\n",
      "Weights:  [ 0.28857077 -0.6228253   0.43144053  0.35141124  0.88791987]\n",
      "Epoch:  2 Step:  60\n",
      "Weights:  [-0.35142923 -0.9428253  -0.09855947  0.12141124  0.78791987]\n",
      "Epoch:  2 Step:  64\n",
      "Weights:  [ 0.25857077 -0.6428253   0.36144053  0.26141124  0.88791987]\n",
      "Epoch:  2 Step:  65\n",
      "Weights:  [-0.24142923 -0.9728253   0.22144053  0.24141124  0.78791987]\n",
      "Epoch:  2 Step:  67\n",
      "Weights:  [ 0.38857077 -0.7228253   0.71144053  0.39141124  0.88791987]\n",
      "Epoch:  2 Step:  68\n",
      "Weights:  [-0.34142923 -1.0128253   0.08144053  0.21141124  0.78791987]\n",
      "Epoch:  2 Step:  74\n",
      "Weights:  [ 0.22857077 -0.7128253   0.50144053  0.33141124  0.88791987]\n",
      "Epoch:  2 Step:  76\n",
      "Weights:  [-0.26142923 -0.9628253   0.05144053  0.16141124  0.78791987]\n",
      "Epoch:  2 Step:  84\n",
      "Weights:  [ 0.29857077 -0.7128253   0.44144053  0.27141124  0.88791987]\n",
      "Epoch:  2 Step:  85\n",
      "Weights:  [-0.16142923 -1.0328253   0.30144053  0.25141124  0.78791987]\n",
      "Epoch:  2 Step:  86\n",
      "Weights:  [ 0.39857077 -0.7628253   0.72144053  0.38141124  0.88791987]\n",
      "Epoch:  2 Step:  88\n",
      "Weights:  [-0.36142923 -1.0628253   0.06144053  0.17141124  0.78791987]\n",
      "Epoch:  2 Step:  89\n",
      "Weights:  [ 0.23857077 -0.8428253   0.46144053  0.27141124  0.88791987]\n",
      "Epoch:  2 Step:  91\n",
      "Weights:  [-0.23142923 -1.1628253   0.30144053  0.25141124  0.78791987]\n",
      "Epoch:  2 Step:  97\n",
      "Weights:  [ 0.34857077 -0.8928253   0.71144053  0.35141124  0.88791987]\n",
      "Epoch:  2 Step:  98\n",
      "Weights:  [-0.15142923 -1.2328253   0.56144053  0.33141124  0.78791987]\n",
      "Epoch:  3 Step:  2\n",
      "Weights:  [-0.75142923 -1.4528253   0.06144053  0.18141124  0.68791987]\n",
      "Epoch:  3 Step:  7\n",
      "Weights:  [-0.12142923 -1.2228253   0.50144053  0.31141124  0.78791987]\n",
      "Epoch:  3 Step:  9\n",
      "Weights:  [ 0.45857077 -0.9528253   0.89144053  0.43141124  0.88791987]\n",
      "Epoch:  3 Step:  10\n",
      "Weights:  [-0.19142923 -1.2528253   0.31144053  0.21141124  0.78791987]\n",
      "Epoch:  3 Step:  14\n",
      "Weights:  [ 0.41857077 -0.9628253   0.78144053  0.35141124  0.88791987]\n",
      "Epoch:  3 Step:  15\n",
      "Weights:  [-0.04142923 -1.3228253   0.68144053  0.33141124  0.78791987]\n",
      "Epoch:  3 Step:  16\n",
      "Weights:  [-0.73142923 -1.6428253   0.11144053  0.10141124  0.68791987]\n",
      "Epoch:  3 Step:  24\n",
      "Weights:  [-0.07142923 -1.3428253   0.55144053  0.24141124  0.78791987]\n",
      "Epoch:  3 Step:  26\n",
      "Weights:  [ 0.43857077 -1.0928253   0.85144053  0.35141124  0.88791987]\n",
      "Epoch:  3 Step:  29\n",
      "Weights:  [-0.19142923 -1.4228253   0.25144053  0.10141124  0.78791987]\n",
      "Epoch:  3 Step:  30\n",
      "Weights:  [ 0.35857077 -1.1628253   0.69144053  0.22141124  0.88791987]\n",
      "Epoch:  3 Step:  32\n",
      "Weights:  [-0.29142923 -1.4828253   0.18144053  0.02141124  0.78791987]\n",
      "Epoch:  3 Step:  33\n",
      "Weights:  [ 0.35857077 -1.2028253   0.64144053  0.17141124  0.88791987]\n",
      "Epoch:  3 Step:  35\n",
      "Weights:  [-0.41142923 -1.5028253   0.03144053 -0.05858876  0.78791987]\n",
      "Epoch:  3 Step:  36\n",
      "Weights:  [ 0.27857077 -1.1928253   0.52144053  0.09141124  0.88791987]\n",
      "Epoch:  3 Step:  37\n",
      "Weights:  [-0.35142923 -1.4828253  -0.03855947 -0.08858876  0.78791987]\n",
      "Epoch:  3 Step:  38\n",
      "Weights:  [ 0.24857077 -1.2128253   0.47144053  0.07141124  0.88791987]\n",
      "Epoch:  3 Step:  48\n",
      "Weights:  [-0.47142923 -1.5128253  -0.10855947 -0.08858876  0.78791987]\n",
      "Epoch:  3 Step:  49\n",
      "Weights:  [ 0.18857077 -1.2228253   0.35144053  0.04141124  0.88791987]\n",
      "Epoch:  3 Step:  50\n",
      "Weights:  [-0.46142923 -1.5228253  -0.16855947 -0.15858876  0.78791987]\n",
      "Epoch:  3 Step:  53\n",
      "Weights:  [ 0.08857077 -1.2728253   0.23144053 -0.02858876  0.88791987]\n",
      "Epoch:  3 Step:  56\n",
      "Weights:  [ 0.65857077 -0.9928253   0.68144053  0.10141124  0.98791987]\n",
      "Epoch:  3 Step:  57\n",
      "Weights:  [ 0.09857077 -1.2728253   0.19144053 -0.09858876  0.88791987]\n",
      "Epoch:  3 Step:  58\n",
      "Weights:  [ 0.59857077 -1.0428253   0.52144053  0.00141124  0.98791987]\n",
      "Epoch:  3 Step:  60\n",
      "Weights:  [-0.04142923 -1.3628253  -0.00855947 -0.22858876  0.88791987]\n",
      "Epoch:  3 Step:  64\n",
      "Weights:  [ 0.56857077 -1.0628253   0.45144053 -0.08858876  0.98791987]\n",
      "Epoch:  3 Step:  65\n",
      "Weights:  [ 0.06857077 -1.3928253   0.31144053 -0.10858876  0.88791987]\n",
      "Epoch:  3 Step:  67\n",
      "Weights:  [ 0.69857077 -1.1428253   0.80144053  0.04141124  0.98791987]\n",
      "Epoch:  3 Step:  68\n",
      "Weights:  [-0.03142923 -1.4328253   0.17144053 -0.13858876  0.88791987]\n",
      "Epoch:  3 Step:  74\n",
      "Weights:  [ 0.53857077 -1.1328253   0.59144053 -0.01858876  0.98791987]\n",
      "Epoch:  3 Step:  76\n",
      "Weights:  [ 0.04857077 -1.3828253   0.14144053 -0.18858876  0.88791987]\n",
      "Epoch:  3 Step:  84\n",
      "Weights:  [ 0.60857077 -1.1328253   0.53144053 -0.07858876  0.98791987]\n",
      "Epoch:  3 Step:  85\n",
      "Weights:  [ 0.14857077 -1.4528253   0.39144053 -0.09858876  0.88791987]\n",
      "Epoch:  3 Step:  86\n",
      "Weights:  [ 0.70857077 -1.1828253   0.81144053  0.03141124  0.98791987]\n",
      "Epoch:  3 Step:  88\n",
      "Weights:  [-0.05142923 -1.4828253   0.15144053 -0.17858876  0.88791987]\n",
      "Epoch:  3 Step:  89\n",
      "Weights:  [ 0.54857077 -1.2628253   0.55144053 -0.07858876  0.98791987]\n",
      "Epoch:  3 Step:  91\n",
      "Weights:  [ 0.07857077 -1.5828253   0.39144053 -0.09858876  0.88791987]\n",
      "Epoch:  3 Step:  97\n",
      "Weights:  [ 0.65857077 -1.3128253   0.80144053  0.00141124  0.98791987]\n",
      "Epoch:  3 Step:  98\n",
      "Weights:  [ 0.15857077 -1.6528253   0.65144053 -0.01858876  0.88791987]\n",
      "Epoch:  3 Step:  99\n",
      "Weights:  [-0.51142923 -1.9628253   0.09144053 -0.25858876  0.78791987]\n",
      "Epoch:  4 Step:  7\n",
      "Weights:  [ 0.11857077 -1.7328253   0.53144053 -0.12858876  0.88791987]\n",
      "Epoch:  4 Step:  9\n",
      "Weights:  [ 0.69857077 -1.4628253   0.92144053 -0.00858876  0.98791987]\n",
      "Epoch:  4 Step:  10\n",
      "Weights:  [ 0.04857077 -1.7628253   0.34144053 -0.22858876  0.88791987]\n",
      "Epoch:  4 Step:  14\n",
      "Weights:  [ 0.65857077 -1.4728253   0.81144053 -0.08858876  0.98791987]\n",
      "Epoch:  4 Step:  16\n",
      "Weights:  [-0.03142923 -1.7928253   0.24144053 -0.31858876  0.88791987]\n",
      "Epoch:  4 Step:  24\n",
      "Weights:  [ 0.62857077 -1.4928253   0.68144053 -0.17858876  0.98791987]\n",
      "Epoch:  4 Step:  25\n",
      "Weights:  [-0.16142923 -1.8728253   0.04144053 -0.37858876  0.88791987]\n",
      "Epoch:  4 Step:  26\n",
      "Weights:  [ 0.34857077 -1.6228253   0.34144053 -0.26858876  0.98791987]\n",
      "Epoch:  4 Step:  27\n",
      "Weights:  [ 1.01857077 -1.3128253   0.81144053 -0.11858876  1.08791987]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  4 Step:  29\n",
      "Weights:  [ 0.38857077 -1.6428253   0.21144053 -0.36858876  0.98791987]\n",
      "Epoch:  4 Step:  30\n",
      "Weights:  [ 0.93857077 -1.3828253   0.65144053 -0.24858876  1.08791987]\n",
      "Epoch:  4 Step:  32\n",
      "Weights:  [ 0.28857077 -1.7028253   0.14144053 -0.44858876  0.98791987]\n",
      "Epoch:  4 Step:  33\n",
      "Weights:  [ 0.93857077 -1.4228253   0.60144053 -0.29858876  1.08791987]\n",
      "Epoch:  4 Step:  34\n",
      "Weights:  [ 0.45857077 -1.7228253   0.46144053 -0.30858876  0.98791987]\n",
      "Epoch:  4 Step:  35\n",
      "Weights:  [-0.31142923 -2.0228253  -0.14855947 -0.53858876  0.88791987]\n",
      "Epoch:  4 Step:  36\n",
      "Weights:  [ 0.37857077 -1.7128253   0.34144053 -0.38858876  0.98791987]\n",
      "Epoch:  4 Step:  38\n",
      "Weights:  [ 0.97857077 -1.4428253   0.85144053 -0.22858876  1.08791987]\n",
      "Epoch:  4 Step:  39\n",
      "Weights:  [ 0.44857077 -1.8128253   0.70144053 -0.24858876  0.98791987]\n",
      "Epoch:  4 Step:  48\n",
      "Weights:  [-0.27142923 -2.1128253   0.12144053 -0.40858876  0.88791987]\n",
      "Epoch:  4 Step:  49\n",
      "Weights:  [ 0.38857077 -1.8228253   0.58144053 -0.27858876  0.98791987]\n",
      "Epoch:  4 Step:  50\n",
      "Weights:  [-0.26142923 -2.1228253   0.06144053 -0.47858876  0.88791987]\n",
      "Epoch:  4 Step:  53\n",
      "Weights:  [ 0.28857077 -1.8728253   0.46144053 -0.34858876  0.98791987]\n",
      "Epoch:  4 Step:  56\n",
      "Weights:  [ 0.85857077 -1.5928253   0.91144053 -0.21858876  1.08791987]\n",
      "Epoch:  4 Step:  57\n",
      "Weights:  [ 0.29857077 -1.8728253   0.42144053 -0.41858876  0.98791987]\n",
      "Epoch:  4 Step:  58\n",
      "Weights:  [ 0.79857077 -1.6428253   0.75144053 -0.31858876  1.08791987]\n",
      "Epoch:  4 Step:  60\n",
      "Weights:  [ 0.15857077 -1.9628253   0.22144053 -0.54858876  0.98791987]\n",
      "Epoch:  4 Step:  64\n",
      "Weights:  [ 0.76857077 -1.6628253   0.68144053 -0.40858876  1.08791987]\n",
      "Epoch:  4 Step:  65\n",
      "Weights:  [ 0.26857077 -1.9928253   0.54144053 -0.42858876  0.98791987]\n",
      "Epoch:  4 Step:  67\n",
      "Weights:  [ 0.89857077 -1.7428253   1.03144053 -0.27858876  1.08791987]\n",
      "Epoch:  4 Step:  68\n",
      "Weights:  [ 0.16857077 -2.0328253   0.40144053 -0.45858876  0.98791987]\n",
      "Epoch:  4 Step:  74\n",
      "Weights:  [ 0.73857077 -1.7328253   0.82144053 -0.33858876  1.08791987]\n",
      "Epoch:  4 Step:  76\n",
      "Weights:  [ 0.24857077 -1.9828253   0.37144053 -0.50858876  0.98791987]\n",
      "Epoch:  4 Step:  84\n",
      "Weights:  [ 0.80857077 -1.7328253   0.76144053 -0.39858876  1.08791987]\n",
      "Epoch:  4 Step:  85\n",
      "Weights:  [ 0.34857077 -2.0528253   0.62144053 -0.41858876  0.98791987]\n",
      "Epoch:  4 Step:  86\n",
      "Weights:  [ 0.90857077 -1.7828253   1.04144053 -0.28858876  1.08791987]\n",
      "Epoch:  4 Step:  88\n",
      "Weights:  [ 0.14857077 -2.0828253   0.38144053 -0.49858876  0.98791987]\n",
      "Epoch:  4 Step:  89\n",
      "Weights:  [ 0.74857077 -1.8628253   0.78144053 -0.39858876  1.08791987]\n",
      "Epoch:  4 Step:  92\n",
      "Weights:  [ 0.16857077 -2.1328253   0.27144053 -0.58858876  0.98791987]\n",
      "Epoch:  4 Step:  97\n",
      "Weights:  [ 0.74857077 -1.8628253   0.68144053 -0.48858876  1.08791987]\n",
      "Epoch:  4 Step:  99\n",
      "Weights:  [ 0.07857077 -2.1728253   0.12144053 -0.72858876  0.98791987]\n",
      "Epoch:  5 Step:  7\n",
      "Weights:  [ 0.70857077 -1.9428253   0.56144053 -0.59858876  1.08791987]\n",
      "Epoch:  5 Step:  10\n",
      "Weights:  [ 0.05857077 -2.2428253  -0.01855947 -0.81858876  0.98791987]\n",
      "Epoch:  5 Step:  14\n",
      "Weights:  [ 0.66857077 -1.9528253   0.45144053 -0.67858876  1.08791987]\n",
      "Epoch:  5 Step:  16\n",
      "Weights:  [-0.02142923 -2.2728253  -0.11855947 -0.90858876  0.98791987]\n",
      "Epoch:  5 Step:  24\n",
      "Weights:  [ 0.63857077 -1.9728253   0.32144053 -0.76858876  1.08791987]\n",
      "Epoch:  5 Step:  26\n",
      "Weights:  [ 1.14857077 -1.7228253   0.62144053 -0.65858876  1.18791987]\n",
      "Epoch:  5 Step:  29\n",
      "Weights:  [ 0.51857077 -2.0528253   0.02144053 -0.90858876  1.08791987]\n",
      "Epoch:  5 Step:  30\n",
      "Weights:  [ 1.06857077 -1.7928253   0.46144053 -0.78858876  1.18791987]\n",
      "Epoch:  5 Step:  32\n",
      "Weights:  [ 0.41857077 -2.1128253  -0.04855947 -0.98858876  1.08791987]\n",
      "Epoch:  5 Step:  33\n",
      "Weights:  [ 1.06857077 -1.8328253   0.41144053 -0.83858876  1.18791987]\n",
      "Epoch:  5 Step:  34\n",
      "Weights:  [ 0.58857077 -2.1328253   0.27144053 -0.84858876  1.08791987]\n",
      "Epoch:  5 Step:  36\n",
      "Weights:  [ 1.27857077 -1.8228253   0.76144053 -0.69858876  1.18791987]\n",
      "Epoch:  5 Step:  37\n",
      "Weights:  [ 0.64857077 -2.1128253   0.20144053 -0.87858876  1.08791987]\n",
      "Epoch:  5 Step:  38\n",
      "Weights:  [ 1.24857077 -1.8428253   0.71144053 -0.71858876  1.18791987]\n",
      "Epoch:  5 Step:  39\n",
      "Weights:  [ 0.71857077 -2.2128253   0.56144053 -0.73858876  1.08791987]\n",
      "Epoch:  5 Step:  48\n",
      "Weights:  [-1.42922722e-03 -2.51282530e+00 -1.85594682e-02 -8.98588765e-01\n",
      "  9.87919869e-01]\n",
      "Epoch:  5 Step:  49\n",
      "Weights:  [ 0.65857077 -2.2228253   0.44144053 -0.76858876  1.08791987]\n",
      "Epoch:  5 Step:  53\n",
      "Weights:  [ 1.20857077 -1.9728253   0.84144053 -0.63858876  1.18791987]\n",
      "Epoch:  5 Step:  54\n",
      "Weights:  [ 0.56857077 -2.2828253   0.29144053 -0.81858876  1.08791987]\n",
      "Epoch:  5 Step:  56\n",
      "Weights:  [ 1.13857077 -2.0028253   0.74144053 -0.68858876  1.18791987]\n",
      "Epoch:  5 Step:  57\n",
      "Weights:  [ 0.57857077 -2.2828253   0.25144053 -0.88858876  1.08791987]\n",
      "Epoch:  5 Step:  58\n",
      "Weights:  [ 1.07857077 -2.0528253   0.58144053 -0.78858876  1.18791987]\n",
      "Epoch:  5 Step:  60\n",
      "Weights:  [ 0.43857077 -2.3728253   0.05144053 -1.01858876  1.08791987]\n",
      "Epoch:  5 Step:  64\n",
      "Weights:  [ 1.04857077 -2.0728253   0.51144053 -0.87858876  1.18791987]\n",
      "Epoch:  5 Step:  65\n",
      "Weights:  [ 0.54857077 -2.4028253   0.37144053 -0.89858876  1.08791987]\n",
      "Epoch:  5 Step:  67\n",
      "Weights:  [ 1.17857077 -2.1528253   0.86144053 -0.74858876  1.18791987]\n",
      "Epoch:  5 Step:  68\n",
      "Weights:  [ 0.44857077 -2.4428253   0.23144053 -0.92858876  1.08791987]\n",
      "Epoch:  5 Step:  74\n",
      "Weights:  [ 1.01857077 -2.1428253   0.65144053 -0.80858876  1.18791987]\n",
      "Epoch:  5 Step:  76\n",
      "Weights:  [ 0.52857077 -2.3928253   0.20144053 -0.97858876  1.08791987]\n",
      "Epoch:  5 Step:  84\n",
      "Weights:  [ 1.08857077 -2.1428253   0.59144053 -0.86858876  1.18791987]\n",
      "Epoch:  5 Step:  88\n",
      "Weights:  [ 0.32857077 -2.4428253  -0.06855947 -1.07858876  1.08791987]\n",
      "Epoch:  5 Step:  89\n",
      "Weights:  [ 0.92857077 -2.2228253   0.33144053 -0.97858876  1.18791987]\n",
      "Epoch:  5 Step:  92\n",
      "Weights:  [ 0.34857077 -2.4928253  -0.17855947 -1.16858876  1.08791987]\n",
      "Epoch:  5 Step:  97\n",
      "Weights:  [ 0.92857077 -2.2228253   0.23144053 -1.06858876  1.18791987]\n",
      "Epoch:  6 Step:  2\n",
      "Weights:  [ 0.32857077 -2.4428253  -0.26855947 -1.21858876  1.08791987]\n",
      "Epoch:  6 Step:  7\n",
      "Weights:  [ 0.95857077 -2.2128253   0.17144053 -1.08858876  1.18791987]\n",
      "Epoch:  6 Step:  11\n",
      "Weights:  [ 0.31857077 -2.4828253  -0.35855947 -1.27858876  1.08791987]\n",
      "Epoch:  6 Step:  14\n",
      "Weights:  [ 0.92857077 -2.1928253   0.11144053 -1.13858876  1.18791987]\n",
      "Epoch:  6 Step:  24\n",
      "Weights:  [ 1.58857077 -1.8928253   0.55144053 -0.99858876  1.28791987]\n",
      "Epoch:  6 Step:  25\n",
      "Weights:  [ 0.79857077 -2.2728253  -0.08855947 -1.19858876  1.18791987]\n",
      "Epoch:  6 Step:  26\n",
      "Weights:  [ 1.30857077 -2.0228253   0.21144053 -1.08858876  1.28791987]\n",
      "Epoch:  6 Step:  29\n",
      "Weights:  [ 0.67857077 -2.3528253  -0.38855947 -1.33858876  1.18791987]\n",
      "Epoch:  6 Step:  30\n",
      "Weights:  [ 1.22857077 -2.0928253   0.05144053 -1.21858876  1.28791987]\n",
      "Epoch:  6 Step:  32\n",
      "Weights:  [ 0.57857077 -2.4128253  -0.45855947 -1.41858876  1.18791987]\n",
      "Epoch:  6 Step:  33\n",
      "Weights:  [ 1.22857077e+00 -2.13282530e+00  1.44053178e-03 -1.26858876e+00\n",
      "  1.28791987e+00]\n",
      "Epoch:  6 Step:  34\n",
      "Weights:  [ 0.74857077 -2.4328253  -0.13855947 -1.27858876  1.18791987]\n",
      "Epoch:  6 Step:  36\n",
      "Weights:  [ 1.43857077 -2.1228253   0.35144053 -1.12858876  1.28791987]\n",
      "Epoch:  6 Step:  37\n",
      "Weights:  [ 0.80857077 -2.4128253  -0.20855947 -1.30858876  1.18791987]\n",
      "Epoch:  6 Step:  38\n",
      "Weights:  [ 1.40857077 -2.1428253   0.30144053 -1.14858876  1.28791987]\n",
      "Epoch:  6 Step:  39\n",
      "Weights:  [ 0.87857077 -2.5128253   0.15144053 -1.16858876  1.18791987]\n",
      "Epoch:  6 Step:  41\n",
      "Weights:  [ 1.44857077 -2.2228253   0.57144053 -1.03858876  1.28791987]\n",
      "Epoch:  6 Step:  46\n",
      "Weights:  [ 0.92857077 -2.6328253   0.42144053 -1.04858876  1.18791987]\n",
      "Epoch:  6 Step:  48\n",
      "Weights:  [ 0.20857077 -2.9328253  -0.15855947 -1.20858876  1.08791987]\n",
      "Epoch:  6 Step:  49\n",
      "Weights:  [ 0.86857077 -2.6428253   0.30144053 -1.07858876  1.18791987]\n",
      "Epoch:  6 Step:  53\n",
      "Weights:  [ 1.41857077 -2.3928253   0.70144053 -0.94858876  1.28791987]\n",
      "Epoch:  6 Step:  54\n",
      "Weights:  [ 0.77857077 -2.7028253   0.15144053 -1.12858876  1.18791987]\n",
      "Epoch:  6 Step:  56\n",
      "Weights:  [ 1.34857077 -2.4228253   0.60144053 -0.99858876  1.28791987]\n",
      "Epoch:  6 Step:  57\n",
      "Weights:  [ 0.78857077 -2.7028253   0.11144053 -1.19858876  1.18791987]\n",
      "Epoch:  6 Step:  58\n",
      "Weights:  [ 1.28857077 -2.4728253   0.44144053 -1.09858876  1.28791987]\n",
      "Epoch:  6 Step:  60\n",
      "Weights:  [ 0.64857077 -2.7928253  -0.08855947 -1.32858876  1.18791987]\n",
      "Epoch:  6 Step:  64\n",
      "Weights:  [ 1.25857077 -2.4928253   0.37144053 -1.18858876  1.28791987]\n",
      "Epoch:  6 Step:  68\n",
      "Weights:  [ 0.52857077 -2.7828253  -0.25855947 -1.36858876  1.18791987]\n",
      "Epoch:  6 Step:  74\n",
      "Weights:  [ 1.09857077 -2.4828253   0.16144053 -1.24858876  1.28791987]\n",
      "Epoch:  6 Step:  75\n",
      "Weights:  [ 1.68857077 -2.1828253   0.58144053 -1.09858876  1.38791987]\n",
      "Epoch:  6 Step:  76\n",
      "Weights:  [ 1.19857077 -2.4328253   0.13144053 -1.26858876  1.28791987]\n",
      "Epoch:  6 Step:  77\n",
      "Weights:  [ 0.55857077 -2.7128253  -0.42855947 -1.48858876  1.18791987]\n",
      "Epoch:  6 Step:  84\n",
      "Weights:  [ 1.11857077 -2.4628253  -0.03855947 -1.37858876  1.28791987]\n",
      "Epoch:  6 Step:  86\n",
      "Weights:  [ 1.67857077 -2.1928253   0.38144053 -1.24858876  1.38791987]\n",
      "Epoch:  6 Step:  88\n",
      "Weights:  [ 0.91857077 -2.4928253  -0.27855947 -1.45858876  1.28791987]\n",
      "Epoch:  6 Step:  89\n",
      "Weights:  [ 1.51857077 -2.2728253   0.12144053 -1.35858876  1.38791987]\n",
      "Epoch:  6 Step:  91\n",
      "Weights:  [ 1.04857077 -2.5928253  -0.03855947 -1.37858876  1.28791987]\n",
      "Epoch:  6 Step:  97\n",
      "Weights:  [ 1.62857077 -2.3228253   0.37144053 -1.27858876  1.38791987]\n",
      "Epoch:  6 Step:  98\n",
      "Weights:  [ 1.12857077 -2.6628253   0.22144053 -1.29858876  1.28791987]\n",
      "Epoch:  7 Step:  2\n",
      "Weights:  [ 0.52857077 -2.8828253  -0.27855947 -1.44858876  1.18791987]\n",
      "Epoch:  7 Step:  7\n",
      "Weights:  [ 1.15857077 -2.6528253   0.16144053 -1.31858876  1.28791987]\n",
      "Epoch:  7 Step:  9\n",
      "Weights:  [ 1.73857077 -2.3828253   0.55144053 -1.19858876  1.38791987]\n",
      "Epoch:  7 Step:  10\n",
      "Weights:  [ 1.08857077 -2.6828253  -0.02855947 -1.41858876  1.28791987]\n",
      "Epoch:  7 Step:  14\n",
      "Weights:  [ 1.69857077 -2.3928253   0.44144053 -1.27858876  1.38791987]\n",
      "Epoch:  7 Step:  15\n",
      "Weights:  [ 1.23857077 -2.7528253   0.34144053 -1.29858876  1.28791987]\n",
      "Epoch:  7 Step:  19\n",
      "Weights:  [ 0.52857077 -3.0528253  -0.24855947 -1.50858876  1.18791987]\n",
      "Epoch:  7 Step:  24\n",
      "Weights:  [ 1.18857077 -2.7528253   0.19144053 -1.36858876  1.28791987]\n",
      "Epoch:  7 Step:  26\n",
      "Weights:  [ 1.69857077 -2.5028253   0.49144053 -1.25858876  1.38791987]\n",
      "Epoch:  7 Step:  29\n",
      "Weights:  [ 1.06857077 -2.8328253  -0.10855947 -1.50858876  1.28791987]\n",
      "Epoch:  7 Step:  30\n",
      "Weights:  [ 1.61857077 -2.5728253   0.33144053 -1.38858876  1.38791987]\n",
      "Epoch:  7 Step:  32\n",
      "Weights:  [ 0.96857077 -2.8928253  -0.17855947 -1.58858876  1.28791987]\n",
      "Epoch:  7 Step:  33\n",
      "Weights:  [ 1.61857077 -2.6128253   0.28144053 -1.43858876  1.38791987]\n",
      "Epoch:  7 Step:  34\n",
      "Weights:  [ 1.13857077 -2.9128253   0.14144053 -1.44858876  1.28791987]\n",
      "Epoch:  7 Step:  36\n",
      "Weights:  [ 1.82857077 -2.6028253   0.63144053 -1.29858876  1.38791987]\n",
      "Epoch:  7 Step:  37\n",
      "Weights:  [ 1.19857077 -2.8928253   0.07144053 -1.47858876  1.28791987]\n",
      "Epoch:  7 Step:  38\n",
      "Weights:  [ 1.79857077 -2.6228253   0.58144053 -1.31858876  1.38791987]\n",
      "Epoch:  7 Step:  39\n",
      "Weights:  [ 1.26857077 -2.9928253   0.43144053 -1.33858876  1.28791987]\n",
      "Epoch:  7 Step:  41\n",
      "Weights:  [ 1.83857077 -2.7028253   0.85144053 -1.20858876  1.38791987]\n",
      "Epoch:  7 Step:  46\n",
      "Weights:  [ 1.31857077 -3.1128253   0.70144053 -1.21858876  1.28791987]\n",
      "Epoch:  7 Step:  48\n",
      "Weights:  [ 0.59857077 -3.4128253   0.12144053 -1.37858876  1.18791987]\n",
      "Epoch:  7 Step:  49\n",
      "Weights:  [ 1.25857077 -3.1228253   0.58144053 -1.24858876  1.28791987]\n",
      "Epoch:  7 Step:  50\n",
      "Weights:  [ 0.60857077 -3.4228253   0.06144053 -1.44858876  1.18791987]\n",
      "Epoch:  7 Step:  53\n",
      "Weights:  [ 1.15857077 -3.1728253   0.46144053 -1.31858876  1.28791987]\n",
      "Epoch:  7 Step:  56\n",
      "Weights:  [ 1.72857077 -2.8928253   0.91144053 -1.18858876  1.38791987]\n",
      "Epoch:  7 Step:  57\n",
      "Weights:  [ 1.16857077 -3.1728253   0.42144053 -1.38858876  1.28791987]\n",
      "Epoch:  7 Step:  58\n",
      "Weights:  [ 1.66857077 -2.9428253   0.75144053 -1.28858876  1.38791987]\n",
      "Epoch:  7 Step:  60\n",
      "Weights:  [ 1.02857077 -3.2628253   0.22144053 -1.51858876  1.28791987]\n",
      "Epoch:  7 Step:  64\n",
      "Weights:  [ 1.63857077 -2.9628253   0.68144053 -1.37858876  1.38791987]\n",
      "Epoch:  7 Step:  65\n",
      "Weights:  [ 1.13857077 -3.2928253   0.54144053 -1.39858876  1.28791987]\n",
      "Epoch:  7 Step:  68\n",
      "Weights:  [ 0.40857077 -3.5828253  -0.08855947 -1.57858876  1.18791987]\n",
      "Epoch:  7 Step:  74\n",
      "Weights:  [ 0.97857077 -3.2828253   0.33144053 -1.45858876  1.28791987]\n",
      "Epoch:  7 Step:  75\n",
      "Weights:  [ 1.56857077 -2.9828253   0.75144053 -1.30858876  1.38791987]\n",
      "Epoch:  7 Step:  76\n",
      "Weights:  [ 1.07857077 -3.2328253   0.30144053 -1.47858876  1.28791987]\n",
      "Epoch:  7 Step:  84\n",
      "Weights:  [ 1.63857077 -2.9828253   0.69144053 -1.36858876  1.38791987]\n",
      "Epoch:  7 Step:  85\n",
      "Weights:  [ 1.17857077 -3.3028253   0.55144053 -1.38858876  1.28791987]\n",
      "Epoch:  7 Step:  86\n",
      "Weights:  [ 1.73857077 -3.0328253   0.97144053 -1.25858876  1.38791987]\n",
      "Epoch:  7 Step:  88\n",
      "Weights:  [ 0.97857077 -3.3328253   0.31144053 -1.46858876  1.28791987]\n",
      "Epoch:  7 Step:  89\n",
      "Weights:  [ 1.57857077 -3.1128253   0.71144053 -1.36858876  1.38791987]\n",
      "Epoch:  7 Step:  92\n",
      "Weights:  [ 0.99857077 -3.3828253   0.20144053 -1.55858876  1.28791987]\n",
      "Epoch:  7 Step:  97\n",
      "Weights:  [ 1.57857077 -3.1128253   0.61144053 -1.45858876  1.38791987]\n",
      "Epoch:  7 Step:  99\n",
      "Weights:  [ 0.90857077 -3.4228253   0.05144053 -1.69858876  1.28791987]\n",
      "Epoch:  8 Step:  7\n",
      "Weights:  [ 1.53857077 -3.1928253   0.49144053 -1.56858876  1.38791987]\n",
      "Epoch:  8 Step:  10\n",
      "Weights:  [ 0.88857077 -3.4928253  -0.08855947 -1.78858876  1.28791987]\n",
      "Epoch:  8 Step:  14\n",
      "Weights:  [ 1.49857077 -3.2028253   0.38144053 -1.64858876  1.38791987]\n",
      "Epoch:  8 Step:  19\n",
      "Weights:  [ 0.78857077 -3.5028253  -0.20855947 -1.85858876  1.28791987]\n",
      "Epoch:  8 Step:  24\n",
      "Weights:  [ 1.44857077 -3.2028253   0.23144053 -1.71858876  1.38791987]\n",
      "Epoch:  8 Step:  26\n",
      "Weights:  [ 1.95857077 -2.9528253   0.53144053 -1.60858876  1.48791987]\n",
      "Epoch:  8 Step:  29\n",
      "Weights:  [ 1.32857077 -3.2828253  -0.06855947 -1.85858876  1.38791987]\n",
      "Epoch:  8 Step:  30\n",
      "Weights:  [ 1.87857077 -3.0228253   0.37144053 -1.73858876  1.48791987]\n",
      "Epoch:  8 Step:  32\n",
      "Weights:  [ 1.22857077 -3.3428253  -0.13855947 -1.93858876  1.38791987]\n",
      "Epoch:  8 Step:  33\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights:  [ 1.87857077 -3.0628253   0.32144053 -1.78858876  1.48791987]\n",
      "Epoch:  8 Step:  34\n",
      "Weights:  [ 1.39857077 -3.3628253   0.18144053 -1.79858876  1.38791987]\n",
      "Epoch:  8 Step:  36\n",
      "Weights:  [ 2.08857077 -3.0528253   0.67144053 -1.64858876  1.48791987]\n",
      "Epoch:  8 Step:  37\n",
      "Weights:  [ 1.45857077 -3.3428253   0.11144053 -1.82858876  1.38791987]\n",
      "Epoch:  8 Step:  38\n",
      "Weights:  [ 2.05857077 -3.0728253   0.62144053 -1.66858876  1.48791987]\n",
      "Epoch:  8 Step:  39\n",
      "Weights:  [ 1.52857077 -3.4428253   0.47144053 -1.68858876  1.38791987]\n",
      "Epoch:  8 Step:  41\n",
      "Weights:  [ 2.09857077 -3.1528253   0.89144053 -1.55858876  1.48791987]\n",
      "Epoch:  8 Step:  46\n",
      "Weights:  [ 1.57857077 -3.5628253   0.74144053 -1.56858876  1.38791987]\n",
      "Epoch:  8 Step:  48\n",
      "Weights:  [ 0.85857077 -3.8628253   0.16144053 -1.72858876  1.28791987]\n",
      "Epoch:  8 Step:  49\n",
      "Weights:  [ 1.51857077 -3.5728253   0.62144053 -1.59858876  1.38791987]\n",
      "Epoch:  8 Step:  50\n",
      "Weights:  [ 0.86857077 -3.8728253   0.10144053 -1.79858876  1.28791987]\n",
      "Epoch:  8 Step:  53\n",
      "Weights:  [ 1.41857077 -3.6228253   0.50144053 -1.66858876  1.38791987]\n",
      "Epoch:  8 Step:  56\n",
      "Weights:  [ 1.98857077 -3.3428253   0.95144053 -1.53858876  1.48791987]\n",
      "Epoch:  8 Step:  57\n",
      "Weights:  [ 1.42857077 -3.6228253   0.46144053 -1.73858876  1.38791987]\n",
      "Epoch:  8 Step:  58\n",
      "Weights:  [ 1.92857077 -3.3928253   0.79144053 -1.63858876  1.48791987]\n",
      "Epoch:  8 Step:  60\n",
      "Weights:  [ 1.28857077 -3.7128253   0.26144053 -1.86858876  1.38791987]\n",
      "Epoch:  8 Step:  64\n",
      "Weights:  [ 1.89857077 -3.4128253   0.72144053 -1.72858876  1.48791987]\n",
      "Epoch:  8 Step:  65\n",
      "Weights:  [ 1.39857077 -3.7428253   0.58144053 -1.74858876  1.38791987]\n",
      "Epoch:  8 Step:  68\n",
      "Weights:  [ 0.66857077 -4.0328253  -0.04855947 -1.92858876  1.28791987]\n",
      "Epoch:  8 Step:  74\n",
      "Weights:  [ 1.23857077 -3.7328253   0.37144053 -1.80858876  1.38791987]\n",
      "Epoch:  8 Step:  75\n",
      "Weights:  [ 1.82857077 -3.4328253   0.79144053 -1.65858876  1.48791987]\n",
      "Epoch:  8 Step:  76\n",
      "Weights:  [ 1.33857077 -3.6828253   0.34144053 -1.82858876  1.38791987]\n",
      "Epoch:  8 Step:  84\n",
      "Weights:  [ 1.89857077 -3.4328253   0.73144053 -1.71858876  1.48791987]\n",
      "Epoch:  8 Step:  88\n",
      "Weights:  [ 1.13857077 -3.7328253   0.07144053 -1.92858876  1.38791987]\n",
      "Epoch:  8 Step:  89\n",
      "Weights:  [ 1.73857077 -3.5128253   0.47144053 -1.82858876  1.48791987]\n",
      "Epoch:  8 Step:  92\n",
      "Weights:  [ 1.15857077 -3.7828253  -0.03855947 -2.01858876  1.38791987]\n",
      "Epoch:  8 Step:  97\n",
      "Weights:  [ 1.73857077 -3.5128253   0.37144053 -1.91858876  1.48791987]\n",
      "Epoch:  8 Step:  100\n",
      "Weights:  [ 1.05857077 -3.8128253  -0.17855947 -2.12858876  1.38791987]\n",
      "Epoch:  9 Step:  7\n",
      "Weights:  [ 1.68857077 -3.5828253   0.26144053 -1.99858876  1.48791987]\n",
      "Epoch:  9 Step:  11\n",
      "Weights:  [ 1.04857077 -3.8528253  -0.26855947 -2.18858876  1.38791987]\n",
      "Epoch:  9 Step:  14\n",
      "Weights:  [ 1.65857077 -3.5628253   0.20144053 -2.04858876  1.48791987]\n",
      "Epoch:  9 Step:  22\n",
      "Weights:  [ 1.02857077 -3.8128253  -0.29855947 -2.23858876  1.38791987]\n",
      "Epoch:  9 Step:  24\n",
      "Weights:  [ 1.68857077 -3.5128253   0.14144053 -2.09858876  1.48791987]\n",
      "Epoch:  9 Step:  26\n",
      "Weights:  [ 2.19857077 -3.2628253   0.44144053 -1.98858876  1.58791987]\n",
      "Epoch:  9 Step:  29\n",
      "Weights:  [ 1.56857077 -3.5928253  -0.15855947 -2.23858876  1.48791987]\n",
      "Epoch:  9 Step:  30\n",
      "Weights:  [ 2.11857077 -3.3328253   0.28144053 -2.11858876  1.58791987]\n",
      "Epoch:  9 Step:  32\n",
      "Weights:  [ 1.46857077 -3.6528253  -0.22855947 -2.31858876  1.48791987]\n",
      "Epoch:  9 Step:  33\n",
      "Weights:  [ 2.11857077 -3.3728253   0.23144053 -2.16858876  1.58791987]\n",
      "Epoch:  9 Step:  34\n",
      "Weights:  [ 1.63857077 -3.6728253   0.09144053 -2.17858876  1.48791987]\n",
      "Epoch:  9 Step:  36\n",
      "Weights:  [ 2.32857077 -3.3628253   0.58144053 -2.02858876  1.58791987]\n",
      "Epoch:  9 Step:  37\n",
      "Weights:  [ 1.69857077 -3.6528253   0.02144053 -2.20858876  1.48791987]\n",
      "Epoch:  9 Step:  38\n",
      "Weights:  [ 2.29857077 -3.3828253   0.53144053 -2.04858876  1.58791987]\n",
      "Epoch:  9 Step:  39\n",
      "Weights:  [ 1.76857077 -3.7528253   0.38144053 -2.06858876  1.48791987]\n",
      "Epoch:  9 Step:  41\n",
      "Weights:  [ 2.33857077 -3.4628253   0.80144053 -1.93858876  1.58791987]\n",
      "Epoch:  9 Step:  46\n",
      "Weights:  [ 1.81857077 -3.8728253   0.65144053 -1.94858876  1.48791987]\n",
      "Epoch:  9 Step:  48\n",
      "Weights:  [ 1.09857077 -4.1728253   0.07144053 -2.10858876  1.38791987]\n",
      "Epoch:  9 Step:  49\n",
      "Weights:  [ 1.75857077 -3.8828253   0.53144053 -1.97858876  1.48791987]\n",
      "Epoch:  9 Step:  50\n",
      "Weights:  [ 1.10857077 -4.1828253   0.01144053 -2.17858876  1.38791987]\n",
      "Epoch:  9 Step:  53\n",
      "Weights:  [ 1.65857077 -3.9328253   0.41144053 -2.04858876  1.48791987]\n",
      "Epoch:  9 Step:  56\n",
      "Weights:  [ 2.22857077 -3.6528253   0.86144053 -1.91858876  1.58791987]\n",
      "Epoch:  9 Step:  57\n",
      "Weights:  [ 1.66857077 -3.9328253   0.37144053 -2.11858876  1.48791987]\n",
      "Epoch:  9 Step:  58\n",
      "Weights:  [ 2.16857077 -3.7028253   0.70144053 -2.01858876  1.58791987]\n",
      "Epoch:  9 Step:  60\n",
      "Weights:  [ 1.52857077 -4.0228253   0.17144053 -2.24858876  1.48791987]\n",
      "Epoch:  9 Step:  64\n",
      "Weights:  [ 2.13857077 -3.7228253   0.63144053 -2.10858876  1.58791987]\n",
      "Epoch:  9 Step:  65\n",
      "Weights:  [ 1.63857077 -4.0528253   0.49144053 -2.12858876  1.48791987]\n",
      "Epoch:  9 Step:  68\n",
      "Weights:  [ 0.90857077 -4.3428253  -0.13855947 -2.30858876  1.38791987]\n",
      "Epoch:  9 Step:  74\n",
      "Weights:  [ 1.47857077 -4.0428253   0.28144053 -2.18858876  1.48791987]\n",
      "Epoch:  9 Step:  75\n",
      "Weights:  [ 2.06857077 -3.7428253   0.70144053 -2.03858876  1.58791987]\n",
      "Epoch:  9 Step:  76\n",
      "Weights:  [ 1.57857077 -3.9928253   0.25144053 -2.20858876  1.48791987]\n",
      "Epoch:  9 Step:  84\n",
      "Weights:  [ 2.13857077 -3.7428253   0.64144053 -2.09858876  1.58791987]\n",
      "Epoch:  9 Step:  88\n",
      "Weights:  [ 1.37857077 -4.0428253  -0.01855947 -2.30858876  1.48791987]\n",
      "Epoch:  9 Step:  89\n",
      "Weights:  [ 1.97857077 -3.8228253   0.38144053 -2.20858876  1.58791987]\n",
      "Epoch:  9 Step:  92\n",
      "Weights:  [ 1.39857077 -4.0928253  -0.12855947 -2.39858876  1.48791987]\n",
      "Epoch:  9 Step:  97\n",
      "Weights:  [ 1.97857077 -3.8228253   0.28144053 -2.29858876  1.58791987]\n",
      "Epoch:  9 Step:  100\n",
      "Weights:  [ 1.29857077 -4.1228253  -0.26855947 -2.50858876  1.48791987]\n",
      "Epoch:  10 Step:  7\n",
      "Weights:  [ 1.92857077 -3.8928253   0.17144053 -2.37858876  1.58791987]\n",
      "Epoch:  10 Step:  12\n",
      "Weights:  [ 1.31857077 -4.1528253  -0.38855947 -2.51858876  1.48791987]\n",
      "Epoch:  10 Step:  14\n",
      "Weights:  [ 1.92857077 -3.8628253   0.08144053 -2.37858876  1.58791987]\n",
      "Epoch:  10 Step:  24\n",
      "Weights:  [ 2.58857077 -3.5628253   0.52144053 -2.23858876  1.68791987]\n",
      "Epoch:  10 Step:  25\n",
      "Weights:  [ 1.79857077 -3.9428253  -0.11855947 -2.43858876  1.58791987]\n",
      "Epoch:  10 Step:  26\n",
      "Weights:  [ 2.30857077 -3.6928253   0.18144053 -2.32858876  1.68791987]\n",
      "Epoch:  10 Step:  32\n",
      "Weights:  [ 1.65857077 -4.0128253  -0.32855947 -2.52858876  1.58791987]\n",
      "Epoch:  10 Step:  33\n",
      "Weights:  [ 2.30857077 -3.7328253   0.13144053 -2.37858876  1.68791987]\n",
      "Epoch:  10 Step:  34\n",
      "Weights:  [ 1.82857077 -4.0328253  -0.00855947 -2.38858876  1.58791987]\n",
      "Epoch:  10 Step:  36\n",
      "Weights:  [ 2.51857077 -3.7228253   0.48144053 -2.23858876  1.68791987]\n",
      "Epoch:  10 Step:  37\n",
      "Weights:  [ 1.88857077 -4.0128253  -0.07855947 -2.41858876  1.58791987]\n",
      "Epoch:  10 Step:  38\n",
      "Weights:  [ 2.48857077 -3.7428253   0.43144053 -2.25858876  1.68791987]\n",
      "Epoch:  10 Step:  39\n",
      "Weights:  [ 1.95857077 -4.1128253   0.28144053 -2.27858876  1.58791987]\n",
      "Epoch:  10 Step:  41\n",
      "Weights:  [ 2.52857077 -3.8228253   0.70144053 -2.14858876  1.68791987]\n",
      "Epoch:  10 Step:  46\n",
      "Weights:  [ 2.00857077 -4.2328253   0.55144053 -2.15858876  1.58791987]\n",
      "Epoch:  10 Step:  48\n",
      "Weights:  [ 1.28857077 -4.5328253  -0.02855947 -2.31858876  1.48791987]\n",
      "Epoch:  10 Step:  49\n",
      "Weights:  [ 1.94857077 -4.2428253   0.43144053 -2.18858876  1.58791987]\n",
      "Epoch:  10 Step:  56\n",
      "Weights:  [ 2.51857077 -3.9628253   0.88144053 -2.05858876  1.68791987]\n",
      "Epoch:  10 Step:  57\n",
      "Weights:  [ 1.95857077 -4.2428253   0.39144053 -2.25858876  1.58791987]\n",
      "Epoch:  10 Step:  64\n",
      "Weights:  [ 2.56857077 -3.9428253   0.85144053 -2.11858876  1.68791987]\n",
      "Epoch:  10 Step:  65\n",
      "Weights:  [ 2.06857077 -4.2728253   0.71144053 -2.13858876  1.58791987]\n",
      "Epoch:  10 Step:  68\n",
      "Weights:  [ 1.33857077 -4.5628253   0.08144053 -2.31858876  1.48791987]\n",
      "Epoch:  10 Step:  74\n",
      "Weights:  [ 1.90857077 -4.2628253   0.50144053 -2.19858876  1.58791987]\n",
      "Epoch:  10 Step:  75\n",
      "Weights:  [ 2.49857077 -3.9628253   0.92144053 -2.04858876  1.68791987]\n",
      "Epoch:  10 Step:  76\n",
      "Weights:  [ 2.00857077 -4.2128253   0.47144053 -2.21858876  1.58791987]\n",
      "Epoch:  10 Step:  77\n",
      "Weights:  [ 1.36857077 -4.4928253  -0.08855947 -2.43858876  1.48791987]\n",
      "Epoch:  10 Step:  84\n",
      "Weights:  [ 1.92857077 -4.2428253   0.30144053 -2.32858876  1.58791987]\n",
      "Epoch:  10 Step:  86\n",
      "Weights:  [ 2.48857077 -3.9728253   0.72144053 -2.19858876  1.68791987]\n",
      "Epoch:  10 Step:  88\n",
      "Weights:  [ 1.72857077 -4.2728253   0.06144053 -2.40858876  1.58791987]\n",
      "Epoch:  10 Step:  90\n",
      "Weights:  [ 2.29857077 -4.0128253   0.41144053 -2.30858876  1.68791987]\n",
      "Epoch:  10 Step:  92\n",
      "Weights:  [ 1.71857077 -4.2828253  -0.09855947 -2.49858876  1.58791987]\n",
      "Epoch:  10 Step:  97\n",
      "Weights:  [ 2.29857077 -4.0128253   0.31144053 -2.39858876  1.68791987]\n",
      "Epoch:  10 Step:  99\n",
      "Weights:  [ 1.62857077 -4.3228253  -0.24855947 -2.63858876  1.58791987]\n",
      "Epoch:  11 Step:  7\n",
      "Weights:  [ 2.25857077 -4.0928253   0.19144053 -2.50858876  1.68791987]\n",
      "Epoch:  11 Step:  8\n",
      "Weights:  [ 1.76857077 -4.4028253   0.04144053 -2.51858876  1.58791987]\n",
      "Epoch:  11 Step:  9\n",
      "Weights:  [ 2.34857077 -4.1328253   0.43144053 -2.39858876  1.68791987]\n",
      "Epoch:  11 Step:  10\n",
      "Weights:  [ 1.69857077 -4.4328253  -0.14855947 -2.61858876  1.58791987]\n",
      "Epoch:  11 Step:  14\n",
      "Weights:  [ 2.30857077 -4.1428253   0.32144053 -2.47858876  1.68791987]\n",
      "Epoch:  11 Step:  16\n",
      "Weights:  [ 1.61857077 -4.4628253  -0.24855947 -2.70858876  1.58791987]\n",
      "Epoch:  11 Step:  24\n",
      "Weights:  [ 2.27857077 -4.1628253   0.19144053 -2.56858876  1.68791987]\n",
      "Epoch:  11 Step:  31\n",
      "Weights:  [ 2.79857077 -3.8928253   0.58144053 -2.42858876  1.78791987]\n",
      "Epoch:  11 Step:  32\n",
      "Weights:  [ 2.14857077 -4.2128253   0.07144053 -2.62858876  1.68791987]\n",
      "Epoch:  11 Step:  36\n",
      "Weights:  [ 2.83857077 -3.9028253   0.56144053 -2.47858876  1.78791987]\n",
      "Epoch:  11 Step:  37\n",
      "Weights:  [ 2.20857077e+00 -4.19282530e+00  1.44053178e-03 -2.65858876e+00\n",
      "  1.68791987e+00]\n",
      "Epoch:  11 Step:  38\n",
      "Weights:  [ 2.80857077 -3.9228253   0.51144053 -2.49858876  1.78791987]\n",
      "Epoch:  11 Step:  39\n",
      "Weights:  [ 2.27857077 -4.2928253   0.36144053 -2.51858876  1.68791987]\n",
      "Epoch:  11 Step:  48\n",
      "Weights:  [ 1.55857077 -4.5928253  -0.21855947 -2.67858876  1.58791987]\n",
      "Epoch:  11 Step:  49\n",
      "Weights:  [ 2.21857077 -4.3028253   0.24144053 -2.54858876  1.68791987]\n",
      "Epoch:  11 Step:  64\n",
      "Weights:  [ 2.82857077 -4.0028253   0.70144053 -2.40858876  1.78791987]\n",
      "Epoch:  11 Step:  65\n",
      "Weights:  [ 2.32857077 -4.3328253   0.56144053 -2.42858876  1.68791987]\n",
      "Epoch:  11 Step:  68\n",
      "Weights:  [ 1.59857077 -4.6228253  -0.06855947 -2.60858876  1.58791987]\n",
      "Epoch:  11 Step:  74\n",
      "Weights:  [ 2.16857077 -4.3228253   0.35144053 -2.48858876  1.68791987]\n",
      "Epoch:  11 Step:  75\n",
      "Weights:  [ 2.75857077 -4.0228253   0.77144053 -2.33858876  1.78791987]\n",
      "Epoch:  11 Step:  76\n",
      "Weights:  [ 2.26857077 -4.2728253   0.32144053 -2.50858876  1.68791987]\n",
      "Epoch:  11 Step:  77\n",
      "Weights:  [ 1.62857077 -4.5528253  -0.23855947 -2.72858876  1.58791987]\n",
      "Epoch:  11 Step:  84\n",
      "Weights:  [ 2.18857077 -4.3028253   0.15144053 -2.61858876  1.68791987]\n",
      "Epoch:  11 Step:  86\n",
      "Weights:  [ 2.74857077 -4.0328253   0.57144053 -2.48858876  1.78791987]\n",
      "Epoch:  11 Step:  88\n",
      "Weights:  [ 1.98857077 -4.3328253  -0.08855947 -2.69858876  1.68791987]\n",
      "Epoch:  11 Step:  90\n",
      "Weights:  [ 2.55857077 -4.0728253   0.26144053 -2.59858876  1.78791987]\n",
      "Epoch:  11 Step:  91\n",
      "Weights:  [ 2.08857077 -4.3928253   0.10144053 -2.61858876  1.68791987]\n",
      "Epoch:  11 Step:  96\n",
      "Weights:  [ 1.63857077 -4.6228253  -0.02855947 -2.64858876  1.58791987]\n",
      "Epoch:  11 Step:  97\n",
      "Weights:  [ 2.21857077 -4.3528253   0.38144053 -2.54858876  1.68791987]\n",
      "Epoch:  11 Step:  100\n",
      "Weights:  [ 1.53857077 -4.6528253  -0.16855947 -2.75858876  1.58791987]\n",
      "Epoch:  12 Step:  7\n",
      "Weights:  [ 2.16857077 -4.4228253   0.27144053 -2.62858876  1.68791987]\n",
      "Epoch:  12 Step:  11\n",
      "Weights:  [ 1.52857077 -4.6928253  -0.25855947 -2.81858876  1.58791987]\n",
      "Epoch:  12 Step:  14\n",
      "Weights:  [ 2.13857077 -4.4028253   0.21144053 -2.67858876  1.68791987]\n",
      "Epoch:  12 Step:  22\n",
      "Weights:  [ 1.50857077 -4.6528253  -0.28855947 -2.86858876  1.58791987]\n",
      "Epoch:  12 Step:  24\n",
      "Weights:  [ 2.16857077 -4.3528253   0.15144053 -2.72858876  1.68791987]\n",
      "Epoch:  12 Step:  26\n",
      "Weights:  [ 2.67857077 -4.1028253   0.45144053 -2.61858876  1.78791987]\n",
      "Epoch:  12 Step:  29\n",
      "Weights:  [ 2.04857077 -4.4328253  -0.14855947 -2.86858876  1.68791987]\n",
      "Epoch:  12 Step:  30\n",
      "Weights:  [ 2.59857077 -4.1728253   0.29144053 -2.74858876  1.78791987]\n",
      "Epoch:  12 Step:  32\n",
      "Weights:  [ 1.94857077 -4.4928253  -0.21855947 -2.94858876  1.68791987]\n",
      "Epoch:  12 Step:  33\n",
      "Weights:  [ 2.59857077 -4.2128253   0.24144053 -2.79858876  1.78791987]\n",
      "Epoch:  12 Step:  34\n",
      "Weights:  [ 2.11857077 -4.5128253   0.10144053 -2.80858876  1.68791987]\n",
      "Epoch:  12 Step:  36\n",
      "Weights:  [ 2.80857077 -4.2028253   0.59144053 -2.65858876  1.78791987]\n",
      "Epoch:  12 Step:  37\n",
      "Weights:  [ 2.17857077 -4.4928253   0.03144053 -2.83858876  1.68791987]\n",
      "Epoch:  12 Step:  38\n",
      "Weights:  [ 2.77857077 -4.2228253   0.54144053 -2.67858876  1.78791987]\n",
      "Epoch:  12 Step:  39\n",
      "Weights:  [ 2.24857077 -4.5928253   0.39144053 -2.69858876  1.68791987]\n",
      "Epoch:  12 Step:  41\n",
      "Weights:  [ 2.81857077 -4.3028253   0.81144053 -2.56858876  1.78791987]\n",
      "Epoch:  12 Step:  47\n",
      "Weights:  [ 2.27857077 -4.6428253   0.66144053 -2.60858876  1.68791987]\n",
      "Epoch:  12 Step:  48\n",
      "Weights:  [ 1.55857077 -4.9428253   0.08144053 -2.76858876  1.58791987]\n",
      "Epoch:  12 Step:  49\n",
      "Weights:  [ 2.21857077 -4.6528253   0.54144053 -2.63858876  1.68791987]\n",
      "Epoch:  12 Step:  68\n",
      "Weights:  [ 1.48857077 -4.9428253  -0.08855947 -2.81858876  1.58791987]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  12 Step:  74\n",
      "Weights:  [ 2.05857077 -4.6428253   0.33144053 -2.69858876  1.68791987]\n",
      "Epoch:  12 Step:  75\n",
      "Weights:  [ 2.64857077 -4.3428253   0.75144053 -2.54858876  1.78791987]\n",
      "Epoch:  12 Step:  76\n",
      "Weights:  [ 2.15857077 -4.5928253   0.30144053 -2.71858876  1.68791987]\n",
      "Epoch:  12 Step:  86\n",
      "Weights:  [ 2.71857077 -4.3228253   0.72144053 -2.58858876  1.78791987]\n",
      "Epoch:  12 Step:  88\n",
      "Weights:  [ 1.95857077 -4.6228253   0.06144053 -2.79858876  1.68791987]\n",
      "Epoch:  12 Step:  90\n",
      "Weights:  [ 2.52857077 -4.3628253   0.41144053 -2.69858876  1.78791987]\n",
      "Epoch:  12 Step:  92\n",
      "Weights:  [ 1.94857077 -4.6328253  -0.09855947 -2.88858876  1.68791987]\n",
      "Epoch:  12 Step:  97\n",
      "Weights:  [ 2.52857077 -4.3628253   0.31144053 -2.78858876  1.78791987]\n",
      "Epoch:  12 Step:  99\n",
      "Weights:  [ 1.85857077 -4.6728253  -0.24855947 -3.02858876  1.68791987]\n",
      "Epoch:  13 Step:  7\n",
      "Weights:  [ 2.48857077 -4.4428253   0.19144053 -2.89858876  1.78791987]\n",
      "Epoch:  13 Step:  8\n",
      "Weights:  [ 1.99857077 -4.7528253   0.04144053 -2.90858876  1.68791987]\n",
      "Epoch:  13 Step:  9\n",
      "Weights:  [ 2.57857077 -4.4828253   0.43144053 -2.78858876  1.78791987]\n",
      "Epoch:  13 Step:  10\n",
      "Weights:  [ 1.92857077 -4.7828253  -0.14855947 -3.00858876  1.68791987]\n",
      "Epoch:  13 Step:  14\n",
      "Weights:  [ 2.53857077 -4.4928253   0.32144053 -2.86858876  1.78791987]\n",
      "Epoch:  13 Step:  16\n",
      "Weights:  [ 1.84857077 -4.8128253  -0.24855947 -3.09858876  1.68791987]\n",
      "Epoch:  13 Step:  24\n",
      "Weights:  [ 2.50857077 -4.5128253   0.19144053 -2.95858876  1.78791987]\n",
      "Epoch:  13 Step:  31\n",
      "Weights:  [ 3.02857077 -4.2428253   0.58144053 -2.81858876  1.88791987]\n",
      "Epoch:  13 Step:  32\n",
      "Weights:  [ 2.37857077 -4.5628253   0.07144053 -3.01858876  1.78791987]\n",
      "Epoch:  13 Step:  36\n",
      "Weights:  [ 3.06857077 -4.2528253   0.56144053 -2.86858876  1.88791987]\n",
      "Epoch:  13 Step:  37\n",
      "Weights:  [ 2.43857077e+00 -4.54282530e+00  1.44053178e-03 -3.04858876e+00\n",
      "  1.78791987e+00]\n",
      "Epoch:  13 Step:  38\n",
      "Weights:  [ 3.03857077 -4.2728253   0.51144053 -2.88858876  1.88791987]\n",
      "Epoch:  13 Step:  39\n",
      "Weights:  [ 2.50857077 -4.6428253   0.36144053 -2.90858876  1.78791987]\n",
      "Epoch:  13 Step:  48\n",
      "Weights:  [ 1.78857077 -4.9428253  -0.21855947 -3.06858876  1.68791987]\n",
      "Epoch:  13 Step:  49\n",
      "Weights:  [ 2.44857077 -4.6528253   0.24144053 -2.93858876  1.78791987]\n",
      "Epoch:  13 Step:  56\n",
      "Weights:  [ 3.01857077 -4.3728253   0.69144053 -2.80858876  1.88791987]\n",
      "Epoch:  13 Step:  57\n",
      "Weights:  [ 2.45857077 -4.6528253   0.20144053 -3.00858876  1.78791987]\n",
      "Epoch:  13 Step:  64\n",
      "Weights:  [ 3.06857077 -4.3528253   0.66144053 -2.86858876  1.88791987]\n",
      "Epoch:  13 Step:  65\n",
      "Weights:  [ 2.56857077 -4.6828253   0.52144053 -2.88858876  1.78791987]\n",
      "Epoch:  13 Step:  68\n",
      "Weights:  [ 1.83857077 -4.9728253  -0.10855947 -3.06858876  1.68791987]\n",
      "Epoch:  13 Step:  74\n",
      "Weights:  [ 2.40857077 -4.6728253   0.31144053 -2.94858876  1.78791987]\n",
      "Epoch:  13 Step:  75\n",
      "Weights:  [ 2.99857077 -4.3728253   0.73144053 -2.79858876  1.88791987]\n",
      "Epoch:  13 Step:  76\n",
      "Weights:  [ 2.50857077 -4.6228253   0.28144053 -2.96858876  1.78791987]\n",
      "Epoch:  13 Step:  87\n",
      "Weights:  [ 3.14857077 -4.3028253   0.73144053 -2.81858876  1.88791987]\n",
      "Epoch:  13 Step:  88\n",
      "Weights:  [ 2.38857077 -4.6028253   0.07144053 -3.02858876  1.78791987]\n",
      "Epoch:  13 Step:  96\n",
      "Weights:  [ 1.93857077 -4.8328253  -0.05855947 -3.05858876  1.68791987]\n",
      "Epoch:  13 Step:  97\n",
      "Weights:  [ 2.51857077 -4.5628253   0.35144053 -2.95858876  1.78791987]\n",
      "Epoch:  13 Step:  100\n",
      "Weights:  [ 1.83857077 -4.8628253  -0.19855947 -3.16858876  1.68791987]\n",
      "Epoch:  14 Step:  7\n",
      "Weights:  [ 2.46857077 -4.6328253   0.24144053 -3.03858876  1.78791987]\n",
      "Epoch:  14 Step:  11\n",
      "Weights:  [ 1.82857077 -4.9028253  -0.28855947 -3.22858876  1.68791987]\n",
      "Epoch:  14 Step:  14\n",
      "Weights:  [ 2.43857077 -4.6128253   0.18144053 -3.08858876  1.78791987]\n",
      "Epoch:  14 Step:  22\n",
      "Weights:  [ 1.80857077 -4.8628253  -0.31855947 -3.27858876  1.68791987]\n",
      "Epoch:  14 Step:  24\n",
      "Weights:  [ 2.46857077 -4.5628253   0.12144053 -3.13858876  1.78791987]\n",
      "Epoch:  14 Step:  26\n",
      "Weights:  [ 2.97857077 -4.3128253   0.42144053 -3.02858876  1.88791987]\n",
      "Epoch:  14 Step:  29\n",
      "Weights:  [ 2.34857077 -4.6428253  -0.17855947 -3.27858876  1.78791987]\n",
      "Epoch:  14 Step:  30\n",
      "Weights:  [ 2.89857077 -4.3828253   0.26144053 -3.15858876  1.88791987]\n",
      "Epoch:  14 Step:  32\n",
      "Weights:  [ 2.24857077 -4.7028253  -0.24855947 -3.35858876  1.78791987]\n",
      "Epoch:  14 Step:  33\n",
      "Weights:  [ 2.89857077 -4.4228253   0.21144053 -3.20858876  1.88791987]\n",
      "Epoch:  14 Step:  34\n",
      "Weights:  [ 2.41857077 -4.7228253   0.07144053 -3.21858876  1.78791987]\n",
      "Epoch:  14 Step:  36\n",
      "Weights:  [ 3.10857077 -4.4128253   0.56144053 -3.06858876  1.88791987]\n",
      "Epoch:  14 Step:  37\n",
      "Weights:  [ 2.47857077e+00 -4.70282530e+00  1.44053178e-03 -3.24858876e+00\n",
      "  1.78791987e+00]\n",
      "Epoch:  14 Step:  38\n",
      "Weights:  [ 3.07857077 -4.4328253   0.51144053 -3.08858876  1.88791987]\n",
      "Epoch:  14 Step:  39\n",
      "Weights:  [ 2.54857077 -4.8028253   0.36144053 -3.10858876  1.78791987]\n",
      "Epoch:  14 Step:  41\n",
      "Weights:  [ 3.11857077 -4.5128253   0.78144053 -2.97858876  1.88791987]\n",
      "Epoch:  14 Step:  46\n",
      "Weights:  [ 2.59857077 -4.9228253   0.63144053 -2.98858876  1.78791987]\n",
      "Epoch:  14 Step:  48\n",
      "Weights:  [ 1.87857077 -5.2228253   0.05144053 -3.14858876  1.68791987]\n",
      "Epoch:  14 Step:  49\n",
      "Weights:  [ 2.53857077 -4.9328253   0.51144053 -3.01858876  1.78791987]\n",
      "Epoch:  14 Step:  50\n",
      "Weights:  [ 1.88857077 -5.2328253  -0.00855947 -3.21858876  1.68791987]\n",
      "Epoch:  14 Step:  53\n",
      "Weights:  [ 2.43857077 -4.9828253   0.39144053 -3.08858876  1.78791987]\n",
      "Epoch:  14 Step:  56\n",
      "Weights:  [ 3.00857077 -4.7028253   0.84144053 -2.95858876  1.88791987]\n",
      "Epoch:  14 Step:  57\n",
      "Weights:  [ 2.44857077 -4.9828253   0.35144053 -3.15858876  1.78791987]\n",
      "Epoch:  14 Step:  59\n",
      "Weights:  [ 3.06857077 -4.6928253   0.78144053 -3.02858876  1.88791987]\n",
      "Epoch:  14 Step:  60\n",
      "Weights:  [ 2.42857077 -5.0128253   0.25144053 -3.25858876  1.78791987]\n",
      "Epoch:  14 Step:  64\n",
      "Weights:  [ 3.03857077 -4.7128253   0.71144053 -3.11858876  1.88791987]\n",
      "Epoch:  14 Step:  65\n",
      "Weights:  [ 2.53857077 -5.0428253   0.57144053 -3.13858876  1.78791987]\n",
      "Epoch:  14 Step:  68\n",
      "Weights:  [ 1.80857077 -5.3328253  -0.05855947 -3.31858876  1.68791987]\n",
      "Epoch:  14 Step:  74\n",
      "Weights:  [ 2.37857077 -5.0328253   0.36144053 -3.19858876  1.78791987]\n",
      "Epoch:  14 Step:  75\n",
      "Weights:  [ 2.96857077 -4.7328253   0.78144053 -3.04858876  1.88791987]\n",
      "Epoch:  14 Step:  76\n",
      "Weights:  [ 2.47857077 -4.9828253   0.33144053 -3.21858876  1.78791987]\n",
      "Epoch:  14 Step:  86\n",
      "Weights:  [ 3.03857077 -4.7128253   0.75144053 -3.08858876  1.88791987]\n",
      "Epoch:  14 Step:  88\n",
      "Weights:  [ 2.27857077 -5.0128253   0.09144053 -3.29858876  1.78791987]\n",
      "Epoch:  14 Step:  90\n",
      "Weights:  [ 2.84857077 -4.7528253   0.44144053 -3.19858876  1.88791987]\n",
      "Epoch:  14 Step:  91\n",
      "Weights:  [ 2.37857077 -5.0728253   0.28144053 -3.21858876  1.78791987]\n",
      "Epoch:  14 Step:  96\n",
      "Weights:  [ 1.92857077 -5.3028253   0.15144053 -3.24858876  1.68791987]\n",
      "Epoch:  14 Step:  97\n",
      "Weights:  [ 2.50857077 -5.0328253   0.56144053 -3.14858876  1.78791987]\n",
      "Epoch:  14 Step:  100\n",
      "Weights:  [ 1.82857077 -5.3328253   0.01144053 -3.35858876  1.68791987]\n",
      "Epoch:  15 Step:  7\n",
      "Weights:  [ 2.45857077 -5.1028253   0.45144053 -3.22858876  1.78791987]\n",
      "Epoch:  15 Step:  11\n",
      "Weights:  [ 1.81857077 -5.3728253  -0.07855947 -3.41858876  1.68791987]\n",
      "Epoch:  15 Step:  14\n",
      "Weights:  [ 2.42857077 -5.0828253   0.39144053 -3.27858876  1.78791987]\n",
      "Epoch:  15 Step:  22\n",
      "Weights:  [ 1.79857077 -5.3328253  -0.10855947 -3.46858876  1.68791987]\n",
      "Epoch:  15 Step:  24\n",
      "Weights:  [ 2.45857077 -5.0328253   0.33144053 -3.32858876  1.78791987]\n",
      "Epoch:  15 Step:  26\n",
      "Weights:  [ 2.96857077 -4.7828253   0.63144053 -3.21858876  1.88791987]\n",
      "Epoch:  15 Step:  29\n",
      "Weights:  [ 2.33857077 -5.1128253   0.03144053 -3.46858876  1.78791987]\n",
      "Epoch:  15 Step:  30\n",
      "Weights:  [ 2.88857077 -4.8528253   0.47144053 -3.34858876  1.88791987]\n",
      "Epoch:  15 Step:  32\n",
      "Weights:  [ 2.23857077 -5.1728253  -0.03855947 -3.54858876  1.78791987]\n",
      "Epoch:  15 Step:  33\n",
      "Weights:  [ 2.88857077 -4.8928253   0.42144053 -3.39858876  1.88791987]\n",
      "Epoch:  15 Step:  34\n",
      "Weights:  [ 2.40857077 -5.1928253   0.28144053 -3.40858876  1.78791987]\n",
      "Epoch:  15 Step:  36\n",
      "Weights:  [ 3.09857077 -4.8828253   0.77144053 -3.25858876  1.88791987]\n",
      "Epoch:  15 Step:  37\n",
      "Weights:  [ 2.46857077 -5.1728253   0.21144053 -3.43858876  1.78791987]\n",
      "Epoch:  15 Step:  38\n",
      "Weights:  [ 3.06857077 -4.9028253   0.72144053 -3.27858876  1.88791987]\n",
      "Epoch:  15 Step:  39\n",
      "Weights:  [ 2.53857077 -5.2728253   0.57144053 -3.29858876  1.78791987]\n",
      "Epoch:  15 Step:  41\n",
      "Weights:  [ 3.10857077 -4.9828253   0.99144053 -3.16858876  1.88791987]\n",
      "Epoch:  15 Step:  47\n",
      "Weights:  [ 2.56857077 -5.3228253   0.84144053 -3.20858876  1.78791987]\n",
      "Epoch:  15 Step:  48\n",
      "Weights:  [ 1.84857077 -5.6228253   0.26144053 -3.36858876  1.68791987]\n",
      "Epoch:  15 Step:  49\n",
      "Weights:  [ 2.50857077 -5.3328253   0.72144053 -3.23858876  1.78791987]\n",
      "Epoch:  15 Step:  64\n",
      "Weights:  [ 3.11857077 -5.0328253   1.18144053 -3.09858876  1.88791987]\n",
      "Epoch:  15 Step:  65\n",
      "Weights:  [ 2.61857077 -5.3628253   1.04144053 -3.11858876  1.78791987]\n",
      "Epoch:  15 Step:  68\n",
      "Weights:  [ 1.88857077 -5.6528253   0.41144053 -3.29858876  1.68791987]\n",
      "Epoch:  15 Step:  74\n",
      "Weights:  [ 2.45857077 -5.3528253   0.83144053 -3.17858876  1.78791987]\n",
      "Epoch:  15 Step:  75\n",
      "Weights:  [ 3.04857077 -5.0528253   1.25144053 -3.02858876  1.88791987]\n",
      "Epoch:  15 Step:  76\n",
      "Weights:  [ 2.55857077 -5.3028253   0.80144053 -3.19858876  1.78791987]\n",
      "Epoch:  15 Step:  77\n",
      "Weights:  [ 1.91857077 -5.5828253   0.24144053 -3.41858876  1.68791987]\n",
      "Epoch:  15 Step:  84\n",
      "Weights:  [ 2.47857077 -5.3328253   0.63144053 -3.30858876  1.78791987]\n",
      "Epoch:  15 Step:  86\n",
      "Weights:  [ 3.03857077 -5.0628253   1.05144053 -3.17858876  1.88791987]\n",
      "Epoch:  15 Step:  88\n",
      "Weights:  [ 2.27857077 -5.3628253   0.39144053 -3.38858876  1.78791987]\n",
      "Epoch:  15 Step:  90\n",
      "Weights:  [ 2.84857077 -5.1028253   0.74144053 -3.28858876  1.88791987]\n",
      "Epoch:  15 Step:  92\n",
      "Weights:  [ 2.26857077 -5.3728253   0.23144053 -3.47858876  1.78791987]\n",
      "Epoch:  15 Step:  97\n",
      "Weights:  [ 2.84857077 -5.1028253   0.64144053 -3.37858876  1.88791987]\n",
      "Epoch:  15 Step:  99\n",
      "Weights:  [ 2.17857077 -5.4128253   0.08144053 -3.61858876  1.78791987]\n",
      "Epoch:  16 Step:  7\n",
      "Weights:  [ 2.80857077 -5.1828253   0.52144053 -3.48858876  1.88791987]\n",
      "Epoch:  16 Step:  8\n",
      "Weights:  [ 2.31857077 -5.4928253   0.37144053 -3.49858876  1.78791987]\n",
      "Epoch:  16 Step:  9\n",
      "Weights:  [ 2.89857077 -5.2228253   0.76144053 -3.37858876  1.88791987]\n",
      "Epoch:  16 Step:  10\n",
      "Weights:  [ 2.24857077 -5.5228253   0.18144053 -3.59858876  1.78791987]\n",
      "Epoch:  16 Step:  14\n",
      "Weights:  [ 2.85857077 -5.2328253   0.65144053 -3.45858876  1.88791987]\n",
      "Epoch:  16 Step:  16\n",
      "Weights:  [ 2.16857077 -5.5528253   0.08144053 -3.68858876  1.78791987]\n",
      "Epoch:  16 Step:  24\n",
      "Weights:  [ 2.82857077 -5.2528253   0.52144053 -3.54858876  1.88791987]\n",
      "Epoch:  16 Step:  25\n",
      "Weights:  [ 2.03857077 -5.6328253  -0.11855947 -3.74858876  1.78791987]\n",
      "Epoch:  16 Step:  26\n",
      "Weights:  [ 2.54857077 -5.3828253   0.18144053 -3.63858876  1.88791987]\n",
      "Epoch:  16 Step:  27\n",
      "Weights:  [ 3.21857077 -5.0728253   0.65144053 -3.48858876  1.98791987]\n",
      "Epoch:  16 Step:  29\n",
      "Weights:  [ 2.58857077 -5.4028253   0.05144053 -3.73858876  1.88791987]\n",
      "Epoch:  16 Step:  30\n",
      "Weights:  [ 3.13857077 -5.1428253   0.49144053 -3.61858876  1.98791987]\n",
      "Epoch:  16 Step:  32\n",
      "Weights:  [ 2.48857077 -5.4628253  -0.01855947 -3.81858876  1.88791987]\n",
      "Epoch:  16 Step:  33\n",
      "Weights:  [ 3.13857077 -5.1828253   0.44144053 -3.66858876  1.98791987]\n",
      "Epoch:  16 Step:  34\n",
      "Weights:  [ 2.65857077 -5.4828253   0.30144053 -3.67858876  1.88791987]\n",
      "Epoch:  16 Step:  36\n",
      "Weights:  [ 3.34857077 -5.1728253   0.79144053 -3.52858876  1.98791987]\n",
      "Epoch:  16 Step:  37\n",
      "Weights:  [ 2.71857077 -5.4628253   0.23144053 -3.70858876  1.88791987]\n",
      "Epoch:  16 Step:  38\n",
      "Weights:  [ 3.31857077 -5.1928253   0.74144053 -3.54858876  1.98791987]\n",
      "Epoch:  16 Step:  39\n",
      "Weights:  [ 2.78857077 -5.5628253   0.59144053 -3.56858876  1.88791987]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  16 Step:  41\n",
      "Weights:  [ 3.35857077 -5.2728253   1.01144053 -3.43858876  1.98791987]\n",
      "Epoch:  16 Step:  47\n",
      "Weights:  [ 2.81857077 -5.6128253   0.86144053 -3.47858876  1.88791987]\n",
      "Epoch:  16 Step:  48\n",
      "Weights:  [ 2.09857077 -5.9128253   0.28144053 -3.63858876  1.78791987]\n",
      "Epoch:  16 Step:  49\n",
      "Weights:  [ 2.75857077 -5.6228253   0.74144053 -3.50858876  1.88791987]\n",
      "Epoch:  16 Step:  68\n",
      "Weights:  [ 2.02857077 -5.9128253   0.11144053 -3.68858876  1.78791987]\n",
      "Epoch:  16 Step:  74\n",
      "Weights:  [ 2.59857077 -5.6128253   0.53144053 -3.56858876  1.88791987]\n",
      "Epoch:  16 Step:  75\n",
      "Weights:  [ 3.18857077 -5.3128253   0.95144053 -3.41858876  1.98791987]\n",
      "Epoch:  16 Step:  76\n",
      "Weights:  [ 2.69857077 -5.5628253   0.50144053 -3.58858876  1.88791987]\n",
      "Epoch:  16 Step:  86\n",
      "Weights:  [ 3.25857077 -5.2928253   0.92144053 -3.45858876  1.98791987]\n",
      "Epoch:  16 Step:  88\n",
      "Weights:  [ 2.49857077 -5.5928253   0.26144053 -3.66858876  1.88791987]\n",
      "Epoch:  16 Step:  90\n",
      "Weights:  [ 3.06857077 -5.3328253   0.61144053 -3.56858876  1.98791987]\n",
      "Epoch:  16 Step:  92\n",
      "Weights:  [ 2.48857077 -5.6028253   0.10144053 -3.75858876  1.88791987]\n",
      "Epoch:  16 Step:  97\n",
      "Weights:  [ 3.06857077 -5.3328253   0.51144053 -3.65858876  1.98791987]\n",
      "Epoch:  16 Step:  99\n",
      "Weights:  [ 2.39857077 -5.6428253  -0.04855947 -3.89858876  1.88791987]\n",
      "Epoch:  17 Step:  7\n",
      "Weights:  [ 3.02857077 -5.4128253   0.39144053 -3.76858876  1.98791987]\n",
      "Epoch:  17 Step:  8\n",
      "Weights:  [ 2.53857077 -5.7228253   0.24144053 -3.77858876  1.88791987]\n",
      "Epoch:  17 Step:  9\n",
      "Weights:  [ 3.11857077 -5.4528253   0.63144053 -3.65858876  1.98791987]\n",
      "Epoch:  17 Step:  10\n",
      "Weights:  [ 2.46857077 -5.7528253   0.05144053 -3.87858876  1.88791987]\n",
      "Epoch:  17 Step:  14\n",
      "Weights:  [ 3.07857077 -5.4628253   0.52144053 -3.73858876  1.98791987]\n",
      "Epoch:  17 Step:  16\n",
      "Weights:  [ 2.38857077 -5.7828253  -0.04855947 -3.96858876  1.88791987]\n",
      "Epoch:  17 Step:  24\n",
      "Weights:  [ 3.04857077 -5.4828253   0.39144053 -3.82858876  1.98791987]\n",
      "Epoch:  17 Step:  25\n",
      "Weights:  [ 2.25857077 -5.8628253  -0.24855947 -4.02858876  1.88791987]\n",
      "Epoch:  17 Step:  26\n",
      "Weights:  [ 2.76857077 -5.6128253   0.05144053 -3.91858876  1.98791987]\n",
      "Epoch:  17 Step:  27\n",
      "Weights:  [ 3.43857077 -5.3028253   0.52144053 -3.76858876  2.08791987]\n",
      "Epoch:  17 Step:  32\n",
      "Weights:  [ 2.78857077 -5.6228253   0.01144053 -3.96858876  1.98791987]\n",
      "Epoch:  17 Step:  33\n",
      "Weights:  [ 3.43857077 -5.3428253   0.47144053 -3.81858876  2.08791987]\n",
      "Epoch:  17 Step:  34\n",
      "Weights:  [ 2.95857077 -5.6428253   0.33144053 -3.82858876  1.98791987]\n",
      "Epoch:  17 Step:  35\n",
      "Weights:  [ 2.18857077 -5.9428253  -0.27855947 -4.05858876  1.88791987]\n",
      "Epoch:  17 Step:  36\n",
      "Weights:  [ 2.87857077 -5.6328253   0.21144053 -3.90858876  1.98791987]\n",
      "Epoch:  17 Step:  38\n",
      "Weights:  [ 3.47857077 -5.3628253   0.72144053 -3.74858876  2.08791987]\n",
      "Epoch:  17 Step:  39\n",
      "Weights:  [ 2.94857077 -5.7328253   0.57144053 -3.76858876  1.98791987]\n",
      "Epoch:  17 Step:  41\n",
      "Weights:  [ 3.51857077 -5.4428253   0.99144053 -3.63858876  2.08791987]\n",
      "Epoch:  17 Step:  47\n",
      "Weights:  [ 2.97857077 -5.7828253   0.84144053 -3.67858876  1.98791987]\n",
      "Epoch:  17 Step:  48\n",
      "Weights:  [ 2.25857077 -6.0828253   0.26144053 -3.83858876  1.88791987]\n",
      "Epoch:  17 Step:  49\n",
      "Weights:  [ 2.91857077 -5.7928253   0.72144053 -3.70858876  1.98791987]\n",
      "Epoch:  17 Step:  54\n",
      "Weights:  [ 2.27857077 -6.1028253   0.17144053 -3.88858876  1.88791987]\n",
      "Epoch:  17 Step:  56\n",
      "Weights:  [ 2.84857077 -5.8228253   0.62144053 -3.75858876  1.98791987]\n",
      "Epoch:  17 Step:  64\n",
      "Weights:  [ 3.45857077 -5.5228253   1.08144053 -3.61858876  2.08791987]\n",
      "Epoch:  17 Step:  65\n",
      "Weights:  [ 2.95857077 -5.8528253   0.94144053 -3.63858876  1.98791987]\n",
      "Epoch:  17 Step:  68\n",
      "Weights:  [ 2.22857077 -6.1428253   0.31144053 -3.81858876  1.88791987]\n",
      "Epoch:  17 Step:  74\n",
      "Weights:  [ 2.79857077 -5.8428253   0.73144053 -3.69858876  1.98791987]\n",
      "Epoch:  17 Step:  75\n",
      "Weights:  [ 3.38857077 -5.5428253   1.15144053 -3.54858876  2.08791987]\n",
      "Epoch:  17 Step:  76\n",
      "Weights:  [ 2.89857077 -5.7928253   0.70144053 -3.71858876  1.98791987]\n",
      "Epoch:  17 Step:  77\n",
      "Weights:  [ 2.25857077 -6.0728253   0.14144053 -3.93858876  1.88791987]\n",
      "Epoch:  17 Step:  84\n",
      "Weights:  [ 2.81857077 -5.8228253   0.53144053 -3.82858876  1.98791987]\n",
      "Epoch:  17 Step:  86\n",
      "Weights:  [ 3.37857077 -5.5528253   0.95144053 -3.69858876  2.08791987]\n",
      "Epoch:  17 Step:  88\n",
      "Weights:  [ 2.61857077 -5.8528253   0.29144053 -3.90858876  1.98791987]\n",
      "Epoch:  17 Step:  90\n",
      "Weights:  [ 3.18857077 -5.5928253   0.64144053 -3.80858876  2.08791987]\n",
      "Epoch:  17 Step:  92\n",
      "Weights:  [ 2.60857077 -5.8628253   0.13144053 -3.99858876  1.98791987]\n",
      "Epoch:  17 Step:  97\n",
      "Weights:  [ 3.18857077 -5.5928253   0.54144053 -3.89858876  2.08791987]\n",
      "Epoch:  17 Step:  100\n",
      "Weights:  [ 2.50857077 -5.8928253  -0.00855947 -4.10858876  1.98791987]\n",
      "Epoch:  18 Step:  7\n",
      "Weights:  [ 3.13857077 -5.6628253   0.43144053 -3.97858876  2.08791987]\n",
      "Epoch:  18 Step:  8\n",
      "Weights:  [ 2.64857077 -5.9728253   0.28144053 -3.98858876  1.98791987]\n",
      "Epoch:  18 Step:  9\n",
      "Weights:  [ 3.22857077 -5.7028253   0.67144053 -3.86858876  2.08791987]\n",
      "Epoch:  18 Step:  10\n",
      "Weights:  [ 2.57857077 -6.0028253   0.09144053 -4.08858876  1.98791987]\n",
      "Epoch:  18 Step:  14\n",
      "Weights:  [ 3.18857077 -5.7128253   0.56144053 -3.94858876  2.08791987]\n",
      "Epoch:  18 Step:  19\n",
      "Weights:  [ 2.47857077 -6.0128253  -0.02855947 -4.15858876  1.98791987]\n",
      "Epoch:  18 Step:  24\n",
      "Weights:  [ 3.13857077 -5.7128253   0.41144053 -4.01858876  2.08791987]\n",
      "Epoch:  18 Step:  31\n",
      "Weights:  [ 3.65857077 -5.4428253   0.80144053 -3.87858876  2.18791987]\n",
      "Epoch:  18 Step:  32\n",
      "Weights:  [ 3.00857077 -5.7628253   0.29144053 -4.07858876  2.08791987]\n",
      "Epoch:  18 Step:  35\n",
      "Weights:  [ 2.23857077 -6.0628253  -0.31855947 -4.30858876  1.98791987]\n",
      "Epoch:  18 Step:  36\n",
      "Weights:  [ 2.92857077 -5.7528253   0.17144053 -4.15858876  2.08791987]\n",
      "Epoch:  18 Step:  38\n",
      "Weights:  [ 3.52857077 -5.4828253   0.68144053 -3.99858876  2.18791987]\n",
      "Epoch:  18 Step:  39\n",
      "Weights:  [ 2.99857077 -5.8528253   0.53144053 -4.01858876  2.08791987]\n",
      "Epoch:  18 Step:  41\n",
      "Weights:  [ 3.56857077 -5.5628253   0.95144053 -3.88858876  2.18791987]\n",
      "Epoch:  18 Step:  47\n",
      "Weights:  [ 3.02857077 -5.9028253   0.80144053 -3.92858876  2.08791987]\n",
      "Epoch:  18 Step:  48\n",
      "Weights:  [ 2.30857077 -6.2028253   0.22144053 -4.08858876  1.98791987]\n",
      "Epoch:  18 Step:  49\n",
      "Weights:  [ 2.96857077 -5.9128253   0.68144053 -3.95858876  2.08791987]\n",
      "Epoch:  18 Step:  68\n",
      "Weights:  [ 2.23857077 -6.2028253   0.05144053 -4.13858876  1.98791987]\n",
      "Epoch:  18 Step:  74\n",
      "Weights:  [ 2.80857077 -5.9028253   0.47144053 -4.01858876  2.08791987]\n",
      "Epoch:  18 Step:  75\n",
      "Weights:  [ 3.39857077 -5.6028253   0.89144053 -3.86858876  2.18791987]\n",
      "Epoch:  18 Step:  76\n",
      "Weights:  [ 2.90857077 -5.8528253   0.44144053 -4.03858876  2.08791987]\n",
      "Epoch:  18 Step:  86\n",
      "Weights:  [ 3.46857077 -5.5828253   0.86144053 -3.90858876  2.18791987]\n",
      "Epoch:  18 Step:  88\n",
      "Weights:  [ 2.70857077 -5.8828253   0.20144053 -4.11858876  2.08791987]\n",
      "Epoch:  18 Step:  90\n",
      "Weights:  [ 3.27857077 -5.6228253   0.55144053 -4.01858876  2.18791987]\n",
      "Epoch:  18 Step:  92\n",
      "Weights:  [ 2.69857077 -5.8928253   0.04144053 -4.20858876  2.08791987]\n",
      "Epoch:  18 Step:  97\n",
      "Weights:  [ 3.27857077 -5.6228253   0.45144053 -4.10858876  2.18791987]\n",
      "Epoch:  18 Step:  100\n",
      "Weights:  [ 2.59857077 -5.9228253  -0.09855947 -4.31858876  2.08791987]\n",
      "Epoch:  19 Step:  7\n",
      "Weights:  [ 3.22857077 -5.6928253   0.34144053 -4.18858876  2.18791987]\n",
      "Epoch:  19 Step:  8\n",
      "Weights:  [ 2.73857077 -6.0028253   0.19144053 -4.19858876  2.08791987]\n",
      "Epoch:  19 Step:  9\n",
      "Weights:  [ 3.31857077 -5.7328253   0.58144053 -4.07858876  2.18791987]\n",
      "Epoch:  19 Step:  10\n",
      "Weights:  [ 2.66857077e+00 -6.03282530e+00  1.44053178e-03 -4.29858876e+00\n",
      "  2.08791987e+00]\n",
      "Epoch:  19 Step:  14\n",
      "Weights:  [ 3.27857077 -5.7428253   0.47144053 -4.15858876  2.18791987]\n",
      "Epoch:  19 Step:  19\n",
      "Weights:  [ 2.56857077 -6.0428253  -0.11855947 -4.36858876  2.08791987]\n",
      "Epoch:  19 Step:  24\n",
      "Weights:  [ 3.22857077 -5.7428253   0.32144053 -4.22858876  2.18791987]\n",
      "Epoch:  19 Step:  31\n",
      "Weights:  [ 3.74857077 -5.4728253   0.71144053 -4.08858876  2.28791987]\n",
      "Epoch:  19 Step:  32\n",
      "Weights:  [ 3.09857077 -5.7928253   0.20144053 -4.28858876  2.18791987]\n",
      "Epoch:  19 Step:  35\n",
      "Weights:  [ 2.32857077 -6.0928253  -0.40855947 -4.51858876  2.08791987]\n",
      "Epoch:  19 Step:  36\n",
      "Weights:  [ 3.01857077 -5.7828253   0.08144053 -4.36858876  2.18791987]\n",
      "Epoch:  19 Step:  38\n",
      "Weights:  [ 3.61857077 -5.5128253   0.59144053 -4.20858876  2.28791987]\n",
      "Epoch:  19 Step:  39\n",
      "Weights:  [ 3.08857077 -5.8828253   0.44144053 -4.22858876  2.18791987]\n",
      "Epoch:  19 Step:  41\n",
      "Weights:  [ 3.65857077 -5.5928253   0.86144053 -4.09858876  2.28791987]\n",
      "Epoch:  19 Step:  47\n",
      "Weights:  [ 3.11857077 -5.9328253   0.71144053 -4.13858876  2.18791987]\n",
      "Epoch:  19 Step:  48\n",
      "Weights:  [ 2.39857077 -6.2328253   0.13144053 -4.29858876  2.08791987]\n",
      "Epoch:  19 Step:  49\n",
      "Weights:  [ 3.05857077 -5.9428253   0.59144053 -4.16858876  2.18791987]\n",
      "Epoch:  19 Step:  64\n",
      "Weights:  [ 3.66857077 -5.6428253   1.05144053 -4.02858876  2.28791987]\n",
      "Epoch:  19 Step:  65\n",
      "Weights:  [ 3.16857077 -5.9728253   0.91144053 -4.04858876  2.18791987]\n",
      "Epoch:  19 Step:  68\n",
      "Weights:  [ 2.43857077 -6.2628253   0.28144053 -4.22858876  2.08791987]\n",
      "Epoch:  19 Step:  74\n",
      "Weights:  [ 3.00857077 -5.9628253   0.70144053 -4.10858876  2.18791987]\n",
      "Epoch:  19 Step:  75\n",
      "Weights:  [ 3.59857077 -5.6628253   1.12144053 -3.95858876  2.28791987]\n",
      "Epoch:  19 Step:  76\n",
      "Weights:  [ 3.10857077 -5.9128253   0.67144053 -4.12858876  2.18791987]\n",
      "Epoch:  19 Step:  77\n",
      "Weights:  [ 2.46857077 -6.1928253   0.11144053 -4.34858876  2.08791987]\n",
      "Epoch:  19 Step:  84\n",
      "Weights:  [ 3.02857077 -5.9428253   0.50144053 -4.23858876  2.18791987]\n",
      "Epoch:  19 Step:  86\n",
      "Weights:  [ 3.58857077 -5.6728253   0.92144053 -4.10858876  2.28791987]\n",
      "Epoch:  19 Step:  88\n",
      "Weights:  [ 2.82857077 -5.9728253   0.26144053 -4.31858876  2.18791987]\n",
      "Epoch:  19 Step:  90\n",
      "Weights:  [ 3.39857077 -5.7128253   0.61144053 -4.21858876  2.28791987]\n",
      "Epoch:  19 Step:  91\n",
      "Weights:  [ 2.92857077 -6.0328253   0.45144053 -4.23858876  2.18791987]\n",
      "Epoch:  19 Step:  96\n",
      "Weights:  [ 2.47857077 -6.2628253   0.32144053 -4.26858876  2.08791987]\n",
      "Epoch:  19 Step:  97\n",
      "Weights:  [ 3.05857077 -5.9928253   0.73144053 -4.16858876  2.18791987]\n",
      "Epoch:  19 Step:  100\n",
      "Weights:  [ 2.37857077 -6.2928253   0.18144053 -4.37858876  2.08791987]\n",
      "Epoch:  20 Step:  7\n",
      "Weights:  [ 3.00857077 -6.0628253   0.62144053 -4.24858876  2.18791987]\n",
      "Epoch:  20 Step:  11\n",
      "Weights:  [ 2.36857077 -6.3328253   0.09144053 -4.43858876  2.08791987]\n",
      "Epoch:  20 Step:  14\n",
      "Weights:  [ 2.97857077 -6.0428253   0.56144053 -4.29858876  2.18791987]\n",
      "Epoch:  20 Step:  22\n",
      "Weights:  [ 2.34857077 -6.2928253   0.06144053 -4.48858876  2.08791987]\n",
      "Epoch:  20 Step:  24\n",
      "Weights:  [ 3.00857077 -5.9928253   0.50144053 -4.34858876  2.18791987]\n",
      "Epoch:  20 Step:  26\n",
      "Weights:  [ 3.51857077 -5.7428253   0.80144053 -4.23858876  2.28791987]\n",
      "Epoch:  20 Step:  32\n",
      "Weights:  [ 2.86857077 -6.0628253   0.29144053 -4.43858876  2.18791987]\n",
      "Epoch:  20 Step:  33\n",
      "Weights:  [ 3.51857077 -5.7828253   0.75144053 -4.28858876  2.28791987]\n",
      "Epoch:  20 Step:  34\n",
      "Weights:  [ 3.03857077 -6.0828253   0.61144053 -4.29858876  2.18791987]\n",
      "Epoch:  20 Step:  35\n",
      "Weights:  [ 2.26857077e+00 -6.38282530e+00  1.44053178e-03 -4.52858876e+00\n",
      "  2.08791987e+00]\n",
      "Epoch:  20 Step:  36\n",
      "Weights:  [ 2.95857077 -6.0728253   0.49144053 -4.37858876  2.18791987]\n",
      "Epoch:  20 Step:  38\n",
      "Weights:  [ 3.55857077 -5.8028253   1.00144053 -4.21858876  2.28791987]\n",
      "Epoch:  20 Step:  39\n",
      "Weights:  [ 3.02857077 -6.1728253   0.85144053 -4.23858876  2.18791987]\n",
      "Epoch:  20 Step:  41\n",
      "Weights:  [ 3.59857077 -5.8828253   1.27144053 -4.10858876  2.28791987]\n",
      "Epoch:  20 Step:  47\n",
      "Weights:  [ 3.05857077 -6.2228253   1.12144053 -4.14858876  2.18791987]\n",
      "Epoch:  20 Step:  48\n",
      "Weights:  [ 2.33857077 -6.5228253   0.54144053 -4.30858876  2.08791987]\n",
      "Epoch:  20 Step:  49\n",
      "Weights:  [ 2.99857077 -6.2328253   1.00144053 -4.17858876  2.18791987]\n",
      "Epoch:  20 Step:  54\n",
      "Weights:  [ 2.35857077 -6.5428253   0.45144053 -4.35858876  2.08791987]\n",
      "Epoch:  20 Step:  56\n",
      "Weights:  [ 2.92857077 -6.2628253   0.90144053 -4.22858876  2.18791987]\n",
      "Epoch:  20 Step:  64\n",
      "Weights:  [ 3.53857077 -5.9628253   1.36144053 -4.08858876  2.28791987]\n",
      "Epoch:  20 Step:  65\n",
      "Weights:  [ 3.03857077 -6.2928253   1.22144053 -4.10858876  2.18791987]\n",
      "Epoch:  20 Step:  68\n",
      "Weights:  [ 2.30857077 -6.5828253   0.59144053 -4.28858876  2.08791987]\n",
      "Epoch:  20 Step:  74\n",
      "Weights:  [ 2.87857077 -6.2828253   1.01144053 -4.16858876  2.18791987]\n",
      "Epoch:  20 Step:  75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights:  [ 3.46857077 -5.9828253   1.43144053 -4.01858876  2.28791987]\n",
      "Epoch:  20 Step:  76\n",
      "Weights:  [ 2.97857077 -6.2328253   0.98144053 -4.18858876  2.18791987]\n",
      "Epoch:  20 Step:  77\n",
      "Weights:  [ 2.33857077 -6.5128253   0.42144053 -4.40858876  2.08791987]\n",
      "Epoch:  20 Step:  84\n",
      "Weights:  [ 2.89857077 -6.2628253   0.81144053 -4.29858876  2.18791987]\n",
      "Epoch:  20 Step:  86\n",
      "Weights:  [ 3.45857077 -5.9928253   1.23144053 -4.16858876  2.28791987]\n",
      "Epoch:  20 Step:  88\n",
      "Weights:  [ 2.69857077 -6.2928253   0.57144053 -4.37858876  2.18791987]\n",
      "Epoch:  20 Step:  90\n",
      "Weights:  [ 3.26857077 -6.0328253   0.92144053 -4.27858876  2.28791987]\n",
      "Epoch:  20 Step:  92\n",
      "Weights:  [ 2.68857077 -6.3028253   0.41144053 -4.46858876  2.18791987]\n",
      "Epoch:  20 Step:  97\n",
      "Weights:  [ 3.26857077 -6.0328253   0.82144053 -4.36858876  2.28791987]\n",
      "Epoch:  20 Step:  100\n",
      "Weights:  [ 2.58857077 -6.3328253   0.27144053 -4.57858876  2.18791987]\n",
      "Epoch:  21 Step:  7\n",
      "Weights:  [ 3.21857077 -6.1028253   0.71144053 -4.44858876  2.28791987]\n",
      "Epoch:  21 Step:  11\n",
      "Weights:  [ 2.57857077 -6.3728253   0.18144053 -4.63858876  2.18791987]\n",
      "Epoch:  21 Step:  14\n",
      "Weights:  [ 3.18857077 -6.0828253   0.65144053 -4.49858876  2.28791987]\n",
      "Epoch:  21 Step:  19\n",
      "Weights:  [ 2.47857077 -6.3828253   0.06144053 -4.70858876  2.18791987]\n",
      "Epoch:  21 Step:  24\n",
      "Weights:  [ 3.13857077 -6.0828253   0.50144053 -4.56858876  2.28791987]\n",
      "Epoch:  21 Step:  26\n",
      "Weights:  [ 3.64857077 -5.8328253   0.80144053 -4.45858876  2.38791987]\n",
      "Epoch:  21 Step:  32\n",
      "Weights:  [ 2.99857077 -6.1528253   0.29144053 -4.65858876  2.28791987]\n",
      "Epoch:  21 Step:  33\n",
      "Weights:  [ 3.64857077 -5.8728253   0.75144053 -4.50858876  2.38791987]\n",
      "Epoch:  21 Step:  34\n",
      "Weights:  [ 3.16857077 -6.1728253   0.61144053 -4.51858876  2.28791987]\n",
      "Epoch:  21 Step:  35\n",
      "Weights:  [ 2.39857077e+00 -6.47282530e+00  1.44053178e-03 -4.74858876e+00\n",
      "  2.18791987e+00]\n",
      "Epoch:  21 Step:  36\n",
      "Weights:  [ 3.08857077 -6.1628253   0.49144053 -4.59858876  2.28791987]\n",
      "Epoch:  21 Step:  38\n",
      "Weights:  [ 3.68857077 -5.8928253   1.00144053 -4.43858876  2.38791987]\n",
      "Epoch:  21 Step:  39\n",
      "Weights:  [ 3.15857077 -6.2628253   0.85144053 -4.45858876  2.28791987]\n",
      "Epoch:  21 Step:  41\n",
      "Weights:  [ 3.72857077 -5.9728253   1.27144053 -4.32858876  2.38791987]\n",
      "Epoch:  21 Step:  47\n",
      "Weights:  [ 3.18857077 -6.3128253   1.12144053 -4.36858876  2.28791987]\n",
      "Epoch:  21 Step:  48\n",
      "Weights:  [ 2.46857077 -6.6128253   0.54144053 -4.52858876  2.18791987]\n",
      "Epoch:  21 Step:  49\n",
      "Weights:  [ 3.12857077 -6.3228253   1.00144053 -4.39858876  2.28791987]\n",
      "Epoch:  21 Step:  50\n",
      "Weights:  [ 2.47857077 -6.6228253   0.48144053 -4.59858876  2.18791987]\n",
      "Epoch:  21 Step:  53\n",
      "Weights:  [ 3.02857077 -6.3728253   0.88144053 -4.46858876  2.28791987]\n",
      "Epoch:  21 Step:  56\n",
      "Weights:  [ 3.59857077 -6.0928253   1.33144053 -4.33858876  2.38791987]\n",
      "Epoch:  21 Step:  57\n",
      "Weights:  [ 3.03857077 -6.3728253   0.84144053 -4.53858876  2.28791987]\n",
      "Epoch:  21 Step:  64\n",
      "Weights:  [ 3.64857077 -6.0728253   1.30144053 -4.39858876  2.38791987]\n",
      "Epoch:  21 Step:  65\n",
      "Weights:  [ 3.14857077 -6.4028253   1.16144053 -4.41858876  2.28791987]\n",
      "Epoch:  21 Step:  68\n",
      "Weights:  [ 2.41857077 -6.6928253   0.53144053 -4.59858876  2.18791987]\n",
      "Epoch:  21 Step:  74\n",
      "Weights:  [ 2.98857077 -6.3928253   0.95144053 -4.47858876  2.28791987]\n",
      "Epoch:  21 Step:  75\n",
      "Weights:  [ 3.57857077 -6.0928253   1.37144053 -4.32858876  2.38791987]\n",
      "Epoch:  21 Step:  76\n",
      "Weights:  [ 3.08857077 -6.3428253   0.92144053 -4.49858876  2.28791987]\n",
      "Epoch:  21 Step:  87\n",
      "Weights:  [ 3.72857077 -6.0228253   1.37144053 -4.34858876  2.38791987]\n",
      "Epoch:  21 Step:  88\n",
      "Weights:  [ 2.96857077 -6.3228253   0.71144053 -4.55858876  2.28791987]\n",
      "Epoch:  21 Step:  96\n",
      "Weights:  [ 2.51857077 -6.5528253   0.58144053 -4.58858876  2.18791987]\n",
      "Epoch:  21 Step:  97\n",
      "Weights:  [ 3.09857077 -6.2828253   0.99144053 -4.48858876  2.28791987]\n",
      "Epoch:  21 Step:  100\n",
      "Weights:  [ 2.41857077 -6.5828253   0.44144053 -4.69858876  2.18791987]\n",
      "Epoch:  22 Step:  7\n",
      "Weights:  [ 3.04857077 -6.3528253   0.88144053 -4.56858876  2.28791987]\n",
      "Epoch:  22 Step:  11\n",
      "Weights:  [ 2.40857077 -6.6228253   0.35144053 -4.75858876  2.18791987]\n",
      "Epoch:  22 Step:  14\n",
      "Weights:  [ 3.01857077 -6.3328253   0.82144053 -4.61858876  2.28791987]\n",
      "Epoch:  22 Step:  22\n",
      "Weights:  [ 2.38857077 -6.5828253   0.32144053 -4.80858876  2.18791987]\n",
      "Epoch:  22 Step:  24\n",
      "Weights:  [ 3.04857077 -6.2828253   0.76144053 -4.66858876  2.28791987]\n",
      "Epoch:  22 Step:  26\n",
      "Weights:  [ 3.55857077 -6.0328253   1.06144053 -4.55858876  2.38791987]\n",
      "Epoch:  22 Step:  32\n",
      "Weights:  [ 2.90857077 -6.3528253   0.55144053 -4.75858876  2.28791987]\n",
      "Epoch:  22 Step:  33\n",
      "Weights:  [ 3.55857077 -6.0728253   1.01144053 -4.60858876  2.38791987]\n",
      "Epoch:  22 Step:  34\n",
      "Weights:  [ 3.07857077 -6.3728253   0.87144053 -4.61858876  2.28791987]\n",
      "Epoch:  22 Step:  35\n",
      "Weights:  [ 2.30857077 -6.6728253   0.26144053 -4.84858876  2.18791987]\n",
      "Epoch:  22 Step:  36\n",
      "Weights:  [ 2.99857077 -6.3628253   0.75144053 -4.69858876  2.28791987]\n",
      "Epoch:  22 Step:  38\n",
      "Weights:  [ 3.59857077 -6.0928253   1.26144053 -4.53858876  2.38791987]\n",
      "Epoch:  22 Step:  47\n",
      "Weights:  [ 3.05857077 -6.4328253   1.11144053 -4.57858876  2.28791987]\n",
      "Epoch:  22 Step:  48\n",
      "Weights:  [ 2.33857077 -6.7328253   0.53144053 -4.73858876  2.18791987]\n",
      "Epoch:  22 Step:  49\n",
      "Weights:  [ 2.99857077 -6.4428253   0.99144053 -4.60858876  2.28791987]\n",
      "Epoch:  22 Step:  56\n",
      "Weights:  [ 3.56857077 -6.1628253   1.44144053 -4.47858876  2.38791987]\n",
      "Epoch:  22 Step:  57\n",
      "Weights:  [ 3.00857077 -6.4428253   0.95144053 -4.67858876  2.28791987]\n",
      "Epoch:  22 Step:  64\n",
      "Weights:  [ 3.61857077 -6.1428253   1.41144053 -4.53858876  2.38791987]\n",
      "Epoch:  22 Step:  65\n",
      "Weights:  [ 3.11857077 -6.4728253   1.27144053 -4.55858876  2.28791987]\n",
      "Epoch:  22 Step:  68\n",
      "Weights:  [ 2.38857077 -6.7628253   0.64144053 -4.73858876  2.18791987]\n",
      "Epoch:  22 Step:  74\n",
      "Weights:  [ 2.95857077 -6.4628253   1.06144053 -4.61858876  2.28791987]\n",
      "Epoch:  22 Step:  75\n",
      "Weights:  [ 3.54857077 -6.1628253   1.48144053 -4.46858876  2.38791987]\n",
      "Epoch:  22 Step:  76\n",
      "Weights:  [ 3.05857077 -6.4128253   1.03144053 -4.63858876  2.28791987]\n",
      "Epoch:  22 Step:  87\n",
      "Weights:  [ 3.69857077 -6.0928253   1.48144053 -4.48858876  2.38791987]\n",
      "Epoch:  22 Step:  88\n",
      "Weights:  [ 2.93857077 -6.3928253   0.82144053 -4.69858876  2.28791987]\n",
      "Epoch:  22 Step:  96\n",
      "Weights:  [ 2.48857077 -6.6228253   0.69144053 -4.72858876  2.18791987]\n",
      "Epoch:  22 Step:  97\n",
      "Weights:  [ 3.06857077 -6.3528253   1.10144053 -4.62858876  2.28791987]\n",
      "Epoch:  22 Step:  100\n",
      "Weights:  [ 2.38857077 -6.6528253   0.55144053 -4.83858876  2.18791987]\n",
      "Epoch:  23 Step:  7\n",
      "Weights:  [ 3.01857077 -6.4228253   0.99144053 -4.70858876  2.28791987]\n",
      "Epoch:  23 Step:  11\n",
      "Weights:  [ 2.37857077 -6.6928253   0.46144053 -4.89858876  2.18791987]\n",
      "Epoch:  23 Step:  14\n",
      "Weights:  [ 2.98857077 -6.4028253   0.93144053 -4.75858876  2.28791987]\n",
      "Epoch:  23 Step:  22\n",
      "Weights:  [ 2.35857077 -6.6528253   0.43144053 -4.94858876  2.18791987]\n",
      "Epoch:  23 Step:  24\n",
      "Weights:  [ 3.01857077 -6.3528253   0.87144053 -4.80858876  2.28791987]\n",
      "Epoch:  23 Step:  26\n",
      "Weights:  [ 3.52857077 -6.1028253   1.17144053 -4.69858876  2.38791987]\n",
      "Epoch:  23 Step:  32\n",
      "Weights:  [ 2.87857077 -6.4228253   0.66144053 -4.89858876  2.28791987]\n",
      "Epoch:  23 Step:  33\n",
      "Weights:  [ 3.52857077 -6.1428253   1.12144053 -4.74858876  2.38791987]\n",
      "Epoch:  23 Step:  34\n",
      "Weights:  [ 3.04857077 -6.4428253   0.98144053 -4.75858876  2.28791987]\n",
      "Epoch:  23 Step:  35\n",
      "Weights:  [ 2.27857077 -6.7428253   0.37144053 -4.98858876  2.18791987]\n",
      "Epoch:  23 Step:  36\n",
      "Weights:  [ 2.96857077 -6.4328253   0.86144053 -4.83858876  2.28791987]\n",
      "Epoch:  23 Step:  38\n",
      "Weights:  [ 3.56857077 -6.1628253   1.37144053 -4.67858876  2.38791987]\n",
      "Epoch:  23 Step:  47\n",
      "Weights:  [ 3.02857077 -6.5028253   1.22144053 -4.71858876  2.28791987]\n",
      "Epoch:  23 Step:  48\n",
      "Weights:  [ 2.30857077 -6.8028253   0.64144053 -4.87858876  2.18791987]\n",
      "Epoch:  23 Step:  49\n",
      "Weights:  [ 2.96857077 -6.5128253   1.10144053 -4.74858876  2.28791987]\n",
      "Epoch:  23 Step:  56\n",
      "Weights:  [ 3.53857077 -6.2328253   1.55144053 -4.61858876  2.38791987]\n",
      "Epoch:  23 Step:  57\n",
      "Weights:  [ 2.97857077 -6.5128253   1.06144053 -4.81858876  2.28791987]\n",
      "Epoch:  23 Step:  64\n",
      "Weights:  [ 3.58857077 -6.2128253   1.52144053 -4.67858876  2.38791987]\n",
      "Epoch:  23 Step:  65\n",
      "Weights:  [ 3.08857077 -6.5428253   1.38144053 -4.69858876  2.28791987]\n",
      "Epoch:  23 Step:  68\n",
      "Weights:  [ 2.35857077 -6.8328253   0.75144053 -4.87858876  2.18791987]\n",
      "Epoch:  23 Step:  74\n",
      "Weights:  [ 2.92857077 -6.5328253   1.17144053 -4.75858876  2.28791987]\n",
      "Epoch:  23 Step:  75\n",
      "Weights:  [ 3.51857077 -6.2328253   1.59144053 -4.60858876  2.38791987]\n",
      "Epoch:  23 Step:  76\n",
      "Weights:  [ 3.02857077 -6.4828253   1.14144053 -4.77858876  2.28791987]\n",
      "Epoch:  23 Step:  87\n",
      "Weights:  [ 3.66857077 -6.1628253   1.59144053 -4.62858876  2.38791987]\n",
      "Epoch:  23 Step:  88\n",
      "Weights:  [ 2.90857077 -6.4628253   0.93144053 -4.83858876  2.28791987]\n",
      "Epoch:  23 Step:  96\n",
      "Weights:  [ 2.45857077 -6.6928253   0.80144053 -4.86858876  2.18791987]\n",
      "Epoch:  23 Step:  97\n",
      "Weights:  [ 3.03857077 -6.4228253   1.21144053 -4.76858876  2.28791987]\n",
      "Epoch:  23 Step:  100\n",
      "Weights:  [ 2.35857077 -6.7228253   0.66144053 -4.97858876  2.18791987]\n",
      "Epoch:  24 Step:  7\n",
      "Weights:  [ 2.98857077 -6.4928253   1.10144053 -4.84858876  2.28791987]\n",
      "Epoch:  24 Step:  11\n",
      "Weights:  [ 2.34857077 -6.7628253   0.57144053 -5.03858876  2.18791987]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  24 Step:  14\n",
      "Weights:  [ 2.95857077 -6.4728253   1.04144053 -4.89858876  2.28791987]\n",
      "Epoch:  24 Step:  22\n",
      "Weights:  [ 2.32857077 -6.7228253   0.54144053 -5.08858876  2.18791987]\n",
      "Epoch:  24 Step:  24\n",
      "Weights:  [ 2.98857077 -6.4228253   0.98144053 -4.94858876  2.28791987]\n",
      "Epoch:  24 Step:  26\n",
      "Weights:  [ 3.49857077 -6.1728253   1.28144053 -4.83858876  2.38791987]\n",
      "Epoch:  24 Step:  32\n",
      "Weights:  [ 2.84857077 -6.4928253   0.77144053 -5.03858876  2.28791987]\n",
      "Epoch:  24 Step:  33\n",
      "Weights:  [ 3.49857077 -6.2128253   1.23144053 -4.88858876  2.38791987]\n",
      "Epoch:  24 Step:  34\n",
      "Weights:  [ 3.01857077 -6.5128253   1.09144053 -4.89858876  2.28791987]\n",
      "Epoch:  24 Step:  35\n",
      "Weights:  [ 2.24857077 -6.8128253   0.48144053 -5.12858876  2.18791987]\n",
      "Epoch:  24 Step:  36\n",
      "Weights:  [ 2.93857077 -6.5028253   0.97144053 -4.97858876  2.28791987]\n",
      "Epoch:  24 Step:  38\n",
      "Weights:  [ 3.53857077 -6.2328253   1.48144053 -4.81858876  2.38791987]\n",
      "Epoch:  24 Step:  47\n",
      "Weights:  [ 2.99857077 -6.5728253   1.33144053 -4.85858876  2.28791987]\n",
      "Epoch:  24 Step:  48\n",
      "Weights:  [ 2.27857077 -6.8728253   0.75144053 -5.01858876  2.18791987]\n",
      "Epoch:  24 Step:  49\n",
      "Weights:  [ 2.93857077 -6.5828253   1.21144053 -4.88858876  2.28791987]\n",
      "Epoch:  24 Step:  56\n",
      "Weights:  [ 3.50857077 -6.3028253   1.66144053 -4.75858876  2.38791987]\n",
      "Epoch:  24 Step:  57\n",
      "Weights:  [ 2.94857077 -6.5828253   1.17144053 -4.95858876  2.28791987]\n",
      "Epoch:  24 Step:  64\n",
      "Weights:  [ 3.55857077 -6.2828253   1.63144053 -4.81858876  2.38791987]\n",
      "Epoch:  24 Step:  65\n",
      "Weights:  [ 3.05857077 -6.6128253   1.49144053 -4.83858876  2.28791987]\n",
      "Epoch:  24 Step:  68\n",
      "Weights:  [ 2.32857077 -6.9028253   0.86144053 -5.01858876  2.18791987]\n",
      "Epoch:  24 Step:  74\n",
      "Weights:  [ 2.89857077 -6.6028253   1.28144053 -4.89858876  2.28791987]\n",
      "Epoch:  24 Step:  75\n",
      "Weights:  [ 3.48857077 -6.3028253   1.70144053 -4.74858876  2.38791987]\n",
      "Epoch:  24 Step:  76\n",
      "Weights:  [ 2.99857077 -6.5528253   1.25144053 -4.91858876  2.28791987]\n",
      "Epoch:  24 Step:  87\n",
      "Weights:  [ 3.63857077 -6.2328253   1.70144053 -4.76858876  2.38791987]\n",
      "Epoch:  24 Step:  88\n",
      "Weights:  [ 2.87857077 -6.5328253   1.04144053 -4.97858876  2.28791987]\n",
      "Epoch:  24 Step:  96\n",
      "Weights:  [ 2.42857077 -6.7628253   0.91144053 -5.00858876  2.18791987]\n",
      "Epoch:  24 Step:  97\n",
      "Weights:  [ 3.00857077 -6.4928253   1.32144053 -4.90858876  2.28791987]\n",
      "Epoch:  24 Step:  100\n",
      "Weights:  [ 2.32857077 -6.7928253   0.77144053 -5.11858876  2.18791987]\n",
      "Epoch:  25 Step:  7\n",
      "Weights:  [ 2.95857077 -6.5628253   1.21144053 -4.98858876  2.28791987]\n",
      "Epoch:  25 Step:  11\n",
      "Weights:  [ 2.31857077 -6.8328253   0.68144053 -5.17858876  2.18791987]\n",
      "Epoch:  25 Step:  14\n",
      "Weights:  [ 2.92857077 -6.5428253   1.15144053 -5.03858876  2.28791987]\n",
      "Epoch:  25 Step:  22\n",
      "Weights:  [ 2.29857077 -6.7928253   0.65144053 -5.22858876  2.18791987]\n",
      "Epoch:  25 Step:  24\n",
      "Weights:  [ 2.95857077 -6.4928253   1.09144053 -5.08858876  2.28791987]\n",
      "Epoch:  25 Step:  26\n",
      "Weights:  [ 3.46857077 -6.2428253   1.39144053 -4.97858876  2.38791987]\n",
      "Epoch:  25 Step:  32\n",
      "Weights:  [ 2.81857077 -6.5628253   0.88144053 -5.17858876  2.28791987]\n",
      "Epoch:  25 Step:  33\n",
      "Weights:  [ 3.46857077 -6.2828253   1.34144053 -5.02858876  2.38791987]\n",
      "Epoch:  25 Step:  34\n",
      "Weights:  [ 2.98857077 -6.5828253   1.20144053 -5.03858876  2.28791987]\n",
      "Epoch:  25 Step:  35\n",
      "Weights:  [ 2.21857077 -6.8828253   0.59144053 -5.26858876  2.18791987]\n",
      "Epoch:  25 Step:  36\n",
      "Weights:  [ 2.90857077 -6.5728253   1.08144053 -5.11858876  2.28791987]\n",
      "Epoch:  25 Step:  38\n",
      "Weights:  [ 3.50857077 -6.3028253   1.59144053 -4.95858876  2.38791987]\n",
      "Epoch:  25 Step:  47\n",
      "Weights:  [ 2.96857077 -6.6428253   1.44144053 -4.99858876  2.28791987]\n",
      "Epoch:  25 Step:  48\n",
      "Weights:  [ 2.24857077 -6.9428253   0.86144053 -5.15858876  2.18791987]\n",
      "Epoch:  25 Step:  49\n",
      "Weights:  [ 2.90857077 -6.6528253   1.32144053 -5.02858876  2.28791987]\n",
      "Epoch:  25 Step:  56\n",
      "Weights:  [ 3.47857077 -6.3728253   1.77144053 -4.89858876  2.38791987]\n",
      "Epoch:  25 Step:  57\n",
      "Weights:  [ 2.91857077 -6.6528253   1.28144053 -5.09858876  2.28791987]\n",
      "Epoch:  25 Step:  59\n",
      "Weights:  [ 3.53857077 -6.3628253   1.71144053 -4.96858876  2.38791987]\n",
      "Epoch:  25 Step:  60\n",
      "Weights:  [ 2.89857077 -6.6828253   1.18144053 -5.19858876  2.28791987]\n",
      "Epoch:  25 Step:  64\n",
      "Weights:  [ 3.50857077 -6.3828253   1.64144053 -5.05858876  2.38791987]\n",
      "Epoch:  25 Step:  65\n",
      "Weights:  [ 3.00857077 -6.7128253   1.50144053 -5.07858876  2.28791987]\n",
      "Epoch:  25 Step:  68\n",
      "Weights:  [ 2.27857077 -7.0028253   0.87144053 -5.25858876  2.18791987]\n",
      "Epoch:  25 Step:  74\n",
      "Weights:  [ 2.84857077 -6.7028253   1.29144053 -5.13858876  2.28791987]\n",
      "Epoch:  25 Step:  75\n",
      "Weights:  [ 3.43857077 -6.4028253   1.71144053 -4.98858876  2.38791987]\n",
      "Epoch:  25 Step:  76\n",
      "Weights:  [ 2.94857077 -6.6528253   1.26144053 -5.15858876  2.28791987]\n",
      "Epoch:  25 Step:  86\n",
      "Weights:  [ 3.50857077 -6.3828253   1.68144053 -5.02858876  2.38791987]\n",
      "Epoch:  25 Step:  88\n",
      "Weights:  [ 2.74857077 -6.6828253   1.02144053 -5.23858876  2.28791987]\n",
      "Epoch:  25 Step:  90\n",
      "Weights:  [ 3.31857077 -6.4228253   1.37144053 -5.13858876  2.38791987]\n",
      "Epoch:  25 Step:  92\n",
      "Weights:  [ 2.73857077 -6.6928253   0.86144053 -5.32858876  2.28791987]\n",
      "Epoch:  25 Step:  97\n",
      "Weights:  [ 3.31857077 -6.4228253   1.27144053 -5.22858876  2.38791987]\n",
      "Epoch:  25 Step:  100\n",
      "Weights:  [ 2.63857077 -6.7228253   0.72144053 -5.43858876  2.28791987]\n",
      "Epoch:  26 Step:  7\n",
      "Weights:  [ 3.26857077 -6.4928253   1.16144053 -5.30858876  2.38791987]\n",
      "Epoch:  26 Step:  11\n",
      "Weights:  [ 2.62857077 -6.7628253   0.63144053 -5.49858876  2.28791987]\n",
      "Epoch:  26 Step:  14\n",
      "Weights:  [ 3.23857077 -6.4728253   1.10144053 -5.35858876  2.38791987]\n",
      "Epoch:  26 Step:  19\n",
      "Weights:  [ 2.52857077 -6.7728253   0.51144053 -5.56858876  2.28791987]\n",
      "Epoch:  26 Step:  24\n",
      "Weights:  [ 3.18857077 -6.4728253   0.95144053 -5.42858876  2.38791987]\n",
      "Epoch:  26 Step:  26\n",
      "Weights:  [ 3.69857077 -6.2228253   1.25144053 -5.31858876  2.48791987]\n",
      "Epoch:  26 Step:  32\n",
      "Weights:  [ 3.04857077 -6.5428253   0.74144053 -5.51858876  2.38791987]\n",
      "Epoch:  26 Step:  33\n",
      "Weights:  [ 3.69857077 -6.2628253   1.20144053 -5.36858876  2.48791987]\n",
      "Epoch:  26 Step:  34\n",
      "Weights:  [ 3.21857077 -6.5628253   1.06144053 -5.37858876  2.38791987]\n",
      "Epoch:  26 Step:  35\n",
      "Weights:  [ 2.44857077 -6.8628253   0.45144053 -5.60858876  2.28791987]\n",
      "Epoch:  26 Step:  36\n",
      "Weights:  [ 3.13857077 -6.5528253   0.94144053 -5.45858876  2.38791987]\n",
      "Epoch:  26 Step:  38\n",
      "Weights:  [ 3.73857077 -6.2828253   1.45144053 -5.29858876  2.48791987]\n",
      "Epoch:  26 Step:  39\n",
      "Weights:  [ 3.20857077 -6.6528253   1.30144053 -5.31858876  2.38791987]\n",
      "Epoch:  26 Step:  41\n",
      "Weights:  [ 3.77857077 -6.3628253   1.72144053 -5.18858876  2.48791987]\n",
      "Epoch:  26 Step:  47\n",
      "Weights:  [ 3.23857077 -6.7028253   1.57144053 -5.22858876  2.38791987]\n",
      "Epoch:  26 Step:  48\n",
      "Weights:  [ 2.51857077 -7.0028253   0.99144053 -5.38858876  2.28791987]\n",
      "Epoch:  26 Step:  49\n",
      "Weights:  [ 3.17857077 -6.7128253   1.45144053 -5.25858876  2.38791987]\n",
      "Epoch:  26 Step:  54\n",
      "Weights:  [ 2.53857077 -7.0228253   0.90144053 -5.43858876  2.28791987]\n",
      "Epoch:  26 Step:  56\n",
      "Weights:  [ 3.10857077 -6.7428253   1.35144053 -5.30858876  2.38791987]\n",
      "Epoch:  26 Step:  64\n",
      "Weights:  [ 3.71857077 -6.4428253   1.81144053 -5.16858876  2.48791987]\n",
      "Epoch:  26 Step:  65\n",
      "Weights:  [ 3.21857077 -6.7728253   1.67144053 -5.18858876  2.38791987]\n",
      "Epoch:  26 Step:  68\n",
      "Weights:  [ 2.48857077 -7.0628253   1.04144053 -5.36858876  2.28791987]\n",
      "Epoch:  26 Step:  74\n",
      "Weights:  [ 3.05857077 -6.7628253   1.46144053 -5.24858876  2.38791987]\n",
      "Epoch:  26 Step:  75\n",
      "Weights:  [ 3.64857077 -6.4628253   1.88144053 -5.09858876  2.48791987]\n",
      "Epoch:  26 Step:  76\n",
      "Weights:  [ 3.15857077 -6.7128253   1.43144053 -5.26858876  2.38791987]\n",
      "Epoch:  26 Step:  77\n",
      "Weights:  [ 2.51857077 -6.9928253   0.87144053 -5.48858876  2.28791987]\n",
      "Epoch:  26 Step:  84\n",
      "Weights:  [ 3.07857077 -6.7428253   1.26144053 -5.37858876  2.38791987]\n",
      "Epoch:  26 Step:  86\n",
      "Weights:  [ 3.63857077 -6.4728253   1.68144053 -5.24858876  2.48791987]\n",
      "Epoch:  26 Step:  88\n",
      "Weights:  [ 2.87857077 -6.7728253   1.02144053 -5.45858876  2.38791987]\n",
      "Epoch:  26 Step:  90\n",
      "Weights:  [ 3.44857077 -6.5128253   1.37144053 -5.35858876  2.48791987]\n",
      "Epoch:  26 Step:  92\n",
      "Weights:  [ 2.86857077 -6.7828253   0.86144053 -5.54858876  2.38791987]\n",
      "Epoch:  26 Step:  97\n",
      "Weights:  [ 3.44857077 -6.5128253   1.27144053 -5.44858876  2.48791987]\n",
      "Epoch:  26 Step:  100\n",
      "Weights:  [ 2.76857077 -6.8128253   0.72144053 -5.65858876  2.38791987]\n",
      "Epoch:  27 Step:  7\n",
      "Weights:  [ 3.39857077 -6.5828253   1.16144053 -5.52858876  2.48791987]\n",
      "Epoch:  27 Step:  11\n",
      "Weights:  [ 2.75857077 -6.8528253   0.63144053 -5.71858876  2.38791987]\n",
      "Epoch:  27 Step:  14\n",
      "Weights:  [ 3.36857077 -6.5628253   1.10144053 -5.57858876  2.48791987]\n",
      "Epoch:  27 Step:  19\n",
      "Weights:  [ 2.65857077 -6.8628253   0.51144053 -5.78858876  2.38791987]\n",
      "Epoch:  27 Step:  24\n",
      "Weights:  [ 3.31857077 -6.5628253   0.95144053 -5.64858876  2.48791987]\n",
      "Epoch:  27 Step:  26\n",
      "Weights:  [ 3.82857077 -6.3128253   1.25144053 -5.53858876  2.58791987]\n",
      "Epoch:  27 Step:  32\n",
      "Weights:  [ 3.17857077 -6.6328253   0.74144053 -5.73858876  2.48791987]\n",
      "Epoch:  27 Step:  33\n",
      "Weights:  [ 3.82857077 -6.3528253   1.20144053 -5.58858876  2.58791987]\n",
      "Epoch:  27 Step:  34\n",
      "Weights:  [ 3.34857077 -6.6528253   1.06144053 -5.59858876  2.48791987]\n",
      "Epoch:  27 Step:  35\n",
      "Weights:  [ 2.57857077 -6.9528253   0.45144053 -5.82858876  2.38791987]\n",
      "Epoch:  27 Step:  36\n",
      "Weights:  [ 3.26857077 -6.6428253   0.94144053 -5.67858876  2.48791987]\n",
      "Epoch:  27 Step:  38\n",
      "Weights:  [ 3.86857077 -6.3728253   1.45144053 -5.51858876  2.58791987]\n",
      "Epoch:  27 Step:  39\n",
      "Weights:  [ 3.33857077 -6.7428253   1.30144053 -5.53858876  2.48791987]\n",
      "Epoch:  27 Step:  48\n",
      "Weights:  [ 2.61857077 -7.0428253   0.72144053 -5.69858876  2.38791987]\n",
      "Epoch:  27 Step:  49\n",
      "Weights:  [ 3.27857077 -6.7528253   1.18144053 -5.56858876  2.48791987]\n",
      "Epoch:  27 Step:  64\n",
      "Weights:  [ 3.88857077 -6.4528253   1.64144053 -5.42858876  2.58791987]\n",
      "Epoch:  27 Step:  65\n",
      "Weights:  [ 3.38857077 -6.7828253   1.50144053 -5.44858876  2.48791987]\n",
      "Epoch:  27 Step:  68\n",
      "Weights:  [ 2.65857077 -7.0728253   0.87144053 -5.62858876  2.38791987]\n",
      "Epoch:  27 Step:  74\n",
      "Weights:  [ 3.22857077 -6.7728253   1.29144053 -5.50858876  2.48791987]\n",
      "Epoch:  27 Step:  75\n",
      "Weights:  [ 3.81857077 -6.4728253   1.71144053 -5.35858876  2.58791987]\n",
      "Epoch:  27 Step:  76\n",
      "Weights:  [ 3.32857077 -6.7228253   1.26144053 -5.52858876  2.48791987]\n",
      "Epoch:  27 Step:  87\n",
      "Weights:  [ 3.96857077 -6.4028253   1.71144053 -5.37858876  2.58791987]\n",
      "Epoch:  27 Step:  88\n",
      "Weights:  [ 3.20857077 -6.7028253   1.05144053 -5.58858876  2.48791987]\n",
      "Epoch:  27 Step:  96\n",
      "Weights:  [ 2.75857077 -6.9328253   0.92144053 -5.61858876  2.38791987]\n",
      "Epoch:  27 Step:  97\n",
      "Weights:  [ 3.33857077 -6.6628253   1.33144053 -5.51858876  2.48791987]\n",
      "Epoch:  27 Step:  100\n",
      "Weights:  [ 2.65857077 -6.9628253   0.78144053 -5.72858876  2.38791987]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  28 Step:  7\n",
      "Weights:  [ 3.28857077 -6.7328253   1.22144053 -5.59858876  2.48791987]\n",
      "Epoch:  28 Step:  11\n",
      "Weights:  [ 2.64857077 -7.0028253   0.69144053 -5.78858876  2.38791987]\n",
      "Epoch:  28 Step:  14\n",
      "Weights:  [ 3.25857077 -6.7128253   1.16144053 -5.64858876  2.48791987]\n",
      "Epoch:  28 Step:  19\n",
      "Weights:  [ 2.54857077 -7.0128253   0.57144053 -5.85858876  2.38791987]\n",
      "Epoch:  28 Step:  24\n",
      "Weights:  [ 3.20857077 -6.7128253   1.01144053 -5.71858876  2.48791987]\n",
      "Epoch:  28 Step:  26\n",
      "Weights:  [ 3.71857077 -6.4628253   1.31144053 -5.60858876  2.58791987]\n",
      "Epoch:  28 Step:  32\n",
      "Weights:  [ 3.06857077 -6.7828253   0.80144053 -5.80858876  2.48791987]\n",
      "Epoch:  28 Step:  33\n",
      "Weights:  [ 3.71857077 -6.5028253   1.26144053 -5.65858876  2.58791987]\n",
      "Epoch:  28 Step:  34\n",
      "Weights:  [ 3.23857077 -6.8028253   1.12144053 -5.66858876  2.48791987]\n",
      "Epoch:  28 Step:  35\n",
      "Weights:  [ 2.46857077 -7.1028253   0.51144053 -5.89858876  2.38791987]\n",
      "Epoch:  28 Step:  36\n",
      "Weights:  [ 3.15857077 -6.7928253   1.00144053 -5.74858876  2.48791987]\n",
      "Epoch:  28 Step:  38\n",
      "Weights:  [ 3.75857077 -6.5228253   1.51144053 -5.58858876  2.58791987]\n",
      "Epoch:  28 Step:  47\n",
      "Weights:  [ 3.21857077 -6.8628253   1.36144053 -5.62858876  2.48791987]\n",
      "Epoch:  28 Step:  48\n",
      "Weights:  [ 2.49857077 -7.1628253   0.78144053 -5.78858876  2.38791987]\n",
      "Epoch:  28 Step:  49\n",
      "Weights:  [ 3.15857077 -6.8728253   1.24144053 -5.65858876  2.48791987]\n",
      "Epoch:  28 Step:  56\n",
      "Weights:  [ 3.72857077 -6.5928253   1.69144053 -5.52858876  2.58791987]\n",
      "Epoch:  28 Step:  57\n",
      "Weights:  [ 3.16857077 -6.8728253   1.20144053 -5.72858876  2.48791987]\n",
      "Epoch:  28 Step:  59\n",
      "Weights:  [ 3.78857077 -6.5828253   1.63144053 -5.59858876  2.58791987]\n",
      "Epoch:  28 Step:  60\n",
      "Weights:  [ 3.14857077 -6.9028253   1.10144053 -5.82858876  2.48791987]\n",
      "Epoch:  28 Step:  64\n",
      "Weights:  [ 3.75857077 -6.6028253   1.56144053 -5.68858876  2.58791987]\n",
      "Epoch:  28 Step:  65\n",
      "Weights:  [ 3.25857077 -6.9328253   1.42144053 -5.70858876  2.48791987]\n",
      "Epoch:  28 Step:  68\n",
      "Weights:  [ 2.52857077 -7.2228253   0.79144053 -5.88858876  2.38791987]\n",
      "Epoch:  28 Step:  74\n",
      "Weights:  [ 3.09857077 -6.9228253   1.21144053 -5.76858876  2.48791987]\n",
      "Epoch:  28 Step:  75\n",
      "Weights:  [ 3.68857077 -6.6228253   1.63144053 -5.61858876  2.58791987]\n",
      "Epoch:  28 Step:  76\n",
      "Weights:  [ 3.19857077 -6.8728253   1.18144053 -5.78858876  2.48791987]\n",
      "Epoch:  28 Step:  86\n",
      "Weights:  [ 3.75857077 -6.6028253   1.60144053 -5.65858876  2.58791987]\n",
      "Epoch:  28 Step:  88\n",
      "Weights:  [ 2.99857077 -6.9028253   0.94144053 -5.86858876  2.48791987]\n",
      "Epoch:  28 Step:  90\n",
      "Weights:  [ 3.56857077 -6.6428253   1.29144053 -5.76858876  2.58791987]\n",
      "Epoch:  28 Step:  92\n",
      "Weights:  [ 2.98857077 -6.9128253   0.78144053 -5.95858876  2.48791987]\n",
      "Epoch:  28 Step:  97\n",
      "Weights:  [ 3.56857077 -6.6428253   1.19144053 -5.85858876  2.58791987]\n",
      "Epoch:  28 Step:  100\n",
      "Weights:  [ 2.88857077 -6.9428253   0.64144053 -6.06858876  2.48791987]\n",
      "Epoch:  29 Step:  7\n",
      "Weights:  [ 3.51857077 -6.7128253   1.08144053 -5.93858876  2.58791987]\n",
      "Epoch:  29 Step:  8\n",
      "Weights:  [ 3.02857077 -7.0228253   0.93144053 -5.94858876  2.48791987]\n",
      "Epoch:  29 Step:  9\n",
      "Weights:  [ 3.60857077 -6.7528253   1.32144053 -5.82858876  2.58791987]\n",
      "Epoch:  29 Step:  10\n",
      "Weights:  [ 2.95857077 -7.0528253   0.74144053 -6.04858876  2.48791987]\n",
      "Epoch:  29 Step:  14\n",
      "Weights:  [ 3.56857077 -6.7628253   1.21144053 -5.90858876  2.58791987]\n",
      "Epoch:  29 Step:  19\n",
      "Weights:  [ 2.85857077 -7.0628253   0.62144053 -6.11858876  2.48791987]\n",
      "Epoch:  29 Step:  24\n",
      "Weights:  [ 3.51857077 -6.7628253   1.06144053 -5.97858876  2.58791987]\n",
      "Epoch:  29 Step:  31\n",
      "Weights:  [ 4.03857077 -6.4928253   1.45144053 -5.83858876  2.68791987]\n",
      "Epoch:  29 Step:  32\n",
      "Weights:  [ 3.38857077 -6.8128253   0.94144053 -6.03858876  2.58791987]\n",
      "Epoch:  29 Step:  35\n",
      "Weights:  [ 2.61857077 -7.1128253   0.33144053 -6.26858876  2.48791987]\n",
      "Epoch:  29 Step:  36\n",
      "Weights:  [ 3.30857077 -6.8028253   0.82144053 -6.11858876  2.58791987]\n",
      "Epoch:  29 Step:  38\n",
      "Weights:  [ 3.90857077 -6.5328253   1.33144053 -5.95858876  2.68791987]\n",
      "Epoch:  29 Step:  39\n",
      "Weights:  [ 3.37857077 -6.9028253   1.18144053 -5.97858876  2.58791987]\n",
      "Epoch:  29 Step:  41\n",
      "Weights:  [ 3.94857077 -6.6128253   1.60144053 -5.84858876  2.68791987]\n",
      "Epoch:  29 Step:  47\n",
      "Weights:  [ 3.40857077 -6.9528253   1.45144053 -5.88858876  2.58791987]\n",
      "Epoch:  29 Step:  48\n",
      "Weights:  [ 2.68857077 -7.2528253   0.87144053 -6.04858876  2.48791987]\n",
      "Epoch:  29 Step:  49\n",
      "Weights:  [ 3.34857077 -6.9628253   1.33144053 -5.91858876  2.58791987]\n",
      "Epoch:  29 Step:  64\n",
      "Weights:  [ 3.95857077 -6.6628253   1.79144053 -5.77858876  2.68791987]\n",
      "Epoch:  29 Step:  65\n",
      "Weights:  [ 3.45857077 -6.9928253   1.65144053 -5.79858876  2.58791987]\n",
      "Epoch:  29 Step:  68\n",
      "Weights:  [ 2.72857077 -7.2828253   1.02144053 -5.97858876  2.48791987]\n",
      "Epoch:  29 Step:  74\n",
      "Weights:  [ 3.29857077 -6.9828253   1.44144053 -5.85858876  2.58791987]\n",
      "Epoch:  29 Step:  75\n",
      "Weights:  [ 3.88857077 -6.6828253   1.86144053 -5.70858876  2.68791987]\n",
      "Epoch:  29 Step:  76\n",
      "Weights:  [ 3.39857077 -6.9328253   1.41144053 -5.87858876  2.58791987]\n",
      "Epoch:  29 Step:  87\n",
      "Weights:  [ 4.03857077 -6.6128253   1.86144053 -5.72858876  2.68791987]\n",
      "Epoch:  29 Step:  88\n",
      "Weights:  [ 3.27857077 -6.9128253   1.20144053 -5.93858876  2.58791987]\n",
      "Epoch:  29 Step:  96\n",
      "Weights:  [ 2.82857077 -7.1428253   1.07144053 -5.96858876  2.48791987]\n",
      "Epoch:  29 Step:  97\n",
      "Weights:  [ 3.40857077 -6.8728253   1.48144053 -5.86858876  2.58791987]\n",
      "Epoch:  29 Step:  100\n",
      "Weights:  [ 2.72857077 -7.1728253   0.93144053 -6.07858876  2.48791987]\n",
      "Epoch:  30 Step:  7\n",
      "Weights:  [ 3.35857077 -6.9428253   1.37144053 -5.94858876  2.58791987]\n",
      "Epoch:  30 Step:  11\n",
      "Weights:  [ 2.71857077 -7.2128253   0.84144053 -6.13858876  2.48791987]\n",
      "Epoch:  30 Step:  14\n",
      "Weights:  [ 3.32857077 -6.9228253   1.31144053 -5.99858876  2.58791987]\n",
      "Epoch:  30 Step:  19\n",
      "Weights:  [ 2.61857077 -7.2228253   0.72144053 -6.20858876  2.48791987]\n",
      "Epoch:  30 Step:  24\n",
      "Weights:  [ 3.27857077 -6.9228253   1.16144053 -6.06858876  2.58791987]\n",
      "Epoch:  30 Step:  26\n",
      "Weights:  [ 3.78857077 -6.6728253   1.46144053 -5.95858876  2.68791987]\n",
      "Epoch:  30 Step:  32\n",
      "Weights:  [ 3.13857077 -6.9928253   0.95144053 -6.15858876  2.58791987]\n",
      "Epoch:  30 Step:  33\n",
      "Weights:  [ 3.78857077 -6.7128253   1.41144053 -6.00858876  2.68791987]\n",
      "Epoch:  30 Step:  34\n",
      "Weights:  [ 3.30857077 -7.0128253   1.27144053 -6.01858876  2.58791987]\n",
      "Epoch:  30 Step:  35\n",
      "Weights:  [ 2.53857077 -7.3128253   0.66144053 -6.24858876  2.48791987]\n",
      "Epoch:  30 Step:  36\n",
      "Weights:  [ 3.22857077 -7.0028253   1.15144053 -6.09858876  2.58791987]\n",
      "Epoch:  30 Step:  38\n",
      "Weights:  [ 3.82857077 -6.7328253   1.66144053 -5.93858876  2.68791987]\n",
      "Epoch:  30 Step:  47\n",
      "Weights:  [ 3.28857077 -7.0728253   1.51144053 -5.97858876  2.58791987]\n",
      "Epoch:  30 Step:  48\n",
      "Weights:  [ 2.56857077 -7.3728253   0.93144053 -6.13858876  2.48791987]\n",
      "Epoch:  30 Step:  49\n",
      "Weights:  [ 3.22857077 -7.0828253   1.39144053 -6.00858876  2.58791987]\n",
      "Epoch:  30 Step:  56\n",
      "Weights:  [ 3.79857077 -6.8028253   1.84144053 -5.87858876  2.68791987]\n",
      "Epoch:  30 Step:  57\n",
      "Weights:  [ 3.23857077 -7.0828253   1.35144053 -6.07858876  2.58791987]\n",
      "Epoch:  30 Step:  64\n",
      "Weights:  [ 3.84857077 -6.7828253   1.81144053 -5.93858876  2.68791987]\n",
      "Epoch:  30 Step:  65\n",
      "Weights:  [ 3.34857077 -7.1128253   1.67144053 -5.95858876  2.58791987]\n",
      "Epoch:  30 Step:  68\n",
      "Weights:  [ 2.61857077 -7.4028253   1.04144053 -6.13858876  2.48791987]\n",
      "Epoch:  30 Step:  74\n",
      "Weights:  [ 3.18857077 -7.1028253   1.46144053 -6.01858876  2.58791987]\n",
      "Epoch:  30 Step:  75\n",
      "Weights:  [ 3.77857077 -6.8028253   1.88144053 -5.86858876  2.68791987]\n",
      "Epoch:  30 Step:  76\n",
      "Weights:  [ 3.28857077 -7.0528253   1.43144053 -6.03858876  2.58791987]\n",
      "Epoch:  30 Step:  87\n",
      "Weights:  [ 3.92857077 -6.7328253   1.88144053 -5.88858876  2.68791987]\n",
      "Epoch:  30 Step:  88\n",
      "Weights:  [ 3.16857077 -7.0328253   1.22144053 -6.09858876  2.58791987]\n",
      "Epoch:  30 Step:  96\n",
      "Weights:  [ 2.71857077 -7.2628253   1.09144053 -6.12858876  2.48791987]\n",
      "Epoch:  30 Step:  97\n",
      "Weights:  [ 3.29857077 -6.9928253   1.50144053 -6.02858876  2.58791987]\n",
      "Epoch:  31 Step:  2\n",
      "Weights:  [ 2.69857077 -7.2128253   1.00144053 -6.17858876  2.48791987]\n",
      "Epoch:  31 Step:  7\n",
      "Weights:  [ 3.32857077 -6.9828253   1.44144053 -6.04858876  2.58791987]\n",
      "Epoch:  31 Step:  11\n",
      "Weights:  [ 2.68857077 -7.2528253   0.91144053 -6.23858876  2.48791987]\n",
      "Epoch:  31 Step:  14\n",
      "Weights:  [ 3.29857077 -6.9628253   1.38144053 -6.09858876  2.58791987]\n",
      "Epoch:  31 Step:  19\n",
      "Weights:  [ 2.58857077 -7.2628253   0.79144053 -6.30858876  2.48791987]\n",
      "Epoch:  31 Step:  24\n",
      "Weights:  [ 3.24857077 -6.9628253   1.23144053 -6.16858876  2.58791987]\n",
      "Epoch:  31 Step:  26\n",
      "Weights:  [ 3.75857077 -6.7128253   1.53144053 -6.05858876  2.68791987]\n",
      "Epoch:  31 Step:  32\n",
      "Weights:  [ 3.10857077 -7.0328253   1.02144053 -6.25858876  2.58791987]\n",
      "Epoch:  31 Step:  33\n",
      "Weights:  [ 3.75857077 -6.7528253   1.48144053 -6.10858876  2.68791987]\n",
      "Epoch:  31 Step:  34\n",
      "Weights:  [ 3.27857077 -7.0528253   1.34144053 -6.11858876  2.58791987]\n",
      "Epoch:  31 Step:  35\n",
      "Weights:  [ 2.50857077 -7.3528253   0.73144053 -6.34858876  2.48791987]\n",
      "Epoch:  31 Step:  36\n",
      "Weights:  [ 3.19857077 -7.0428253   1.22144053 -6.19858876  2.58791987]\n",
      "Epoch:  31 Step:  38\n",
      "Weights:  [ 3.79857077 -6.7728253   1.73144053 -6.03858876  2.68791987]\n",
      "Epoch:  31 Step:  47\n",
      "Weights:  [ 3.25857077 -7.1128253   1.58144053 -6.07858876  2.58791987]\n",
      "Epoch:  31 Step:  48\n",
      "Weights:  [ 2.53857077 -7.4128253   1.00144053 -6.23858876  2.48791987]\n",
      "Epoch:  31 Step:  49\n",
      "Weights:  [ 3.19857077 -7.1228253   1.46144053 -6.10858876  2.58791987]\n",
      "Epoch:  31 Step:  56\n",
      "Weights:  [ 3.76857077 -6.8428253   1.91144053 -5.97858876  2.68791987]\n",
      "Epoch:  31 Step:  57\n",
      "Weights:  [ 3.20857077 -7.1228253   1.42144053 -6.17858876  2.58791987]\n",
      "Epoch:  31 Step:  59\n",
      "Weights:  [ 3.82857077 -6.8328253   1.85144053 -6.04858876  2.68791987]\n",
      "Epoch:  31 Step:  60\n",
      "Weights:  [ 3.18857077 -7.1528253   1.32144053 -6.27858876  2.58791987]\n",
      "Epoch:  31 Step:  64\n",
      "Weights:  [ 3.79857077 -6.8528253   1.78144053 -6.13858876  2.68791987]\n",
      "Epoch:  31 Step:  65\n",
      "Weights:  [ 3.29857077 -7.1828253   1.64144053 -6.15858876  2.58791987]\n",
      "Epoch:  31 Step:  68\n",
      "Weights:  [ 2.56857077 -7.4728253   1.01144053 -6.33858876  2.48791987]\n",
      "Epoch:  31 Step:  74\n",
      "Weights:  [ 3.13857077 -7.1728253   1.43144053 -6.21858876  2.58791987]\n",
      "Epoch:  31 Step:  75\n",
      "Weights:  [ 3.72857077 -6.8728253   1.85144053 -6.06858876  2.68791987]\n",
      "Epoch:  31 Step:  76\n",
      "Weights:  [ 3.23857077 -7.1228253   1.40144053 -6.23858876  2.58791987]\n",
      "Epoch:  31 Step:  86\n",
      "Weights:  [ 3.79857077 -6.8528253   1.82144053 -6.10858876  2.68791987]\n",
      "Epoch:  31 Step:  88\n",
      "Weights:  [ 3.03857077 -7.1528253   1.16144053 -6.31858876  2.58791987]\n",
      "Epoch:  31 Step:  90\n",
      "Weights:  [ 3.60857077 -6.8928253   1.51144053 -6.21858876  2.68791987]\n",
      "Epoch:  31 Step:  92\n",
      "Weights:  [ 3.02857077 -7.1628253   1.00144053 -6.40858876  2.58791987]\n",
      "Epoch:  31 Step:  97\n",
      "Weights:  [ 3.60857077 -6.8928253   1.41144053 -6.30858876  2.68791987]\n",
      "Epoch:  31 Step:  100\n",
      "Weights:  [ 2.92857077 -7.1928253   0.86144053 -6.51858876  2.58791987]\n",
      "Epoch:  32 Step:  7\n",
      "Weights:  [ 3.55857077 -6.9628253   1.30144053 -6.38858876  2.68791987]\n",
      "Epoch:  32 Step:  11\n",
      "Weights:  [ 2.91857077 -7.2328253   0.77144053 -6.57858876  2.58791987]\n",
      "Epoch:  32 Step:  14\n",
      "Weights:  [ 3.52857077 -6.9428253   1.24144053 -6.43858876  2.68791987]\n",
      "Epoch:  32 Step:  19\n",
      "Weights:  [ 2.81857077 -7.2428253   0.65144053 -6.64858876  2.58791987]\n",
      "Epoch:  32 Step:  24\n",
      "Weights:  [ 3.47857077 -6.9428253   1.09144053 -6.50858876  2.68791987]\n",
      "Epoch:  32 Step:  26\n",
      "Weights:  [ 3.98857077 -6.6928253   1.39144053 -6.39858876  2.78791987]\n",
      "Epoch:  32 Step:  32\n",
      "Weights:  [ 3.33857077 -7.0128253   0.88144053 -6.59858876  2.68791987]\n",
      "Epoch:  32 Step:  33\n",
      "Weights:  [ 3.98857077 -6.7328253   1.34144053 -6.44858876  2.78791987]\n",
      "Epoch:  32 Step:  34\n",
      "Weights:  [ 3.50857077 -7.0328253   1.20144053 -6.45858876  2.68791987]\n",
      "Epoch:  32 Step:  35\n",
      "Weights:  [ 2.73857077 -7.3328253   0.59144053 -6.68858876  2.58791987]\n",
      "Epoch:  32 Step:  36\n",
      "Weights:  [ 3.42857077 -7.0228253   1.08144053 -6.53858876  2.68791987]\n",
      "Epoch:  32 Step:  38\n",
      "Weights:  [ 4.02857077 -6.7528253   1.59144053 -6.37858876  2.78791987]\n",
      "Epoch:  32 Step:  39\n",
      "Weights:  [ 3.49857077 -7.1228253   1.44144053 -6.39858876  2.68791987]\n",
      "Epoch:  32 Step:  41\n",
      "Weights:  [ 4.06857077 -6.8328253   1.86144053 -6.26858876  2.78791987]\n",
      "Epoch:  32 Step:  47\n",
      "Weights:  [ 3.52857077 -7.1728253   1.71144053 -6.30858876  2.68791987]\n",
      "Epoch:  32 Step:  48\n",
      "Weights:  [ 2.80857077 -7.4728253   1.13144053 -6.46858876  2.58791987]\n",
      "Epoch:  32 Step:  49\n",
      "Weights:  [ 3.46857077 -7.1828253   1.59144053 -6.33858876  2.68791987]\n",
      "Epoch:  32 Step:  68\n",
      "Weights:  [ 2.73857077 -7.4728253   0.96144053 -6.51858876  2.58791987]\n",
      "Epoch:  32 Step:  74\n",
      "Weights:  [ 3.30857077 -7.1728253   1.38144053 -6.39858876  2.68791987]\n",
      "Epoch:  32 Step:  75\n",
      "Weights:  [ 3.89857077 -6.8728253   1.80144053 -6.24858876  2.78791987]\n",
      "Epoch:  32 Step:  76\n",
      "Weights:  [ 3.40857077 -7.1228253   1.35144053 -6.41858876  2.68791987]\n",
      "Epoch:  32 Step:  86\n",
      "Weights:  [ 3.96857077 -6.8528253   1.77144053 -6.28858876  2.78791987]\n",
      "Epoch:  32 Step:  88\n",
      "Weights:  [ 3.20857077 -7.1528253   1.11144053 -6.49858876  2.68791987]\n",
      "Epoch:  32 Step:  90\n",
      "Weights:  [ 3.77857077 -6.8928253   1.46144053 -6.39858876  2.78791987]\n",
      "Epoch:  32 Step:  92\n",
      "Weights:  [ 3.19857077 -7.1628253   0.95144053 -6.58858876  2.68791987]\n",
      "Epoch:  32 Step:  97\n",
      "Weights:  [ 3.77857077 -6.8928253   1.36144053 -6.48858876  2.78791987]\n",
      "Epoch:  32 Step:  100\n",
      "Weights:  [ 3.09857077 -7.1928253   0.81144053 -6.69858876  2.68791987]\n",
      "Epoch:  33 Step:  9\n",
      "Weights:  [ 3.67857077 -6.9228253   1.20144053 -6.57858876  2.78791987]\n",
      "Epoch:  33 Step:  11\n",
      "Weights:  [ 3.03857077 -7.1928253   0.67144053 -6.76858876  2.68791987]\n",
      "Epoch:  33 Step:  14\n",
      "Weights:  [ 3.64857077 -6.9028253   1.14144053 -6.62858876  2.78791987]\n",
      "Epoch:  33 Step:  19\n",
      "Weights:  [ 2.93857077 -7.2028253   0.55144053 -6.83858876  2.68791987]\n",
      "Epoch:  33 Step:  24\n",
      "Weights:  [ 3.59857077 -6.9028253   0.99144053 -6.69858876  2.78791987]\n",
      "Epoch:  33 Step:  26\n",
      "Weights:  [ 4.10857077 -6.6528253   1.29144053 -6.58858876  2.88791987]\n",
      "Epoch:  33 Step:  32\n",
      "Weights:  [ 3.45857077 -6.9728253   0.78144053 -6.78858876  2.78791987]\n",
      "Epoch:  33 Step:  33\n",
      "Weights:  [ 4.10857077 -6.6928253   1.24144053 -6.63858876  2.88791987]\n",
      "Epoch:  33 Step:  34\n",
      "Weights:  [ 3.62857077 -6.9928253   1.10144053 -6.64858876  2.78791987]\n",
      "Epoch:  33 Step:  35\n",
      "Weights:  [ 2.85857077 -7.2928253   0.49144053 -6.87858876  2.68791987]\n",
      "Epoch:  33 Step:  36\n",
      "Weights:  [ 3.54857077 -6.9828253   0.98144053 -6.72858876  2.78791987]\n",
      "Epoch:  33 Step:  38\n",
      "Weights:  [ 4.14857077 -6.7128253   1.49144053 -6.56858876  2.88791987]\n",
      "Epoch:  33 Step:  39\n",
      "Weights:  [ 3.61857077 -7.0828253   1.34144053 -6.58858876  2.78791987]\n",
      "Epoch:  33 Step:  41\n",
      "Weights:  [ 4.18857077 -6.7928253   1.76144053 -6.45858876  2.88791987]\n",
      "Epoch:  33 Step:  47\n",
      "Weights:  [ 3.64857077 -7.1328253   1.61144053 -6.49858876  2.78791987]\n",
      "Epoch:  33 Step:  48\n",
      "Weights:  [ 2.92857077 -7.4328253   1.03144053 -6.65858876  2.68791987]\n",
      "Epoch:  33 Step:  49\n",
      "Weights:  [ 3.58857077 -7.1428253   1.49144053 -6.52858876  2.78791987]\n",
      "Epoch:  33 Step:  54\n",
      "Weights:  [ 2.94857077 -7.4528253   0.94144053 -6.70858876  2.68791987]\n",
      "Epoch:  33 Step:  56\n",
      "Weights:  [ 3.51857077 -7.1728253   1.39144053 -6.57858876  2.78791987]\n",
      "Epoch:  33 Step:  64\n",
      "Weights:  [ 4.12857077 -6.8728253   1.85144053 -6.43858876  2.88791987]\n",
      "Epoch:  33 Step:  65\n",
      "Weights:  [ 3.62857077 -7.2028253   1.71144053 -6.45858876  2.78791987]\n",
      "Epoch:  33 Step:  68\n",
      "Weights:  [ 2.89857077 -7.4928253   1.08144053 -6.63858876  2.68791987]\n",
      "Epoch:  33 Step:  74\n",
      "Weights:  [ 3.46857077 -7.1928253   1.50144053 -6.51858876  2.78791987]\n",
      "Epoch:  33 Step:  75\n",
      "Weights:  [ 4.05857077 -6.8928253   1.92144053 -6.36858876  2.88791987]\n",
      "Epoch:  33 Step:  76\n",
      "Weights:  [ 3.56857077 -7.1428253   1.47144053 -6.53858876  2.78791987]\n",
      "Epoch:  33 Step:  87\n",
      "Weights:  [ 4.20857077 -6.8228253   1.92144053 -6.38858876  2.88791987]\n",
      "Epoch:  33 Step:  88\n",
      "Weights:  [ 3.44857077 -7.1228253   1.26144053 -6.59858876  2.78791987]\n",
      "Epoch:  33 Step:  96\n",
      "Weights:  [ 2.99857077 -7.3528253   1.13144053 -6.62858876  2.68791987]\n",
      "Epoch:  33 Step:  97\n",
      "Weights:  [ 3.57857077 -7.0828253   1.54144053 -6.52858876  2.78791987]\n",
      "Epoch:  33 Step:  100\n",
      "Weights:  [ 2.89857077 -7.3828253   0.99144053 -6.73858876  2.68791987]\n",
      "Epoch:  34 Step:  7\n",
      "Weights:  [ 3.52857077 -7.1528253   1.43144053 -6.60858876  2.78791987]\n",
      "Epoch:  34 Step:  11\n",
      "Weights:  [ 2.88857077 -7.4228253   0.90144053 -6.79858876  2.68791987]\n",
      "Epoch:  34 Step:  14\n",
      "Weights:  [ 3.49857077 -7.1328253   1.37144053 -6.65858876  2.78791987]\n",
      "Epoch:  34 Step:  19\n",
      "Weights:  [ 2.78857077 -7.4328253   0.78144053 -6.86858876  2.68791987]\n",
      "Epoch:  34 Step:  24\n",
      "Weights:  [ 3.44857077 -7.1328253   1.22144053 -6.72858876  2.78791987]\n",
      "Epoch:  34 Step:  26\n",
      "Weights:  [ 3.95857077 -6.8828253   1.52144053 -6.61858876  2.88791987]\n",
      "Epoch:  34 Step:  32\n",
      "Weights:  [ 3.30857077 -7.2028253   1.01144053 -6.81858876  2.78791987]\n",
      "Epoch:  34 Step:  33\n",
      "Weights:  [ 3.95857077 -6.9228253   1.47144053 -6.66858876  2.88791987]\n",
      "Epoch:  34 Step:  34\n",
      "Weights:  [ 3.47857077 -7.2228253   1.33144053 -6.67858876  2.78791987]\n",
      "Epoch:  34 Step:  35\n",
      "Weights:  [ 2.70857077 -7.5228253   0.72144053 -6.90858876  2.68791987]\n",
      "Epoch:  34 Step:  36\n",
      "Weights:  [ 3.39857077 -7.2128253   1.21144053 -6.75858876  2.78791987]\n",
      "Epoch:  34 Step:  38\n",
      "Weights:  [ 3.99857077 -6.9428253   1.72144053 -6.59858876  2.88791987]\n",
      "Epoch:  34 Step:  47\n",
      "Weights:  [ 3.45857077 -7.2828253   1.57144053 -6.63858876  2.78791987]\n",
      "Epoch:  34 Step:  48\n",
      "Weights:  [ 2.73857077 -7.5828253   0.99144053 -6.79858876  2.68791987]\n",
      "Epoch:  34 Step:  49\n",
      "Weights:  [ 3.39857077 -7.2928253   1.45144053 -6.66858876  2.78791987]\n",
      "Epoch:  34 Step:  56\n",
      "Weights:  [ 3.96857077 -7.0128253   1.90144053 -6.53858876  2.88791987]\n",
      "Epoch:  34 Step:  57\n",
      "Weights:  [ 3.40857077 -7.2928253   1.41144053 -6.73858876  2.78791987]\n",
      "Epoch:  34 Step:  64\n",
      "Weights:  [ 4.01857077 -6.9928253   1.87144053 -6.59858876  2.88791987]\n",
      "Epoch:  34 Step:  65\n",
      "Weights:  [ 3.51857077 -7.3228253   1.73144053 -6.61858876  2.78791987]\n",
      "Epoch:  34 Step:  68\n",
      "Weights:  [ 2.78857077 -7.6128253   1.10144053 -6.79858876  2.68791987]\n",
      "Epoch:  34 Step:  74\n",
      "Weights:  [ 3.35857077 -7.3128253   1.52144053 -6.67858876  2.78791987]\n",
      "Epoch:  34 Step:  75\n",
      "Weights:  [ 3.94857077 -7.0128253   1.94144053 -6.52858876  2.88791987]\n",
      "Epoch:  34 Step:  76\n",
      "Weights:  [ 3.45857077 -7.2628253   1.49144053 -6.69858876  2.78791987]\n",
      "Epoch:  34 Step:  87\n",
      "Weights:  [ 4.09857077 -6.9428253   1.94144053 -6.54858876  2.88791987]\n",
      "Epoch:  34 Step:  88\n",
      "Weights:  [ 3.33857077 -7.2428253   1.28144053 -6.75858876  2.78791987]\n",
      "Epoch:  34 Step:  96\n",
      "Weights:  [ 2.88857077 -7.4728253   1.15144053 -6.78858876  2.68791987]\n",
      "Epoch:  34 Step:  97\n",
      "Weights:  [ 3.46857077 -7.2028253   1.56144053 -6.68858876  2.78791987]\n",
      "Epoch:  35 Step:  2\n",
      "Weights:  [ 2.86857077 -7.4228253   1.06144053 -6.83858876  2.68791987]\n",
      "Epoch:  35 Step:  7\n",
      "Weights:  [ 3.49857077 -7.1928253   1.50144053 -6.70858876  2.78791987]\n",
      "Epoch:  35 Step:  11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights:  [ 2.85857077 -7.4628253   0.97144053 -6.89858876  2.68791987]\n",
      "Epoch:  35 Step:  14\n",
      "Weights:  [ 3.46857077 -7.1728253   1.44144053 -6.75858876  2.78791987]\n",
      "Epoch:  35 Step:  19\n",
      "Weights:  [ 2.75857077 -7.4728253   0.85144053 -6.96858876  2.68791987]\n",
      "Epoch:  35 Step:  24\n",
      "Weights:  [ 3.41857077 -7.1728253   1.29144053 -6.82858876  2.78791987]\n",
      "Epoch:  35 Step:  26\n",
      "Weights:  [ 3.92857077 -6.9228253   1.59144053 -6.71858876  2.88791987]\n",
      "Epoch:  35 Step:  32\n",
      "Weights:  [ 3.27857077 -7.2428253   1.08144053 -6.91858876  2.78791987]\n",
      "Epoch:  35 Step:  33\n",
      "Weights:  [ 3.92857077 -6.9628253   1.54144053 -6.76858876  2.88791987]\n",
      "Epoch:  35 Step:  34\n",
      "Weights:  [ 3.44857077 -7.2628253   1.40144053 -6.77858876  2.78791987]\n",
      "Epoch:  35 Step:  35\n",
      "Weights:  [ 2.67857077 -7.5628253   0.79144053 -7.00858876  2.68791987]\n",
      "Epoch:  35 Step:  36\n",
      "Weights:  [ 3.36857077 -7.2528253   1.28144053 -6.85858876  2.78791987]\n",
      "Epoch:  35 Step:  38\n",
      "Weights:  [ 3.96857077 -6.9828253   1.79144053 -6.69858876  2.88791987]\n",
      "Epoch:  35 Step:  47\n",
      "Weights:  [ 3.42857077 -7.3228253   1.64144053 -6.73858876  2.78791987]\n",
      "Epoch:  35 Step:  48\n",
      "Weights:  [ 2.70857077 -7.6228253   1.06144053 -6.89858876  2.68791987]\n",
      "Epoch:  35 Step:  49\n",
      "Weights:  [ 3.36857077 -7.3328253   1.52144053 -6.76858876  2.78791987]\n",
      "Epoch:  35 Step:  56\n",
      "Weights:  [ 3.93857077 -7.0528253   1.97144053 -6.63858876  2.88791987]\n",
      "Epoch:  35 Step:  57\n",
      "Weights:  [ 3.37857077 -7.3328253   1.48144053 -6.83858876  2.78791987]\n",
      "Epoch:  35 Step:  59\n",
      "Weights:  [ 3.99857077 -7.0428253   1.91144053 -6.70858876  2.88791987]\n",
      "Epoch:  35 Step:  60\n",
      "Weights:  [ 3.35857077 -7.3628253   1.38144053 -6.93858876  2.78791987]\n",
      "Epoch:  35 Step:  64\n",
      "Weights:  [ 3.96857077 -7.0628253   1.84144053 -6.79858876  2.88791987]\n",
      "Epoch:  35 Step:  65\n",
      "Weights:  [ 3.46857077 -7.3928253   1.70144053 -6.81858876  2.78791987]\n",
      "Epoch:  35 Step:  68\n",
      "Weights:  [ 2.73857077 -7.6828253   1.07144053 -6.99858876  2.68791987]\n",
      "Epoch:  35 Step:  74\n",
      "Weights:  [ 3.30857077 -7.3828253   1.49144053 -6.87858876  2.78791987]\n",
      "Epoch:  35 Step:  75\n",
      "Weights:  [ 3.89857077 -7.0828253   1.91144053 -6.72858876  2.88791987]\n",
      "Epoch:  35 Step:  76\n",
      "Weights:  [ 3.40857077 -7.3328253   1.46144053 -6.89858876  2.78791987]\n",
      "Epoch:  35 Step:  86\n",
      "Weights:  [ 3.96857077 -7.0628253   1.88144053 -6.76858876  2.88791987]\n",
      "Epoch:  35 Step:  88\n",
      "Weights:  [ 3.20857077 -7.3628253   1.22144053 -6.97858876  2.78791987]\n",
      "Epoch:  35 Step:  90\n",
      "Weights:  [ 3.77857077 -7.1028253   1.57144053 -6.87858876  2.88791987]\n",
      "Epoch:  35 Step:  92\n",
      "Weights:  [ 3.19857077 -7.3728253   1.06144053 -7.06858876  2.78791987]\n",
      "Epoch:  35 Step:  97\n",
      "Weights:  [ 3.77857077 -7.1028253   1.47144053 -6.96858876  2.88791987]\n",
      "Epoch:  35 Step:  100\n",
      "Weights:  [ 3.09857077 -7.4028253   0.92144053 -7.17858876  2.78791987]\n",
      "Epoch:  36 Step:  9\n",
      "Weights:  [ 3.67857077 -7.1328253   1.31144053 -7.05858876  2.88791987]\n",
      "Epoch:  36 Step:  11\n",
      "Weights:  [ 3.03857077 -7.4028253   0.78144053 -7.24858876  2.78791987]\n",
      "Epoch:  36 Step:  14\n",
      "Weights:  [ 3.64857077 -7.1128253   1.25144053 -7.10858876  2.88791987]\n",
      "Epoch:  36 Step:  22\n",
      "Weights:  [ 3.01857077 -7.3628253   0.75144053 -7.29858876  2.78791987]\n",
      "Epoch:  36 Step:  24\n",
      "Weights:  [ 3.67857077 -7.0628253   1.19144053 -7.15858876  2.88791987]\n",
      "Epoch:  36 Step:  26\n",
      "Weights:  [ 4.18857077 -6.8128253   1.49144053 -7.04858876  2.98791987]\n",
      "Epoch:  36 Step:  32\n",
      "Weights:  [ 3.53857077 -7.1328253   0.98144053 -7.24858876  2.88791987]\n",
      "Epoch:  36 Step:  33\n",
      "Weights:  [ 4.18857077 -6.8528253   1.44144053 -7.09858876  2.98791987]\n",
      "Epoch:  36 Step:  34\n",
      "Weights:  [ 3.70857077 -7.1528253   1.30144053 -7.10858876  2.88791987]\n",
      "Epoch:  36 Step:  35\n",
      "Weights:  [ 2.93857077 -7.4528253   0.69144053 -7.33858876  2.78791987]\n",
      "Epoch:  36 Step:  36\n",
      "Weights:  [ 3.62857077 -7.1428253   1.18144053 -7.18858876  2.88791987]\n",
      "Epoch:  36 Step:  38\n",
      "Weights:  [ 4.22857077 -6.8728253   1.69144053 -7.02858876  2.98791987]\n",
      "Epoch:  36 Step:  39\n",
      "Weights:  [ 3.69857077 -7.2428253   1.54144053 -7.04858876  2.88791987]\n",
      "Epoch:  36 Step:  48\n",
      "Weights:  [ 2.97857077 -7.5428253   0.96144053 -7.20858876  2.78791987]\n",
      "Epoch:  36 Step:  49\n",
      "Weights:  [ 3.63857077 -7.2528253   1.42144053 -7.07858876  2.88791987]\n",
      "Epoch:  36 Step:  64\n",
      "Weights:  [ 4.24857077 -6.9528253   1.88144053 -6.93858876  2.98791987]\n",
      "Epoch:  36 Step:  65\n",
      "Weights:  [ 3.74857077 -7.2828253   1.74144053 -6.95858876  2.88791987]\n",
      "Epoch:  36 Step:  68\n",
      "Weights:  [ 3.01857077 -7.5728253   1.11144053 -7.13858876  2.78791987]\n",
      "Epoch:  36 Step:  74\n",
      "Weights:  [ 3.58857077 -7.2728253   1.53144053 -7.01858876  2.88791987]\n",
      "Epoch:  36 Step:  75\n",
      "Weights:  [ 4.17857077 -6.9728253   1.95144053 -6.86858876  2.98791987]\n",
      "Epoch:  36 Step:  76\n",
      "Weights:  [ 3.68857077 -7.2228253   1.50144053 -7.03858876  2.88791987]\n",
      "Epoch:  36 Step:  87\n",
      "Weights:  [ 4.32857077 -6.9028253   1.95144053 -6.88858876  2.98791987]\n",
      "Epoch:  36 Step:  88\n",
      "Weights:  [ 3.56857077 -7.2028253   1.29144053 -7.09858876  2.88791987]\n",
      "Epoch:  36 Step:  96\n",
      "Weights:  [ 3.11857077 -7.4328253   1.16144053 -7.12858876  2.78791987]\n",
      "Epoch:  36 Step:  97\n",
      "Weights:  [ 3.69857077 -7.1628253   1.57144053 -7.02858876  2.88791987]\n",
      "Epoch:  36 Step:  100\n",
      "Weights:  [ 3.01857077 -7.4628253   1.02144053 -7.23858876  2.78791987]\n",
      "Epoch:  37 Step:  7\n",
      "Weights:  [ 3.64857077 -7.2328253   1.46144053 -7.10858876  2.88791987]\n",
      "Epoch:  37 Step:  11\n",
      "Weights:  [ 3.00857077 -7.5028253   0.93144053 -7.29858876  2.78791987]\n",
      "Epoch:  37 Step:  14\n",
      "Weights:  [ 3.61857077 -7.2128253   1.40144053 -7.15858876  2.88791987]\n",
      "Epoch:  37 Step:  19\n",
      "Weights:  [ 2.90857077 -7.5128253   0.81144053 -7.36858876  2.78791987]\n",
      "Epoch:  37 Step:  24\n",
      "Weights:  [ 3.56857077 -7.2128253   1.25144053 -7.22858876  2.88791987]\n",
      "Epoch:  37 Step:  26\n",
      "Weights:  [ 4.07857077 -6.9628253   1.55144053 -7.11858876  2.98791987]\n",
      "Epoch:  37 Step:  32\n",
      "Weights:  [ 3.42857077 -7.2828253   1.04144053 -7.31858876  2.88791987]\n",
      "Epoch:  37 Step:  33\n",
      "Weights:  [ 4.07857077 -7.0028253   1.50144053 -7.16858876  2.98791987]\n",
      "Epoch:  37 Step:  34\n",
      "Weights:  [ 3.59857077 -7.3028253   1.36144053 -7.17858876  2.88791987]\n",
      "Epoch:  37 Step:  35\n",
      "Weights:  [ 2.82857077 -7.6028253   0.75144053 -7.40858876  2.78791987]\n",
      "Epoch:  37 Step:  36\n",
      "Weights:  [ 3.51857077 -7.2928253   1.24144053 -7.25858876  2.88791987]\n",
      "Epoch:  37 Step:  38\n",
      "Weights:  [ 4.11857077 -7.0228253   1.75144053 -7.09858876  2.98791987]\n",
      "Epoch:  37 Step:  39\n",
      "Weights:  [ 3.58857077 -7.3928253   1.60144053 -7.11858876  2.88791987]\n",
      "Epoch:  37 Step:  41\n",
      "Weights:  [ 4.15857077 -7.1028253   2.02144053 -6.98858876  2.98791987]\n",
      "Epoch:  37 Step:  47\n",
      "Weights:  [ 3.61857077 -7.4428253   1.87144053 -7.02858876  2.88791987]\n",
      "Epoch:  37 Step:  48\n",
      "Weights:  [ 2.89857077 -7.7428253   1.29144053 -7.18858876  2.78791987]\n",
      "Epoch:  37 Step:  49\n",
      "Weights:  [ 3.55857077 -7.4528253   1.75144053 -7.05858876  2.88791987]\n",
      "Epoch:  37 Step:  68\n",
      "Weights:  [ 2.82857077 -7.7428253   1.12144053 -7.23858876  2.78791987]\n",
      "Epoch:  37 Step:  74\n",
      "Weights:  [ 3.39857077 -7.4428253   1.54144053 -7.11858876  2.88791987]\n",
      "Epoch:  37 Step:  75\n",
      "Weights:  [ 3.98857077 -7.1428253   1.96144053 -6.96858876  2.98791987]\n",
      "Epoch:  37 Step:  76\n",
      "Weights:  [ 3.49857077 -7.3928253   1.51144053 -7.13858876  2.88791987]\n",
      "Epoch:  37 Step:  86\n",
      "Weights:  [ 4.05857077 -7.1228253   1.93144053 -7.00858876  2.98791987]\n",
      "Epoch:  37 Step:  88\n",
      "Weights:  [ 3.29857077 -7.4228253   1.27144053 -7.21858876  2.88791987]\n",
      "Epoch:  37 Step:  90\n",
      "Weights:  [ 3.86857077 -7.1628253   1.62144053 -7.11858876  2.98791987]\n",
      "Epoch:  37 Step:  92\n",
      "Weights:  [ 3.28857077 -7.4328253   1.11144053 -7.30858876  2.88791987]\n",
      "Epoch:  37 Step:  97\n",
      "Weights:  [ 3.86857077 -7.1628253   1.52144053 -7.20858876  2.98791987]\n",
      "Epoch:  37 Step:  100\n",
      "Weights:  [ 3.18857077 -7.4628253   0.97144053 -7.41858876  2.88791987]\n",
      "Epoch:  38 Step:  9\n",
      "Weights:  [ 3.76857077 -7.1928253   1.36144053 -7.29858876  2.98791987]\n",
      "Epoch:  38 Step:  11\n",
      "Weights:  [ 3.12857077 -7.4628253   0.83144053 -7.48858876  2.88791987]\n",
      "Epoch:  38 Step:  14\n",
      "Weights:  [ 3.73857077 -7.1728253   1.30144053 -7.34858876  2.98791987]\n",
      "Epoch:  38 Step:  19\n",
      "Weights:  [ 3.02857077 -7.4728253   0.71144053 -7.55858876  2.88791987]\n",
      "Epoch:  38 Step:  24\n",
      "Weights:  [ 3.68857077 -7.1728253   1.15144053 -7.41858876  2.98791987]\n",
      "Epoch:  38 Step:  26\n",
      "Weights:  [ 4.19857077 -6.9228253   1.45144053 -7.30858876  3.08791987]\n",
      "Epoch:  38 Step:  32\n",
      "Weights:  [ 3.54857077 -7.2428253   0.94144053 -7.50858876  2.98791987]\n",
      "Epoch:  38 Step:  33\n",
      "Weights:  [ 4.19857077 -6.9628253   1.40144053 -7.35858876  3.08791987]\n",
      "Epoch:  38 Step:  34\n",
      "Weights:  [ 3.71857077 -7.2628253   1.26144053 -7.36858876  2.98791987]\n",
      "Epoch:  38 Step:  35\n",
      "Weights:  [ 2.94857077 -7.5628253   0.65144053 -7.59858876  2.88791987]\n",
      "Epoch:  38 Step:  36\n",
      "Weights:  [ 3.63857077 -7.2528253   1.14144053 -7.44858876  2.98791987]\n",
      "Epoch:  38 Step:  38\n",
      "Weights:  [ 4.23857077 -6.9828253   1.65144053 -7.28858876  3.08791987]\n",
      "Epoch:  38 Step:  39\n",
      "Weights:  [ 3.70857077 -7.3528253   1.50144053 -7.30858876  2.98791987]\n",
      "Epoch:  38 Step:  41\n",
      "Weights:  [ 4.27857077 -7.0628253   1.92144053 -7.17858876  3.08791987]\n",
      "Epoch:  38 Step:  47\n",
      "Weights:  [ 3.73857077 -7.4028253   1.77144053 -7.21858876  2.98791987]\n",
      "Epoch:  38 Step:  48\n",
      "Weights:  [ 3.01857077 -7.7028253   1.19144053 -7.37858876  2.88791987]\n",
      "Epoch:  38 Step:  49\n",
      "Weights:  [ 3.67857077 -7.4128253   1.65144053 -7.24858876  2.98791987]\n",
      "Epoch:  38 Step:  68\n",
      "Weights:  [ 2.94857077 -7.7028253   1.02144053 -7.42858876  2.88791987]\n",
      "Epoch:  38 Step:  74\n",
      "Weights:  [ 3.51857077 -7.4028253   1.44144053 -7.30858876  2.98791987]\n",
      "Epoch:  38 Step:  75\n",
      "Weights:  [ 4.10857077 -7.1028253   1.86144053 -7.15858876  3.08791987]\n",
      "Epoch:  38 Step:  76\n",
      "Weights:  [ 3.61857077 -7.3528253   1.41144053 -7.32858876  2.98791987]\n",
      "Epoch:  38 Step:  86\n",
      "Weights:  [ 4.17857077 -7.0828253   1.83144053 -7.19858876  3.08791987]\n",
      "Epoch:  38 Step:  88\n",
      "Weights:  [ 3.41857077 -7.3828253   1.17144053 -7.40858876  2.98791987]\n",
      "Epoch:  38 Step:  90\n",
      "Weights:  [ 3.98857077 -7.1228253   1.52144053 -7.30858876  3.08791987]\n",
      "Epoch:  38 Step:  91\n",
      "Weights:  [ 3.51857077 -7.4428253   1.36144053 -7.32858876  2.98791987]\n",
      "Epoch:  38 Step:  96\n",
      "Weights:  [ 3.06857077 -7.6728253   1.23144053 -7.35858876  2.88791987]\n",
      "Epoch:  38 Step:  97\n",
      "Weights:  [ 3.64857077 -7.4028253   1.64144053 -7.25858876  2.98791987]\n",
      "Epoch:  39 Step:  2\n",
      "Weights:  [ 3.04857077 -7.6228253   1.14144053 -7.40858876  2.88791987]\n",
      "Epoch:  39 Step:  7\n",
      "Weights:  [ 3.67857077 -7.3928253   1.58144053 -7.27858876  2.98791987]\n",
      "Epoch:  39 Step:  11\n",
      "Weights:  [ 3.03857077 -7.6628253   1.05144053 -7.46858876  2.88791987]\n",
      "Epoch:  39 Step:  14\n",
      "Weights:  [ 3.64857077 -7.3728253   1.52144053 -7.32858876  2.98791987]\n",
      "Epoch:  39 Step:  19\n",
      "Weights:  [ 2.93857077 -7.6728253   0.93144053 -7.53858876  2.88791987]\n",
      "Epoch:  39 Step:  24\n",
      "Weights:  [ 3.59857077 -7.3728253   1.37144053 -7.39858876  2.98791987]\n",
      "Epoch:  39 Step:  26\n",
      "Weights:  [ 4.10857077 -7.1228253   1.67144053 -7.28858876  3.08791987]\n",
      "Epoch:  39 Step:  32\n",
      "Weights:  [ 3.45857077 -7.4428253   1.16144053 -7.48858876  2.98791987]\n",
      "Epoch:  39 Step:  33\n",
      "Weights:  [ 4.10857077 -7.1628253   1.62144053 -7.33858876  3.08791987]\n",
      "Epoch:  39 Step:  34\n",
      "Weights:  [ 3.62857077 -7.4628253   1.48144053 -7.34858876  2.98791987]\n",
      "Epoch:  39 Step:  35\n",
      "Weights:  [ 2.85857077 -7.7628253   0.87144053 -7.57858876  2.88791987]\n",
      "Epoch:  39 Step:  36\n",
      "Weights:  [ 3.54857077 -7.4528253   1.36144053 -7.42858876  2.98791987]\n",
      "Epoch:  39 Step:  38\n",
      "Weights:  [ 4.14857077 -7.1828253   1.87144053 -7.26858876  3.08791987]\n",
      "Epoch:  39 Step:  47\n",
      "Weights:  [ 3.60857077 -7.5228253   1.72144053 -7.30858876  2.98791987]\n",
      "Epoch:  39 Step:  48\n",
      "Weights:  [ 2.88857077 -7.8228253   1.14144053 -7.46858876  2.88791987]\n",
      "Epoch:  39 Step:  49\n",
      "Weights:  [ 3.54857077 -7.5328253   1.60144053 -7.33858876  2.98791987]\n",
      "Epoch:  39 Step:  56\n",
      "Weights:  [ 4.11857077 -7.2528253   2.05144053 -7.20858876  3.08791987]\n",
      "Epoch:  39 Step:  57\n",
      "Weights:  [ 3.55857077 -7.5328253   1.56144053 -7.40858876  2.98791987]\n",
      "Epoch:  39 Step:  64\n",
      "Weights:  [ 4.16857077 -7.2328253   2.02144053 -7.26858876  3.08791987]\n",
      "Epoch:  39 Step:  65\n",
      "Weights:  [ 3.66857077 -7.5628253   1.88144053 -7.28858876  2.98791987]\n",
      "Epoch:  39 Step:  68\n",
      "Weights:  [ 2.93857077 -7.8528253   1.25144053 -7.46858876  2.88791987]\n",
      "Epoch:  39 Step:  74\n",
      "Weights:  [ 3.50857077 -7.5528253   1.67144053 -7.34858876  2.98791987]\n",
      "Epoch:  39 Step:  75\n",
      "Weights:  [ 4.09857077 -7.2528253   2.09144053 -7.19858876  3.08791987]\n",
      "Epoch:  39 Step:  76\n",
      "Weights:  [ 3.60857077 -7.5028253   1.64144053 -7.36858876  2.98791987]\n",
      "Epoch:  39 Step:  87\n",
      "Weights:  [ 4.24857077 -7.1828253   2.09144053 -7.21858876  3.08791987]\n",
      "Epoch:  39 Step:  88\n",
      "Weights:  [ 3.48857077 -7.4828253   1.43144053 -7.42858876  2.98791987]\n",
      "Epoch:  39 Step:  96\n",
      "Weights:  [ 3.03857077 -7.7128253   1.30144053 -7.45858876  2.88791987]\n",
      "Epoch:  39 Step:  97\n",
      "Weights:  [ 3.61857077 -7.4428253   1.71144053 -7.35858876  2.98791987]\n",
      "Epoch:  40 Step:  2\n",
      "Weights:  [ 3.01857077 -7.6628253   1.21144053 -7.50858876  2.88791987]\n",
      "Epoch:  40 Step:  7\n",
      "Weights:  [ 3.64857077 -7.4328253   1.65144053 -7.37858876  2.98791987]\n",
      "Epoch:  40 Step:  11\n",
      "Weights:  [ 3.00857077 -7.7028253   1.12144053 -7.56858876  2.88791987]\n",
      "Epoch:  40 Step:  14\n",
      "Weights:  [ 3.61857077 -7.4128253   1.59144053 -7.42858876  2.98791987]\n",
      "Epoch:  40 Step:  19\n",
      "Weights:  [ 2.90857077 -7.7128253   1.00144053 -7.63858876  2.88791987]\n",
      "Epoch:  40 Step:  24\n",
      "Weights:  [ 3.56857077 -7.4128253   1.44144053 -7.49858876  2.98791987]\n",
      "Epoch:  40 Step:  26\n",
      "Weights:  [ 4.07857077 -7.1628253   1.74144053 -7.38858876  3.08791987]\n",
      "Epoch:  40 Step:  32\n",
      "Weights:  [ 3.42857077 -7.4828253   1.23144053 -7.58858876  2.98791987]\n",
      "Epoch:  40 Step:  33\n",
      "Weights:  [ 4.07857077 -7.2028253   1.69144053 -7.43858876  3.08791987]\n",
      "Epoch:  40 Step:  34\n",
      "Weights:  [ 3.59857077 -7.5028253   1.55144053 -7.44858876  2.98791987]\n",
      "Epoch:  40 Step:  35\n",
      "Weights:  [ 2.82857077 -7.8028253   0.94144053 -7.67858876  2.88791987]\n",
      "Epoch:  40 Step:  36\n",
      "Weights:  [ 3.51857077 -7.4928253   1.43144053 -7.52858876  2.98791987]\n",
      "Epoch:  40 Step:  38\n",
      "Weights:  [ 4.11857077 -7.2228253   1.94144053 -7.36858876  3.08791987]\n",
      "Epoch:  40 Step:  47\n",
      "Weights:  [ 3.57857077 -7.5628253   1.79144053 -7.40858876  2.98791987]\n",
      "Epoch:  40 Step:  48\n",
      "Weights:  [ 2.85857077 -7.8628253   1.21144053 -7.56858876  2.88791987]\n",
      "Epoch:  40 Step:  49\n",
      "Weights:  [ 3.51857077 -7.5728253   1.67144053 -7.43858876  2.98791987]\n",
      "Epoch:  40 Step:  56\n",
      "Weights:  [ 4.08857077 -7.2928253   2.12144053 -7.30858876  3.08791987]\n",
      "Epoch:  40 Step:  57\n",
      "Weights:  [ 3.52857077 -7.5728253   1.63144053 -7.50858876  2.98791987]\n",
      "Epoch:  40 Step:  64\n",
      "Weights:  [ 4.13857077 -7.2728253   2.09144053 -7.36858876  3.08791987]\n",
      "Epoch:  40 Step:  65\n",
      "Weights:  [ 3.63857077 -7.6028253   1.95144053 -7.38858876  2.98791987]\n",
      "Epoch:  40 Step:  68\n",
      "Weights:  [ 2.90857077 -7.8928253   1.32144053 -7.56858876  2.88791987]\n",
      "Epoch:  40 Step:  74\n",
      "Weights:  [ 3.47857077 -7.5928253   1.74144053 -7.44858876  2.98791987]\n",
      "Epoch:  40 Step:  75\n",
      "Weights:  [ 4.06857077 -7.2928253   2.16144053 -7.29858876  3.08791987]\n",
      "Epoch:  40 Step:  76\n",
      "Weights:  [ 3.57857077 -7.5428253   1.71144053 -7.46858876  2.98791987]\n",
      "Epoch:  40 Step:  87\n",
      "Weights:  [ 4.21857077 -7.2228253   2.16144053 -7.31858876  3.08791987]\n",
      "Epoch:  40 Step:  88\n",
      "Weights:  [ 3.45857077 -7.5228253   1.50144053 -7.52858876  2.98791987]\n",
      "Epoch:  40 Step:  96\n",
      "Weights:  [ 3.00857077 -7.7528253   1.37144053 -7.55858876  2.88791987]\n",
      "Epoch:  40 Step:  97\n",
      "Weights:  [ 3.58857077 -7.4828253   1.78144053 -7.45858876  2.98791987]\n",
      "Epoch:  41 Step:  2\n",
      "Weights:  [ 2.98857077 -7.7028253   1.28144053 -7.60858876  2.88791987]\n",
      "Epoch:  41 Step:  7\n",
      "Weights:  [ 3.61857077 -7.4728253   1.72144053 -7.47858876  2.98791987]\n",
      "Epoch:  41 Step:  11\n",
      "Weights:  [ 2.97857077 -7.7428253   1.19144053 -7.66858876  2.88791987]\n",
      "Epoch:  41 Step:  14\n",
      "Weights:  [ 3.58857077 -7.4528253   1.66144053 -7.52858876  2.98791987]\n",
      "Epoch:  41 Step:  19\n",
      "Weights:  [ 2.87857077 -7.7528253   1.07144053 -7.73858876  2.88791987]\n",
      "Epoch:  41 Step:  24\n",
      "Weights:  [ 3.53857077 -7.4528253   1.51144053 -7.59858876  2.98791987]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  41 Step:  26\n",
      "Weights:  [ 4.04857077 -7.2028253   1.81144053 -7.48858876  3.08791987]\n",
      "Epoch:  41 Step:  32\n",
      "Weights:  [ 3.39857077 -7.5228253   1.30144053 -7.68858876  2.98791987]\n",
      "Epoch:  41 Step:  33\n",
      "Weights:  [ 4.04857077 -7.2428253   1.76144053 -7.53858876  3.08791987]\n",
      "Epoch:  41 Step:  34\n",
      "Weights:  [ 3.56857077 -7.5428253   1.62144053 -7.54858876  2.98791987]\n",
      "Epoch:  41 Step:  35\n",
      "Weights:  [ 2.79857077 -7.8428253   1.01144053 -7.77858876  2.88791987]\n",
      "Epoch:  41 Step:  36\n",
      "Weights:  [ 3.48857077 -7.5328253   1.50144053 -7.62858876  2.98791987]\n",
      "Epoch:  41 Step:  38\n",
      "Weights:  [ 4.08857077 -7.2628253   2.01144053 -7.46858876  3.08791987]\n",
      "Epoch:  41 Step:  47\n",
      "Weights:  [ 3.54857077 -7.6028253   1.86144053 -7.50858876  2.98791987]\n",
      "Epoch:  41 Step:  48\n",
      "Weights:  [ 2.82857077 -7.9028253   1.28144053 -7.66858876  2.88791987]\n",
      "Epoch:  41 Step:  49\n",
      "Weights:  [ 3.48857077 -7.6128253   1.74144053 -7.53858876  2.98791987]\n",
      "Epoch:  41 Step:  56\n",
      "Weights:  [ 4.05857077 -7.3328253   2.19144053 -7.40858876  3.08791987]\n",
      "Epoch:  41 Step:  57\n",
      "Weights:  [ 3.49857077 -7.6128253   1.70144053 -7.60858876  2.98791987]\n",
      "Epoch:  41 Step:  64\n",
      "Weights:  [ 4.10857077 -7.3128253   2.16144053 -7.46858876  3.08791987]\n",
      "Epoch:  41 Step:  65\n",
      "Weights:  [ 3.60857077 -7.6428253   2.02144053 -7.48858876  2.98791987]\n",
      "Epoch:  41 Step:  68\n",
      "Weights:  [ 2.87857077 -7.9328253   1.39144053 -7.66858876  2.88791987]\n",
      "Epoch:  41 Step:  74\n",
      "Weights:  [ 3.44857077 -7.6328253   1.81144053 -7.54858876  2.98791987]\n",
      "Epoch:  41 Step:  75\n",
      "Weights:  [ 4.03857077 -7.3328253   2.23144053 -7.39858876  3.08791987]\n",
      "Epoch:  41 Step:  76\n",
      "Weights:  [ 3.54857077 -7.5828253   1.78144053 -7.56858876  2.98791987]\n",
      "Epoch:  41 Step:  87\n",
      "Weights:  [ 4.18857077 -7.2628253   2.23144053 -7.41858876  3.08791987]\n",
      "Epoch:  41 Step:  88\n",
      "Weights:  [ 3.42857077 -7.5628253   1.57144053 -7.62858876  2.98791987]\n",
      "Epoch:  41 Step:  96\n",
      "Weights:  [ 2.97857077 -7.7928253   1.44144053 -7.65858876  2.88791987]\n",
      "Epoch:  41 Step:  97\n",
      "Weights:  [ 3.55857077 -7.5228253   1.85144053 -7.55858876  2.98791987]\n",
      "Epoch:  42 Step:  2\n",
      "Weights:  [ 2.95857077 -7.7428253   1.35144053 -7.70858876  2.88791987]\n",
      "Epoch:  42 Step:  7\n",
      "Weights:  [ 3.58857077 -7.5128253   1.79144053 -7.57858876  2.98791987]\n",
      "Epoch:  42 Step:  11\n",
      "Weights:  [ 2.94857077 -7.7828253   1.26144053 -7.76858876  2.88791987]\n",
      "Epoch:  42 Step:  14\n",
      "Weights:  [ 3.55857077 -7.4928253   1.73144053 -7.62858876  2.98791987]\n",
      "Epoch:  42 Step:  22\n",
      "Weights:  [ 2.92857077 -7.7428253   1.23144053 -7.81858876  2.88791987]\n",
      "Epoch:  42 Step:  24\n",
      "Weights:  [ 3.58857077 -7.4428253   1.67144053 -7.67858876  2.98791987]\n",
      "Epoch:  42 Step:  26\n",
      "Weights:  [ 4.09857077 -7.1928253   1.97144053 -7.56858876  3.08791987]\n",
      "Epoch:  42 Step:  32\n",
      "Weights:  [ 3.44857077 -7.5128253   1.46144053 -7.76858876  2.98791987]\n",
      "Epoch:  42 Step:  33\n",
      "Weights:  [ 4.09857077 -7.2328253   1.92144053 -7.61858876  3.08791987]\n",
      "Epoch:  42 Step:  34\n",
      "Weights:  [ 3.61857077 -7.5328253   1.78144053 -7.62858876  2.98791987]\n",
      "Epoch:  42 Step:  35\n",
      "Weights:  [ 2.84857077 -7.8328253   1.17144053 -7.85858876  2.88791987]\n",
      "Epoch:  42 Step:  36\n",
      "Weights:  [ 3.53857077 -7.5228253   1.66144053 -7.70858876  2.98791987]\n",
      "Epoch:  42 Step:  41\n",
      "Weights:  [ 4.10857077 -7.2328253   2.08144053 -7.57858876  3.08791987]\n",
      "Epoch:  42 Step:  47\n",
      "Weights:  [ 3.56857077 -7.5728253   1.93144053 -7.61858876  2.98791987]\n",
      "Epoch:  42 Step:  48\n",
      "Weights:  [ 2.84857077 -7.8728253   1.35144053 -7.77858876  2.88791987]\n",
      "Epoch:  42 Step:  49\n",
      "Weights:  [ 3.50857077 -7.5828253   1.81144053 -7.64858876  2.98791987]\n",
      "Epoch:  42 Step:  56\n",
      "Weights:  [ 4.07857077 -7.3028253   2.26144053 -7.51858876  3.08791987]\n",
      "Epoch:  42 Step:  57\n",
      "Weights:  [ 3.51857077 -7.5828253   1.77144053 -7.71858876  2.98791987]\n",
      "Epoch:  42 Step:  64\n",
      "Weights:  [ 4.12857077 -7.2828253   2.23144053 -7.57858876  3.08791987]\n",
      "Epoch:  42 Step:  65\n",
      "Weights:  [ 3.62857077 -7.6128253   2.09144053 -7.59858876  2.98791987]\n",
      "Epoch:  42 Step:  68\n",
      "Weights:  [ 2.89857077 -7.9028253   1.46144053 -7.77858876  2.88791987]\n",
      "Epoch:  42 Step:  74\n",
      "Weights:  [ 3.46857077 -7.6028253   1.88144053 -7.65858876  2.98791987]\n",
      "Epoch:  42 Step:  75\n",
      "Weights:  [ 4.05857077 -7.3028253   2.30144053 -7.50858876  3.08791987]\n",
      "Epoch:  42 Step:  76\n",
      "Weights:  [ 3.56857077 -7.5528253   1.85144053 -7.67858876  2.98791987]\n",
      "Epoch:  42 Step:  87\n",
      "Weights:  [ 4.20857077 -7.2328253   2.30144053 -7.52858876  3.08791987]\n",
      "Epoch:  42 Step:  88\n",
      "Weights:  [ 3.44857077 -7.5328253   1.64144053 -7.73858876  2.98791987]\n",
      "Epoch:  42 Step:  96\n",
      "Weights:  [ 2.99857077 -7.7628253   1.51144053 -7.76858876  2.88791987]\n",
      "Epoch:  42 Step:  97\n",
      "Weights:  [ 3.57857077 -7.4928253   1.92144053 -7.66858876  2.98791987]\n",
      "Epoch:  43 Step:  2\n",
      "Weights:  [ 2.97857077 -7.7128253   1.42144053 -7.81858876  2.88791987]\n",
      "Epoch:  43 Step:  9\n",
      "Weights:  [ 3.55857077 -7.4428253   1.81144053 -7.69858876  2.98791987]\n",
      "Epoch:  43 Step:  11\n",
      "Weights:  [ 2.91857077 -7.7128253   1.28144053 -7.88858876  2.88791987]\n",
      "Epoch:  43 Step:  14\n",
      "Weights:  [ 3.52857077 -7.4228253   1.75144053 -7.74858876  2.98791987]\n",
      "Epoch:  43 Step:  22\n",
      "Weights:  [ 2.89857077 -7.6728253   1.25144053 -7.93858876  2.88791987]\n",
      "Epoch:  43 Step:  24\n",
      "Weights:  [ 3.55857077 -7.3728253   1.69144053 -7.79858876  2.98791987]\n",
      "Epoch:  43 Step:  26\n",
      "Weights:  [ 4.06857077 -7.1228253   1.99144053 -7.68858876  3.08791987]\n",
      "Epoch:  43 Step:  32\n",
      "Weights:  [ 3.41857077 -7.4428253   1.48144053 -7.88858876  2.98791987]\n",
      "Epoch:  43 Step:  33\n",
      "Weights:  [ 4.06857077 -7.1628253   1.94144053 -7.73858876  3.08791987]\n",
      "Epoch:  43 Step:  34\n",
      "Weights:  [ 3.58857077 -7.4628253   1.80144053 -7.74858876  2.98791987]\n",
      "Epoch:  43 Step:  35\n",
      "Weights:  [ 2.81857077 -7.7628253   1.19144053 -7.97858876  2.88791987]\n",
      "Epoch:  43 Step:  36\n",
      "Weights:  [ 3.50857077 -7.4528253   1.68144053 -7.82858876  2.98791987]\n",
      "Epoch:  43 Step:  38\n",
      "Weights:  [ 4.10857077 -7.1828253   2.19144053 -7.66858876  3.08791987]\n",
      "Epoch:  43 Step:  39\n",
      "Weights:  [ 3.57857077 -7.5528253   2.04144053 -7.68858876  2.98791987]\n",
      "Epoch:  43 Step:  48\n",
      "Weights:  [ 2.85857077 -7.8528253   1.46144053 -7.84858876  2.88791987]\n",
      "Epoch:  43 Step:  49\n",
      "Weights:  [ 3.51857077 -7.5628253   1.92144053 -7.71858876  2.98791987]\n",
      "Epoch:  43 Step:  64\n",
      "Weights:  [ 4.12857077 -7.2628253   2.38144053 -7.57858876  3.08791987]\n",
      "Epoch:  43 Step:  65\n",
      "Weights:  [ 3.62857077 -7.5928253   2.24144053 -7.59858876  2.98791987]\n",
      "Epoch:  43 Step:  68\n",
      "Weights:  [ 2.89857077 -7.8828253   1.61144053 -7.77858876  2.88791987]\n",
      "Epoch:  43 Step:  74\n",
      "Weights:  [ 3.46857077 -7.5828253   2.03144053 -7.65858876  2.98791987]\n",
      "Epoch:  43 Step:  75\n",
      "Weights:  [ 4.05857077 -7.2828253   2.45144053 -7.50858876  3.08791987]\n",
      "Epoch:  43 Step:  76\n",
      "Weights:  [ 3.56857077 -7.5328253   2.00144053 -7.67858876  2.98791987]\n",
      "Epoch:  43 Step:  87\n",
      "Weights:  [ 4.20857077 -7.2128253   2.45144053 -7.52858876  3.08791987]\n",
      "Epoch:  43 Step:  88\n",
      "Weights:  [ 3.44857077 -7.5128253   1.79144053 -7.73858876  2.98791987]\n",
      "Epoch:  43 Step:  96\n",
      "Weights:  [ 2.99857077 -7.7428253   1.66144053 -7.76858876  2.88791987]\n",
      "Epoch:  43 Step:  97\n",
      "Weights:  [ 3.57857077 -7.4728253   2.07144053 -7.66858876  2.98791987]\n",
      "Epoch:  43 Step:  100\n",
      "Weights:  [ 2.89857077 -7.7728253   1.52144053 -7.87858876  2.88791987]\n",
      "Epoch:  44 Step:  7\n",
      "Weights:  [ 3.52857077 -7.5428253   1.96144053 -7.74858876  2.98791987]\n",
      "Epoch:  44 Step:  11\n",
      "Weights:  [ 2.88857077 -7.8128253   1.43144053 -7.93858876  2.88791987]\n",
      "Epoch:  44 Step:  14\n",
      "Weights:  [ 3.49857077 -7.5228253   1.90144053 -7.79858876  2.98791987]\n",
      "Epoch:  44 Step:  19\n",
      "Weights:  [ 2.78857077 -7.8228253   1.31144053 -8.00858876  2.88791987]\n",
      "Epoch:  44 Step:  24\n",
      "Weights:  [ 3.44857077 -7.5228253   1.75144053 -7.86858876  2.98791987]\n",
      "Epoch:  44 Step:  26\n",
      "Weights:  [ 3.95857077 -7.2728253   2.05144053 -7.75858876  3.08791987]\n",
      "Epoch:  44 Step:  32\n",
      "Weights:  [ 3.30857077 -7.5928253   1.54144053 -7.95858876  2.98791987]\n",
      "Epoch:  44 Step:  33\n",
      "Weights:  [ 3.95857077 -7.3128253   2.00144053 -7.80858876  3.08791987]\n",
      "Epoch:  44 Step:  34\n",
      "Weights:  [ 3.47857077 -7.6128253   1.86144053 -7.81858876  2.98791987]\n",
      "Epoch:  44 Step:  35\n",
      "Weights:  [ 2.70857077 -7.9128253   1.25144053 -8.04858876  2.88791987]\n",
      "Epoch:  44 Step:  36\n",
      "Weights:  [ 3.39857077 -7.6028253   1.74144053 -7.89858876  2.98791987]\n",
      "Epoch:  44 Step:  38\n",
      "Weights:  [ 3.99857077 -7.3328253   2.25144053 -7.73858876  3.08791987]\n",
      "Epoch:  44 Step:  47\n",
      "Weights:  [ 3.45857077 -7.6728253   2.10144053 -7.77858876  2.98791987]\n",
      "Epoch:  44 Step:  48\n",
      "Weights:  [ 2.73857077 -7.9728253   1.52144053 -7.93858876  2.88791987]\n",
      "Epoch:  44 Step:  49\n",
      "Weights:  [ 3.39857077 -7.6828253   1.98144053 -7.80858876  2.98791987]\n",
      "Epoch:  44 Step:  56\n",
      "Weights:  [ 3.96857077 -7.4028253   2.43144053 -7.67858876  3.08791987]\n",
      "Epoch:  44 Step:  57\n",
      "Weights:  [ 3.40857077 -7.6828253   1.94144053 -7.87858876  2.98791987]\n",
      "Epoch:  44 Step:  59\n",
      "Weights:  [ 4.02857077 -7.3928253   2.37144053 -7.74858876  3.08791987]\n",
      "Epoch:  44 Step:  63\n",
      "Weights:  [ 3.41857077 -7.6928253   1.88144053 -7.92858876  2.98791987]\n",
      "Epoch:  44 Step:  64\n",
      "Weights:  [ 4.02857077 -7.3928253   2.34144053 -7.78858876  3.08791987]\n",
      "Epoch:  44 Step:  65\n",
      "Weights:  [ 3.52857077 -7.7228253   2.20144053 -7.80858876  2.98791987]\n",
      "Epoch:  44 Step:  68\n",
      "Weights:  [ 2.79857077 -8.0128253   1.57144053 -7.98858876  2.88791987]\n",
      "Epoch:  44 Step:  74\n",
      "Weights:  [ 3.36857077 -7.7128253   1.99144053 -7.86858876  2.98791987]\n",
      "Epoch:  44 Step:  75\n",
      "Weights:  [ 3.95857077 -7.4128253   2.41144053 -7.71858876  3.08791987]\n",
      "Epoch:  44 Step:  76\n",
      "Weights:  [ 3.46857077 -7.6628253   1.96144053 -7.88858876  2.98791987]\n",
      "Epoch:  44 Step:  86\n",
      "Weights:  [ 4.02857077 -7.3928253   2.38144053 -7.75858876  3.08791987]\n",
      "Epoch:  44 Step:  88\n",
      "Weights:  [ 3.26857077 -7.6928253   1.72144053 -7.96858876  2.98791987]\n",
      "Epoch:  44 Step:  90\n",
      "Weights:  [ 3.83857077 -7.4328253   2.07144053 -7.86858876  3.08791987]\n",
      "Epoch:  44 Step:  92\n",
      "Weights:  [ 3.25857077 -7.7028253   1.56144053 -8.05858876  2.98791987]\n",
      "Epoch:  44 Step:  97\n",
      "Weights:  [ 3.83857077 -7.4328253   1.97144053 -7.95858876  3.08791987]\n",
      "Epoch:  44 Step:  100\n",
      "Weights:  [ 3.15857077 -7.7328253   1.42144053 -8.16858876  2.98791987]\n",
      "Epoch:  45 Step:  9\n",
      "Weights:  [ 3.73857077 -7.4628253   1.81144053 -8.04858876  3.08791987]\n",
      "Epoch:  45 Step:  11\n",
      "Weights:  [ 3.09857077 -7.7328253   1.28144053 -8.23858876  2.98791987]\n",
      "Epoch:  45 Step:  14\n",
      "Weights:  [ 3.70857077 -7.4428253   1.75144053 -8.09858876  3.08791987]\n",
      "Epoch:  45 Step:  19\n",
      "Weights:  [ 2.99857077 -7.7428253   1.16144053 -8.30858876  2.98791987]\n",
      "Epoch:  45 Step:  24\n",
      "Weights:  [ 3.65857077 -7.4428253   1.60144053 -8.16858876  3.08791987]\n",
      "Epoch:  45 Step:  26\n",
      "Weights:  [ 4.16857077 -7.1928253   1.90144053 -8.05858876  3.18791987]\n",
      "Epoch:  45 Step:  32\n",
      "Weights:  [ 3.51857077 -7.5128253   1.39144053 -8.25858876  3.08791987]\n",
      "Epoch:  45 Step:  33\n",
      "Weights:  [ 4.16857077 -7.2328253   1.85144053 -8.10858876  3.18791987]\n",
      "Epoch:  45 Step:  34\n",
      "Weights:  [ 3.68857077 -7.5328253   1.71144053 -8.11858876  3.08791987]\n",
      "Epoch:  45 Step:  35\n",
      "Weights:  [ 2.91857077 -7.8328253   1.10144053 -8.34858876  2.98791987]\n",
      "Epoch:  45 Step:  36\n",
      "Weights:  [ 3.60857077 -7.5228253   1.59144053 -8.19858876  3.08791987]\n",
      "Epoch:  45 Step:  38\n",
      "Weights:  [ 4.20857077 -7.2528253   2.10144053 -8.03858876  3.18791987]\n",
      "Epoch:  45 Step:  39\n",
      "Weights:  [ 3.67857077 -7.6228253   1.95144053 -8.05858876  3.08791987]\n",
      "Epoch:  45 Step:  41\n",
      "Weights:  [ 4.24857077 -7.3328253   2.37144053 -7.92858876  3.18791987]\n",
      "Epoch:  45 Step:  47\n",
      "Weights:  [ 3.70857077 -7.6728253   2.22144053 -7.96858876  3.08791987]\n",
      "Epoch:  45 Step:  48\n",
      "Weights:  [ 2.98857077 -7.9728253   1.64144053 -8.12858876  2.98791987]\n",
      "Epoch:  45 Step:  49\n",
      "Weights:  [ 3.64857077 -7.6828253   2.10144053 -7.99858876  3.08791987]\n",
      "Epoch:  45 Step:  68\n",
      "Weights:  [ 2.91857077 -7.9728253   1.47144053 -8.17858876  2.98791987]\n",
      "Epoch:  45 Step:  74\n",
      "Weights:  [ 3.48857077 -7.6728253   1.89144053 -8.05858876  3.08791987]\n",
      "Epoch:  45 Step:  75\n",
      "Weights:  [ 4.07857077 -7.3728253   2.31144053 -7.90858876  3.18791987]\n",
      "Epoch:  45 Step:  76\n",
      "Weights:  [ 3.58857077 -7.6228253   1.86144053 -8.07858876  3.08791987]\n",
      "Epoch:  45 Step:  86\n",
      "Weights:  [ 4.14857077 -7.3528253   2.28144053 -7.94858876  3.18791987]\n",
      "Epoch:  45 Step:  88\n",
      "Weights:  [ 3.38857077 -7.6528253   1.62144053 -8.15858876  3.08791987]\n",
      "Epoch:  45 Step:  96\n",
      "Weights:  [ 2.93857077 -7.8828253   1.49144053 -8.18858876  2.98791987]\n",
      "Epoch:  45 Step:  97\n",
      "Weights:  [ 3.51857077 -7.6128253   1.90144053 -8.08858876  3.08791987]\n",
      "Epoch:  46 Step:  2\n",
      "Weights:  [ 2.91857077 -7.8328253   1.40144053 -8.23858876  2.98791987]\n",
      "Epoch:  46 Step:  7\n",
      "Weights:  [ 3.54857077 -7.6028253   1.84144053 -8.10858876  3.08791987]\n",
      "Epoch:  46 Step:  12\n",
      "Weights:  [ 2.93857077 -7.8628253   1.28144053 -8.24858876  2.98791987]\n",
      "Epoch:  46 Step:  14\n",
      "Weights:  [ 3.54857077 -7.5728253   1.75144053 -8.10858876  3.08791987]\n",
      "Epoch:  46 Step:  26\n",
      "Weights:  [ 4.05857077 -7.3228253   2.05144053 -7.99858876  3.18791987]\n",
      "Epoch:  46 Step:  32\n",
      "Weights:  [ 3.40857077 -7.6428253   1.54144053 -8.19858876  3.08791987]\n",
      "Epoch:  46 Step:  33\n",
      "Weights:  [ 4.05857077 -7.3628253   2.00144053 -8.04858876  3.18791987]\n",
      "Epoch:  46 Step:  34\n",
      "Weights:  [ 3.57857077 -7.6628253   1.86144053 -8.05858876  3.08791987]\n",
      "Epoch:  46 Step:  35\n",
      "Weights:  [ 2.80857077 -7.9628253   1.25144053 -8.28858876  2.98791987]\n",
      "Epoch:  46 Step:  36\n",
      "Weights:  [ 3.49857077 -7.6528253   1.74144053 -8.13858876  3.08791987]\n",
      "Epoch:  46 Step:  38\n",
      "Weights:  [ 4.09857077 -7.3828253   2.25144053 -7.97858876  3.18791987]\n",
      "Epoch:  46 Step:  47\n",
      "Weights:  [ 3.55857077 -7.7228253   2.10144053 -8.01858876  3.08791987]\n",
      "Epoch:  46 Step:  48\n",
      "Weights:  [ 2.83857077 -8.0228253   1.52144053 -8.17858876  2.98791987]\n",
      "Epoch:  46 Step:  49\n",
      "Weights:  [ 3.49857077 -7.7328253   1.98144053 -8.04858876  3.08791987]\n",
      "Epoch:  46 Step:  56\n",
      "Weights:  [ 4.06857077 -7.4528253   2.43144053 -7.91858876  3.18791987]\n",
      "Epoch:  46 Step:  57\n",
      "Weights:  [ 3.50857077 -7.7328253   1.94144053 -8.11858876  3.08791987]\n",
      "Epoch:  46 Step:  64\n",
      "Weights:  [ 4.11857077 -7.4328253   2.40144053 -7.97858876  3.18791987]\n",
      "Epoch:  46 Step:  65\n",
      "Weights:  [ 3.61857077 -7.7628253   2.26144053 -7.99858876  3.08791987]\n",
      "Epoch:  46 Step:  68\n",
      "Weights:  [ 2.88857077 -8.0528253   1.63144053 -8.17858876  2.98791987]\n",
      "Epoch:  46 Step:  74\n",
      "Weights:  [ 3.45857077 -7.7528253   2.05144053 -8.05858876  3.08791987]\n",
      "Epoch:  46 Step:  75\n",
      "Weights:  [ 4.04857077 -7.4528253   2.47144053 -7.90858876  3.18791987]\n",
      "Epoch:  46 Step:  76\n",
      "Weights:  [ 3.55857077 -7.7028253   2.02144053 -8.07858876  3.08791987]\n",
      "Epoch:  46 Step:  87\n",
      "Weights:  [ 4.19857077 -7.3828253   2.47144053 -7.92858876  3.18791987]\n",
      "Epoch:  46 Step:  88\n",
      "Weights:  [ 3.43857077 -7.6828253   1.81144053 -8.13858876  3.08791987]\n",
      "Epoch:  46 Step:  96\n",
      "Weights:  [ 2.98857077 -7.9128253   1.68144053 -8.16858876  2.98791987]\n",
      "Epoch:  46 Step:  97\n",
      "Weights:  [ 3.56857077 -7.6428253   2.09144053 -8.06858876  3.08791987]\n",
      "Epoch:  47 Step:  2\n",
      "Weights:  [ 2.96857077 -7.8628253   1.59144053 -8.21858876  2.98791987]\n",
      "Epoch:  47 Step:  7\n",
      "Weights:  [ 3.59857077 -7.6328253   2.03144053 -8.08858876  3.08791987]\n",
      "Epoch:  47 Step:  11\n",
      "Weights:  [ 2.95857077 -7.9028253   1.50144053 -8.27858876  2.98791987]\n",
      "Epoch:  47 Step:  14\n",
      "Weights:  [ 3.56857077 -7.6128253   1.97144053 -8.13858876  3.08791987]\n",
      "Epoch:  47 Step:  19\n",
      "Weights:  [ 2.85857077 -7.9128253   1.38144053 -8.34858876  2.98791987]\n",
      "Epoch:  47 Step:  24\n",
      "Weights:  [ 3.51857077 -7.6128253   1.82144053 -8.20858876  3.08791987]\n",
      "Epoch:  47 Step:  26\n",
      "Weights:  [ 4.02857077 -7.3628253   2.12144053 -8.09858876  3.18791987]\n",
      "Epoch:  47 Step:  32\n",
      "Weights:  [ 3.37857077 -7.6828253   1.61144053 -8.29858876  3.08791987]\n",
      "Epoch:  47 Step:  33\n",
      "Weights:  [ 4.02857077 -7.4028253   2.07144053 -8.14858876  3.18791987]\n",
      "Epoch:  47 Step:  34\n",
      "Weights:  [ 3.54857077 -7.7028253   1.93144053 -8.15858876  3.08791987]\n",
      "Epoch:  47 Step:  35\n",
      "Weights:  [ 2.77857077 -8.0028253   1.32144053 -8.38858876  2.98791987]\n",
      "Epoch:  47 Step:  36\n",
      "Weights:  [ 3.46857077 -7.6928253   1.81144053 -8.23858876  3.08791987]\n",
      "Epoch:  47 Step:  38\n",
      "Weights:  [ 4.06857077 -7.4228253   2.32144053 -8.07858876  3.18791987]\n",
      "Epoch:  47 Step:  47\n",
      "Weights:  [ 3.52857077 -7.7628253   2.17144053 -8.11858876  3.08791987]\n",
      "Epoch:  47 Step:  48\n",
      "Weights:  [ 2.80857077 -8.0628253   1.59144053 -8.27858876  2.98791987]\n",
      "Epoch:  47 Step:  49\n",
      "Weights:  [ 3.46857077 -7.7728253   2.05144053 -8.14858876  3.08791987]\n",
      "Epoch:  47 Step:  56\n",
      "Weights:  [ 4.03857077 -7.4928253   2.50144053 -8.01858876  3.18791987]\n",
      "Epoch:  47 Step:  57\n",
      "Weights:  [ 3.47857077 -7.7728253   2.01144053 -8.21858876  3.08791987]\n",
      "Epoch:  47 Step:  64\n",
      "Weights:  [ 4.08857077 -7.4728253   2.47144053 -8.07858876  3.18791987]\n",
      "Epoch:  47 Step:  65\n",
      "Weights:  [ 3.58857077 -7.8028253   2.33144053 -8.09858876  3.08791987]\n",
      "Epoch:  47 Step:  68\n",
      "Weights:  [ 2.85857077 -8.0928253   1.70144053 -8.27858876  2.98791987]\n",
      "Epoch:  47 Step:  74\n",
      "Weights:  [ 3.42857077 -7.7928253   2.12144053 -8.15858876  3.08791987]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  47 Step:  75\n",
      "Weights:  [ 4.01857077 -7.4928253   2.54144053 -8.00858876  3.18791987]\n",
      "Epoch:  47 Step:  76\n",
      "Weights:  [ 3.52857077 -7.7428253   2.09144053 -8.17858876  3.08791987]\n",
      "Epoch:  47 Step:  87\n",
      "Weights:  [ 4.16857077 -7.4228253   2.54144053 -8.02858876  3.18791987]\n",
      "Epoch:  47 Step:  88\n",
      "Weights:  [ 3.40857077 -7.7228253   1.88144053 -8.23858876  3.08791987]\n",
      "Epoch:  47 Step:  96\n",
      "Weights:  [ 2.95857077 -7.9528253   1.75144053 -8.26858876  2.98791987]\n",
      "Epoch:  47 Step:  97\n",
      "Weights:  [ 3.53857077 -7.6828253   2.16144053 -8.16858876  3.08791987]\n",
      "Epoch:  48 Step:  2\n",
      "Weights:  [ 2.93857077 -7.9028253   1.66144053 -8.31858876  2.98791987]\n",
      "Epoch:  48 Step:  7\n",
      "Weights:  [ 3.56857077 -7.6728253   2.10144053 -8.18858876  3.08791987]\n",
      "Epoch:  48 Step:  11\n",
      "Weights:  [ 2.92857077 -7.9428253   1.57144053 -8.37858876  2.98791987]\n",
      "Epoch:  48 Step:  14\n",
      "Weights:  [ 3.53857077 -7.6528253   2.04144053 -8.23858876  3.08791987]\n",
      "Epoch:  48 Step:  22\n",
      "Weights:  [ 2.90857077 -7.9028253   1.54144053 -8.42858876  2.98791987]\n",
      "Epoch:  48 Step:  24\n",
      "Weights:  [ 3.56857077 -7.6028253   1.98144053 -8.28858876  3.08791987]\n",
      "Epoch:  48 Step:  26\n",
      "Weights:  [ 4.07857077 -7.3528253   2.28144053 -8.17858876  3.18791987]\n",
      "Epoch:  48 Step:  32\n",
      "Weights:  [ 3.42857077 -7.6728253   1.77144053 -8.37858876  3.08791987]\n",
      "Epoch:  48 Step:  33\n",
      "Weights:  [ 4.07857077 -7.3928253   2.23144053 -8.22858876  3.18791987]\n",
      "Epoch:  48 Step:  34\n",
      "Weights:  [ 3.59857077 -7.6928253   2.09144053 -8.23858876  3.08791987]\n",
      "Epoch:  48 Step:  35\n",
      "Weights:  [ 2.82857077 -7.9928253   1.48144053 -8.46858876  2.98791987]\n",
      "Epoch:  48 Step:  36\n",
      "Weights:  [ 3.51857077 -7.6828253   1.97144053 -8.31858876  3.08791987]\n",
      "Epoch:  48 Step:  41\n",
      "Weights:  [ 4.08857077 -7.3928253   2.39144053 -8.18858876  3.18791987]\n",
      "Epoch:  48 Step:  47\n",
      "Weights:  [ 3.54857077 -7.7328253   2.24144053 -8.22858876  3.08791987]\n",
      "Epoch:  48 Step:  48\n",
      "Weights:  [ 2.82857077 -8.0328253   1.66144053 -8.38858876  2.98791987]\n",
      "Epoch:  48 Step:  49\n",
      "Weights:  [ 3.48857077 -7.7428253   2.12144053 -8.25858876  3.08791987]\n",
      "Epoch:  48 Step:  64\n",
      "Weights:  [ 4.09857077 -7.4428253   2.58144053 -8.11858876  3.18791987]\n",
      "Epoch:  48 Step:  65\n",
      "Weights:  [ 3.59857077 -7.7728253   2.44144053 -8.13858876  3.08791987]\n",
      "Epoch:  48 Step:  68\n",
      "Weights:  [ 2.86857077 -8.0628253   1.81144053 -8.31858876  2.98791987]\n",
      "Epoch:  48 Step:  74\n",
      "Weights:  [ 3.43857077 -7.7628253   2.23144053 -8.19858876  3.08791987]\n",
      "Epoch:  48 Step:  75\n",
      "Weights:  [ 4.02857077 -7.4628253   2.65144053 -8.04858876  3.18791987]\n",
      "Epoch:  48 Step:  76\n",
      "Weights:  [ 3.53857077 -7.7128253   2.20144053 -8.21858876  3.08791987]\n",
      "Epoch:  48 Step:  87\n",
      "Weights:  [ 4.17857077 -7.3928253   2.65144053 -8.06858876  3.18791987]\n",
      "Epoch:  48 Step:  88\n",
      "Weights:  [ 3.41857077 -7.6928253   1.99144053 -8.27858876  3.08791987]\n",
      "Epoch:  48 Step:  96\n",
      "Weights:  [ 2.96857077 -7.9228253   1.86144053 -8.30858876  2.98791987]\n",
      "Epoch:  48 Step:  97\n",
      "Weights:  [ 3.54857077 -7.6528253   2.27144053 -8.20858876  3.08791987]\n",
      "Epoch:  49 Step:  2\n",
      "Weights:  [ 2.94857077 -7.8728253   1.77144053 -8.35858876  2.98791987]\n",
      "Epoch:  49 Step:  9\n",
      "Weights:  [ 3.52857077 -7.6028253   2.16144053 -8.23858876  3.08791987]\n",
      "Epoch:  49 Step:  11\n",
      "Weights:  [ 2.88857077 -7.8728253   1.63144053 -8.42858876  2.98791987]\n",
      "Epoch:  49 Step:  14\n",
      "Weights:  [ 3.49857077 -7.5828253   2.10144053 -8.28858876  3.08791987]\n",
      "Epoch:  49 Step:  19\n",
      "Weights:  [ 2.78857077 -7.8828253   1.51144053 -8.49858876  2.98791987]\n",
      "Epoch:  49 Step:  24\n",
      "Weights:  [ 3.44857077 -7.5828253   1.95144053 -8.35858876  3.08791987]\n",
      "Epoch:  49 Step:  26\n",
      "Weights:  [ 3.95857077 -7.3328253   2.25144053 -8.24858876  3.18791987]\n",
      "Epoch:  49 Step:  32\n",
      "Weights:  [ 3.30857077 -7.6528253   1.74144053 -8.44858876  3.08791987]\n",
      "Epoch:  49 Step:  33\n",
      "Weights:  [ 3.95857077 -7.3728253   2.20144053 -8.29858876  3.18791987]\n",
      "Epoch:  49 Step:  34\n",
      "Weights:  [ 3.47857077 -7.6728253   2.06144053 -8.30858876  3.08791987]\n",
      "Epoch:  49 Step:  35\n",
      "Weights:  [ 2.70857077 -7.9728253   1.45144053 -8.53858876  2.98791987]\n",
      "Epoch:  49 Step:  36\n",
      "Weights:  [ 3.39857077 -7.6628253   1.94144053 -8.38858876  3.08791987]\n",
      "Epoch:  49 Step:  38\n",
      "Weights:  [ 3.99857077 -7.3928253   2.45144053 -8.22858876  3.18791987]\n",
      "Epoch:  49 Step:  47\n",
      "Weights:  [ 3.45857077 -7.7328253   2.30144053 -8.26858876  3.08791987]\n",
      "Epoch:  49 Step:  48\n",
      "Weights:  [ 2.73857077 -8.0328253   1.72144053 -8.42858876  2.98791987]\n",
      "Epoch:  49 Step:  49\n",
      "Weights:  [ 3.39857077 -7.7428253   2.18144053 -8.29858876  3.08791987]\n",
      "Epoch:  49 Step:  56\n",
      "Weights:  [ 3.96857077 -7.4628253   2.63144053 -8.16858876  3.18791987]\n",
      "Epoch:  49 Step:  57\n",
      "Weights:  [ 3.40857077 -7.7428253   2.14144053 -8.36858876  3.08791987]\n",
      "Epoch:  49 Step:  64\n",
      "Weights:  [ 4.01857077 -7.4428253   2.60144053 -8.22858876  3.18791987]\n",
      "Epoch:  49 Step:  65\n",
      "Weights:  [ 3.51857077 -7.7728253   2.46144053 -8.24858876  3.08791987]\n",
      "Epoch:  49 Step:  68\n",
      "Weights:  [ 2.78857077 -8.0628253   1.83144053 -8.42858876  2.98791987]\n",
      "Epoch:  49 Step:  74\n",
      "Weights:  [ 3.35857077 -7.7628253   2.25144053 -8.30858876  3.08791987]\n",
      "Epoch:  49 Step:  75\n",
      "Weights:  [ 3.94857077 -7.4628253   2.67144053 -8.15858876  3.18791987]\n",
      "Epoch:  49 Step:  76\n",
      "Weights:  [ 3.45857077 -7.7128253   2.22144053 -8.32858876  3.08791987]\n",
      "Epoch:  49 Step:  87\n",
      "Weights:  [ 4.09857077 -7.3928253   2.67144053 -8.17858876  3.18791987]\n",
      "Epoch:  49 Step:  88\n",
      "Weights:  [ 3.33857077 -7.6928253   2.01144053 -8.38858876  3.08791987]\n",
      "Epoch:  49 Step:  96\n",
      "Weights:  [ 2.88857077 -7.9228253   1.88144053 -8.41858876  2.98791987]\n",
      "Epoch:  49 Step:  97\n",
      "Weights:  [ 3.46857077 -7.6528253   2.29144053 -8.31858876  3.08791987]\n",
      "Epoch:  50 Step:  2\n",
      "Weights:  [ 2.86857077 -7.8728253   1.79144053 -8.46858876  2.98791987]\n",
      "Epoch:  50 Step:  7\n",
      "Weights:  [ 3.49857077 -7.6428253   2.23144053 -8.33858876  3.08791987]\n",
      "Epoch:  50 Step:  11\n",
      "Weights:  [ 2.85857077 -7.9128253   1.70144053 -8.52858876  2.98791987]\n",
      "Epoch:  50 Step:  14\n",
      "Weights:  [ 3.46857077 -7.6228253   2.17144053 -8.38858876  3.08791987]\n",
      "Epoch:  50 Step:  19\n",
      "Weights:  [ 2.75857077 -7.9228253   1.58144053 -8.59858876  2.98791987]\n",
      "Epoch:  50 Step:  24\n",
      "Weights:  [ 3.41857077 -7.6228253   2.02144053 -8.45858876  3.08791987]\n",
      "Epoch:  50 Step:  26\n",
      "Weights:  [ 3.92857077 -7.3728253   2.32144053 -8.34858876  3.18791987]\n",
      "Epoch:  50 Step:  32\n",
      "Weights:  [ 3.27857077 -7.6928253   1.81144053 -8.54858876  3.08791987]\n",
      "Epoch:  50 Step:  33\n",
      "Weights:  [ 3.92857077 -7.4128253   2.27144053 -8.39858876  3.18791987]\n",
      "Epoch:  50 Step:  34\n",
      "Weights:  [ 3.44857077 -7.7128253   2.13144053 -8.40858876  3.08791987]\n",
      "Epoch:  50 Step:  35\n",
      "Weights:  [ 2.67857077 -8.0128253   1.52144053 -8.63858876  2.98791987]\n",
      "Epoch:  50 Step:  36\n",
      "Weights:  [ 3.36857077 -7.7028253   2.01144053 -8.48858876  3.08791987]\n",
      "Epoch:  50 Step:  38\n",
      "Weights:  [ 3.96857077 -7.4328253   2.52144053 -8.32858876  3.18791987]\n",
      "Epoch:  50 Step:  48\n",
      "Weights:  [ 3.24857077 -7.7328253   1.94144053 -8.48858876  3.08791987]\n",
      "Epoch:  50 Step:  49\n",
      "Weights:  [ 3.90857077 -7.4428253   2.40144053 -8.35858876  3.18791987]\n",
      "Epoch:  50 Step:  50\n",
      "Weights:  [ 3.25857077 -7.7428253   1.88144053 -8.55858876  3.08791987]\n",
      "Epoch:  50 Step:  53\n",
      "Weights:  [ 3.80857077 -7.4928253   2.28144053 -8.42858876  3.18791987]\n",
      "Epoch:  50 Step:  54\n",
      "Weights:  [ 3.16857077 -7.8028253   1.73144053 -8.60858876  3.08791987]\n",
      "Epoch:  50 Step:  56\n",
      "Weights:  [ 3.73857077 -7.5228253   2.18144053 -8.47858876  3.18791987]\n",
      "Epoch:  50 Step:  68\n",
      "Weights:  [ 3.00857077 -7.8128253   1.55144053 -8.65858876  3.08791987]\n",
      "Epoch:  50 Step:  74\n",
      "Weights:  [ 3.57857077 -7.5128253   1.97144053 -8.53858876  3.18791987]\n",
      "Epoch:  50 Step:  75\n",
      "Weights:  [ 4.16857077 -7.2128253   2.39144053 -8.38858876  3.28791987]\n",
      "Epoch:  50 Step:  76\n",
      "Weights:  [ 3.67857077 -7.4628253   1.94144053 -8.55858876  3.18791987]\n",
      "Epoch:  50 Step:  87\n",
      "Weights:  [ 4.31857077 -7.1428253   2.39144053 -8.40858876  3.28791987]\n",
      "Epoch:  50 Step:  88\n",
      "Weights:  [ 3.55857077 -7.4428253   1.73144053 -8.61858876  3.18791987]\n",
      "Epoch:  50 Step:  96\n",
      "Weights:  [ 3.10857077 -7.6728253   1.60144053 -8.64858876  3.08791987]\n",
      "Epoch:  50 Step:  97\n",
      "Weights:  [ 3.68857077 -7.4028253   2.01144053 -8.54858876  3.18791987]\n",
      "------------------------------------------\n",
      "Perceptron training successfully completed\n",
      "\n",
      "\n",
      "\n",
      "Testing the perceptron\n",
      "-----------------------\n",
      "Correctly classified:  35 \tIncorrectly classified:  15\n",
      "Accuracy:  70.0 %\n"
     ]
    }
   ],
   "source": [
    "inputs, outputs = prepare_train_data_for_classification(df, 3)\n",
    "\n",
    "#Set learning rate and number of epochs\n",
    "lr = 0.1\n",
    "num_epochs = 50\n",
    "\n",
    "perceptron = Perceptron(inputs, outputs, lr, num_epochs)\n",
    "\n",
    "#Training the perceptron\n",
    "perceptron.fit()\n",
    "\n",
    "#Testing the trained perceptron\n",
    "perceptron.test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network for iris classification (4 inputs, 3 outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_iris(sl, sw, pl, pw):\n",
    "    #Input neurons\n",
    "    inputs = [sl, sw, pl, pw, 1]\n",
    "    \n",
    "    #Hidden neurons\n",
    "    set_hidden = set_perceptron.predict(inputs) #pre-trained setosa vs non-setosa perceptron\n",
    "    vir_hidden = vir_perceptron.predict(inputs) #pre-trained virginica vs virginica perceptron\n",
    "    \n",
    "    #Output neurons\n",
    "    ver_out = int(np.array([-1., -1., 0.5]).dot([set_hidden, vir_hidden, 1]) > 0)\n",
    "    set_out = int(np.array([1., 0., -0.5]).dot([set_hidden, vir_hidden, 1]) > 0)\n",
    "    vir_out = int(np.array([0., 1., -0.5]).dot([set_hidden, vir_hidden, 1]) > 0)\n",
    "    \n",
    "    return ver_out, set_out, vir_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict the iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 1, 0) This is an Iris-setosa\n"
     ]
    }
   ],
   "source": [
    "#Set the input values\n",
    "SL = 2.5 #Sepal length\n",
    "SW = 2.5 #Sepal width\n",
    "PL = 1.6 #Petal length\n",
    "PW = 1.5 #Petal width\n",
    "\n",
    "output = predict_iris(SL, SW, PL, PW)\n",
    "\n",
    "if output[0]:\n",
    "    print(output, 'This is an Iris-versicolor')\n",
    "elif output[1]:\n",
    "    print(output, 'This is an Iris-setosa')\n",
    "elif output[2]:\n",
    "    print(output, 'This is an Iris-virginica')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Network evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  94.0 %\n"
     ]
    }
   ],
   "source": [
    "inputs = df[['sepal length', 'sepal width', 'petal length', 'petal width']]\n",
    "inputs = inputs[100:].values #Test set inputs\n",
    "outputs = df['variety']\n",
    "outputs = outputs[100:].reset_index(drop=True) #Test set outputs\n",
    "\n",
    "correct = 0.0\n",
    "wrong = 0.0\n",
    "\n",
    "for i, data in enumerate(inputs):\n",
    "    pred = predict_iris(*data)\n",
    "    \n",
    "    if pred[0] and outputs[i] == 'Iris-versicolor':\n",
    "        correct += 1\n",
    "    elif pred[1] and outputs[i] == 'Iris-setosa':\n",
    "        correct += 1\n",
    "    elif pred[2] and outputs[i] == 'Iris-virginica':\n",
    "        correct += 1\n",
    "    else:\n",
    "        wrong += 1\n",
    "        \n",
    "accuracy = correct/len(inputs) * 100\n",
    "print('Accuracy: ', accuracy, '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building neural network with Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150 input patterns 150 output patterns\n"
     ]
    }
   ],
   "source": [
    "inputs  = []\n",
    "outputs = []\n",
    "\n",
    "d = {}\n",
    "d['Iris-setosa\\n']     = [1., 0., 0.]\n",
    "d['Iris-versicolor\\n'] = [0., 1., 0.]\n",
    "d['Iris-virginica\\n']  = [0., 0., 1.]\n",
    "\n",
    "with open('iris.data') as f:\n",
    "    lines=f.readlines()\n",
    "    for line in lines:\n",
    "        items=line.split(',')\n",
    "        if len(items) == 5:\n",
    "            inp =  [float(x) for x in items[0:4] ]\n",
    "            inputs.append(inp)\n",
    "            out = d[items[4]]\n",
    "            outputs.append(out)\n",
    "            \n",
    "print( len(inputs), 'input patterns', len(outputs), 'output patterns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "# an mlp with a given number of input nodes. Four input nodes, three output nodes \n",
    "nr_hidden = 6\n",
    "nr_out    = 3 \n",
    "\n",
    "model.add(layers.Dense(nr_hidden, activation = 'relu'))\n",
    "model.add(layers.Dense(nr_out,activation='softmax'))\n",
    "model.compile(optimizer=tf.keras.optimizers.SGD(0.05, 0.9),loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split data into training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids=random.sample(range(0,len(inputs)), 100) # generate 100 random ids\n",
    "train_in = []\n",
    "train_out=[]\n",
    "for id in ids:\n",
    "    train_in.append(inputs[id])\n",
    "    train_out.append(outputs[id])\n",
    "train_inputs  = np.array(train_in)\n",
    "train_outputs = np.array(train_out)\n",
    "\n",
    "val_input =[]\n",
    "val_output=[]\n",
    "validation_ids = list(set(range(0,len(inputs))) - set(ids))\n",
    "for val_id in validation_ids:\n",
    "    val_input.append(inputs[val_id])\n",
    "    val_output.append(outputs[val_id])\n",
    "val_inputs  = np.array(val_input)\n",
    "val_outputs = np.array(val_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 100 samples, validate on 50 samples\n",
      "Epoch 1/1000\n",
      "100/100 [==============================] - 1s 6ms/sample - loss: 1.1331 - accuracy: 0.4000 - val_loss: 0.9129 - val_accuracy: 0.6400\n",
      "Epoch 2/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.8097 - accuracy: 0.6800 - val_loss: 0.7286 - val_accuracy: 0.8600\n",
      "Epoch 3/1000\n",
      "100/100 [==============================] - 0s 189us/sample - loss: 0.6508 - accuracy: 0.8600 - val_loss: 0.5348 - val_accuracy: 0.9200\n",
      "Epoch 4/1000\n",
      "100/100 [==============================] - 0s 199us/sample - loss: 0.4945 - accuracy: 0.7900 - val_loss: 0.3636 - val_accuracy: 0.8600\n",
      "Epoch 5/1000\n",
      "100/100 [==============================] - 0s 209us/sample - loss: 0.3737 - accuracy: 0.8600 - val_loss: 0.9314 - val_accuracy: 0.6400\n",
      "Epoch 6/1000\n",
      "100/100 [==============================] - 0s 229us/sample - loss: 1.0219 - accuracy: 0.7200 - val_loss: 1.2019 - val_accuracy: 0.6000\n",
      "Epoch 7/1000\n",
      "100/100 [==============================] - 0s 209us/sample - loss: 1.3334 - accuracy: 0.6800 - val_loss: 0.5619 - val_accuracy: 0.6400\n",
      "Epoch 8/1000\n",
      "100/100 [==============================] - 0s 239us/sample - loss: 0.7429 - accuracy: 0.6800 - val_loss: 0.5934 - val_accuracy: 1.0000\n",
      "Epoch 9/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.6939 - accuracy: 0.6700 - val_loss: 0.4959 - val_accuracy: 0.9200\n",
      "Epoch 10/1000\n",
      "100/100 [==============================] - 0s 259us/sample - loss: 0.5415 - accuracy: 0.7400 - val_loss: 0.4223 - val_accuracy: 0.7000\n",
      "Epoch 11/1000\n",
      "100/100 [==============================] - 0s 289us/sample - loss: 0.4870 - accuracy: 0.6300 - val_loss: 0.3600 - val_accuracy: 0.9400\n",
      "Epoch 12/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.4137 - accuracy: 0.7200 - val_loss: 0.3900 - val_accuracy: 0.9600\n",
      "Epoch 13/1000\n",
      "100/100 [==============================] - 0s 229us/sample - loss: 0.3504 - accuracy: 0.9600 - val_loss: 0.4235 - val_accuracy: 0.6800\n",
      "Epoch 14/1000\n",
      "100/100 [==============================] - 0s 319us/sample - loss: 0.3984 - accuracy: 0.7500 - val_loss: 0.3641 - val_accuracy: 0.7200\n",
      "Epoch 15/1000\n",
      "100/100 [==============================] - 0s 259us/sample - loss: 0.3319 - accuracy: 0.8100 - val_loss: 0.2224 - val_accuracy: 0.9400\n",
      "Epoch 16/1000\n",
      "100/100 [==============================] - 0s 249us/sample - loss: 0.3063 - accuracy: 0.8200 - val_loss: 0.2399 - val_accuracy: 0.8800\n",
      "Epoch 17/1000\n",
      "100/100 [==============================] - 0s 239us/sample - loss: 0.2583 - accuracy: 0.9100 - val_loss: 0.1594 - val_accuracy: 1.0000\n",
      "Epoch 18/1000\n",
      "100/100 [==============================] - 0s 279us/sample - loss: 0.1965 - accuracy: 0.9700 - val_loss: 0.1375 - val_accuracy: 1.0000\n",
      "Epoch 19/1000\n",
      "100/100 [==============================] - 0s 259us/sample - loss: 0.1884 - accuracy: 0.9300 - val_loss: 0.3214 - val_accuracy: 0.8600\n",
      "Epoch 20/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.2098 - accuracy: 0.9200 - val_loss: 0.1095 - val_accuracy: 0.9600\n",
      "Epoch 21/1000\n",
      "100/100 [==============================] - 0s 279us/sample - loss: 0.1997 - accuracy: 0.9200 - val_loss: 0.1741 - val_accuracy: 0.9200\n",
      "Epoch 22/1000\n",
      "100/100 [==============================] - 0s 239us/sample - loss: 0.2513 - accuracy: 0.8900 - val_loss: 0.1637 - val_accuracy: 0.9200\n",
      "Epoch 23/1000\n",
      "100/100 [==============================] - 0s 259us/sample - loss: 0.1637 - accuracy: 0.9400 - val_loss: 0.1199 - val_accuracy: 0.9400\n",
      "Epoch 24/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.2377 - accuracy: 0.9300 - val_loss: 0.0742 - val_accuracy: 1.0000\n",
      "Epoch 25/1000\n",
      "100/100 [==============================] - 0s 239us/sample - loss: 0.2632 - accuracy: 0.8800 - val_loss: 0.0771 - val_accuracy: 1.0000\n",
      "Epoch 26/1000\n",
      "100/100 [==============================] - 0s 269us/sample - loss: 0.4067 - accuracy: 0.8500 - val_loss: 0.0732 - val_accuracy: 1.0000\n",
      "Epoch 27/1000\n",
      "100/100 [==============================] - 0s 189us/sample - loss: 0.3991 - accuracy: 0.8500 - val_loss: 1.0416 - val_accuracy: 0.6400\n",
      "Epoch 28/1000\n",
      "100/100 [==============================] - 0s 309us/sample - loss: 0.5743 - accuracy: 0.8100 - val_loss: 0.1014 - val_accuracy: 0.9800\n",
      "Epoch 29/1000\n",
      "100/100 [==============================] - 0s 359us/sample - loss: 0.4354 - accuracy: 0.7800 - val_loss: 0.2107 - val_accuracy: 0.8800\n",
      "Epoch 30/1000\n",
      "100/100 [==============================] - 0s 239us/sample - loss: 0.3225 - accuracy: 0.8700 - val_loss: 0.2626 - val_accuracy: 0.9000\n",
      "Epoch 31/1000\n",
      "100/100 [==============================] - 0s 189us/sample - loss: 0.2087 - accuracy: 0.9200 - val_loss: 0.1252 - val_accuracy: 1.0000\n",
      "Epoch 32/1000\n",
      "100/100 [==============================] - 0s 229us/sample - loss: 0.1765 - accuracy: 0.9600 - val_loss: 0.1430 - val_accuracy: 0.9400\n",
      "Epoch 33/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.1563 - accuracy: 0.9700 - val_loss: 0.1000 - val_accuracy: 0.9800\n",
      "Epoch 34/1000\n",
      "100/100 [==============================] - 0s 209us/sample - loss: 0.1840 - accuracy: 0.9300 - val_loss: 0.0947 - val_accuracy: 0.9600\n",
      "Epoch 35/1000\n",
      "100/100 [==============================] - 0s 239us/sample - loss: 0.1252 - accuracy: 0.9700 - val_loss: 0.0657 - val_accuracy: 1.0000\n",
      "Epoch 36/1000\n",
      "100/100 [==============================] - 0s 209us/sample - loss: 0.1200 - accuracy: 0.9700 - val_loss: 0.0653 - val_accuracy: 1.0000\n",
      "Epoch 37/1000\n",
      "100/100 [==============================] - 0s 269us/sample - loss: 0.1189 - accuracy: 0.9700 - val_loss: 0.1182 - val_accuracy: 0.9200\n",
      "Epoch 38/1000\n",
      "100/100 [==============================] - 0s 289us/sample - loss: 0.1693 - accuracy: 0.9200 - val_loss: 0.5806 - val_accuracy: 0.7200\n",
      "Epoch 39/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.7975 - accuracy: 0.7500 - val_loss: 0.6657 - val_accuracy: 0.7200\n",
      "Epoch 40/1000\n",
      "100/100 [==============================] - 0s 269us/sample - loss: 0.7501 - accuracy: 0.7000 - val_loss: 0.0881 - val_accuracy: 0.9800\n",
      "Epoch 41/1000\n",
      "100/100 [==============================] - 0s 269us/sample - loss: 0.5330 - accuracy: 0.7700 - val_loss: 0.7319 - val_accuracy: 0.7200\n",
      "Epoch 42/1000\n",
      "100/100 [==============================] - 0s 229us/sample - loss: 0.7734 - accuracy: 0.6700 - val_loss: 0.1618 - val_accuracy: 0.8800\n",
      "Epoch 43/1000\n",
      "100/100 [==============================] - 0s 249us/sample - loss: 0.2571 - accuracy: 0.8800 - val_loss: 0.1353 - val_accuracy: 0.9200\n",
      "Epoch 44/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.1544 - accuracy: 0.9200 - val_loss: 0.1612 - val_accuracy: 0.9600\n",
      "Epoch 45/1000\n",
      "100/100 [==============================] - 0s 249us/sample - loss: 0.1995 - accuracy: 0.9300 - val_loss: 0.3937 - val_accuracy: 0.8200\n",
      "Epoch 46/1000\n",
      "100/100 [==============================] - 0s 209us/sample - loss: 0.2110 - accuracy: 0.9100 - val_loss: 0.2316 - val_accuracy: 0.8600\n",
      "Epoch 47/1000\n",
      "100/100 [==============================] - 0s 239us/sample - loss: 0.1939 - accuracy: 0.9400 - val_loss: 0.0890 - val_accuracy: 1.0000\n",
      "Epoch 48/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.1517 - accuracy: 0.9500 - val_loss: 0.0553 - val_accuracy: 1.0000\n",
      "Epoch 49/1000\n",
      "100/100 [==============================] - 0s 239us/sample - loss: 0.0945 - accuracy: 0.9800 - val_loss: 0.0509 - val_accuracy: 1.0000\n",
      "Epoch 50/1000\n",
      "100/100 [==============================] - 0s 229us/sample - loss: 0.1000 - accuracy: 0.9800 - val_loss: 0.0501 - val_accuracy: 1.0000\n",
      "Epoch 51/1000\n",
      "100/100 [==============================] - 0s 279us/sample - loss: 0.0959 - accuracy: 0.9800 - val_loss: 0.0814 - val_accuracy: 0.9600\n",
      "Epoch 52/1000\n",
      "100/100 [==============================] - 0s 249us/sample - loss: 0.1018 - accuracy: 0.9600 - val_loss: 0.0465 - val_accuracy: 1.0000\n",
      "Epoch 53/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.1173 - accuracy: 0.9600 - val_loss: 0.1460 - val_accuracy: 0.9200\n",
      "Epoch 54/1000\n",
      "100/100 [==============================] - 0s 229us/sample - loss: 0.1838 - accuracy: 0.9000 - val_loss: 0.0446 - val_accuracy: 1.0000\n",
      "Epoch 55/1000\n",
      "100/100 [==============================] - 0s 209us/sample - loss: 0.0871 - accuracy: 0.9700 - val_loss: 0.0372 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/1000\n",
      "100/100 [==============================] - 0s 229us/sample - loss: 0.0857 - accuracy: 0.9700 - val_loss: 0.0429 - val_accuracy: 1.0000\n",
      "Epoch 57/1000\n",
      "100/100 [==============================] - 0s 289us/sample - loss: 0.0947 - accuracy: 0.9700 - val_loss: 0.1148 - val_accuracy: 0.9400\n",
      "Epoch 58/1000\n",
      "100/100 [==============================] - 0s 269us/sample - loss: 0.1081 - accuracy: 0.9600 - val_loss: 0.0425 - val_accuracy: 1.0000\n",
      "Epoch 59/1000\n",
      "100/100 [==============================] - 0s 269us/sample - loss: 0.0997 - accuracy: 0.9700 - val_loss: 0.0276 - val_accuracy: 1.0000\n",
      "Epoch 60/1000\n",
      "100/100 [==============================] - 0s 289us/sample - loss: 0.1197 - accuracy: 0.9600 - val_loss: 0.1401 - val_accuracy: 0.9200\n",
      "Epoch 61/1000\n",
      "100/100 [==============================] - 0s 309us/sample - loss: 0.1423 - accuracy: 0.9500 - val_loss: 0.0233 - val_accuracy: 1.0000\n",
      "Epoch 62/1000\n",
      "100/100 [==============================] - 0s 309us/sample - loss: 0.1415 - accuracy: 0.9300 - val_loss: 0.0363 - val_accuracy: 1.0000\n",
      "Epoch 63/1000\n",
      "100/100 [==============================] - 0s 309us/sample - loss: 0.0978 - accuracy: 0.9600 - val_loss: 0.0599 - val_accuracy: 0.9600\n",
      "Epoch 64/1000\n",
      "100/100 [==============================] - 0s 339us/sample - loss: 0.0834 - accuracy: 0.9700 - val_loss: 0.0650 - val_accuracy: 0.9600\n",
      "Epoch 65/1000\n",
      "100/100 [==============================] - 0s 289us/sample - loss: 0.0971 - accuracy: 0.9700 - val_loss: 0.0388 - val_accuracy: 1.0000\n",
      "Epoch 66/1000\n",
      "100/100 [==============================] - 0s 359us/sample - loss: 0.0838 - accuracy: 0.9700 - val_loss: 0.0505 - val_accuracy: 0.9800\n",
      "Epoch 67/1000\n",
      "100/100 [==============================] - 0s 249us/sample - loss: 0.1012 - accuracy: 0.9500 - val_loss: 0.0262 - val_accuracy: 1.0000\n",
      "Epoch 68/1000\n",
      "100/100 [==============================] - 0s 299us/sample - loss: 0.1663 - accuracy: 0.9400 - val_loss: 0.0967 - val_accuracy: 0.9400\n",
      "Epoch 69/1000\n",
      "100/100 [==============================] - 0s 269us/sample - loss: 0.0988 - accuracy: 0.9600 - val_loss: 0.0281 - val_accuracy: 1.0000\n",
      "Epoch 70/1000\n",
      "100/100 [==============================] - 0s 269us/sample - loss: 0.1292 - accuracy: 0.9300 - val_loss: 0.0226 - val_accuracy: 1.0000\n",
      "Epoch 71/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.0957 - accuracy: 0.9600 - val_loss: 0.0303 - val_accuracy: 1.0000\n",
      "Epoch 72/1000\n",
      "100/100 [==============================] - 0s 199us/sample - loss: 0.0881 - accuracy: 0.9700 - val_loss: 0.0520 - val_accuracy: 0.9800\n",
      "Epoch 73/1000\n",
      "100/100 [==============================] - 0s 269us/sample - loss: 0.0790 - accuracy: 0.9700 - val_loss: 0.0288 - val_accuracy: 1.0000\n",
      "Epoch 74/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.1418 - accuracy: 0.9200 - val_loss: 0.0232 - val_accuracy: 1.0000\n",
      "Epoch 75/1000\n",
      "100/100 [==============================] - 0s 249us/sample - loss: 0.1228 - accuracy: 0.9400 - val_loss: 0.0806 - val_accuracy: 0.9600\n",
      "Epoch 76/1000\n",
      "100/100 [==============================] - 0s 209us/sample - loss: 0.1037 - accuracy: 0.9500 - val_loss: 0.0342 - val_accuracy: 1.0000\n",
      "Epoch 77/1000\n",
      "100/100 [==============================] - 0s 209us/sample - loss: 0.0849 - accuracy: 0.9600 - val_loss: 0.0234 - val_accuracy: 1.0000\n",
      "Epoch 78/1000\n",
      "100/100 [==============================] - 0s 229us/sample - loss: 0.1010 - accuracy: 0.9600 - val_loss: 0.0221 - val_accuracy: 1.0000\n",
      "Epoch 79/1000\n",
      "100/100 [==============================] - 0s 229us/sample - loss: 0.1336 - accuracy: 0.9500 - val_loss: 0.1800 - val_accuracy: 0.9200\n",
      "Epoch 80/1000\n",
      "100/100 [==============================] - 0s 229us/sample - loss: 0.1881 - accuracy: 0.9300 - val_loss: 0.0216 - val_accuracy: 1.0000\n",
      "Epoch 81/1000\n",
      "100/100 [==============================] - 0s 199us/sample - loss: 0.1239 - accuracy: 0.9400 - val_loss: 0.0322 - val_accuracy: 1.0000\n",
      "Epoch 82/1000\n",
      "100/100 [==============================] - 0s 209us/sample - loss: 0.0807 - accuracy: 0.9800 - val_loss: 0.0300 - val_accuracy: 1.0000\n",
      "Epoch 83/1000\n",
      "100/100 [==============================] - 0s 209us/sample - loss: 0.0863 - accuracy: 0.9700 - val_loss: 0.0246 - val_accuracy: 1.0000\n",
      "Epoch 84/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.1122 - accuracy: 0.9500 - val_loss: 0.0509 - val_accuracy: 0.9800\n",
      "Epoch 85/1000\n",
      "100/100 [==============================] - 0s 209us/sample - loss: 0.0792 - accuracy: 0.9700 - val_loss: 0.0219 - val_accuracy: 1.0000\n",
      "Epoch 86/1000\n",
      "100/100 [==============================] - 0s 199us/sample - loss: 0.1317 - accuracy: 0.9500 - val_loss: 0.0890 - val_accuracy: 0.9400\n",
      "Epoch 87/1000\n",
      "100/100 [==============================] - 0s 209us/sample - loss: 0.0933 - accuracy: 0.9600 - val_loss: 0.0210 - val_accuracy: 1.0000\n",
      "Epoch 88/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.0966 - accuracy: 0.9600 - val_loss: 0.0385 - val_accuracy: 1.0000\n",
      "Epoch 89/1000\n",
      "100/100 [==============================] - 0s 209us/sample - loss: 0.0786 - accuracy: 0.9700 - val_loss: 0.0203 - val_accuracy: 1.0000\n",
      "Epoch 90/1000\n",
      "100/100 [==============================] - 0s 209us/sample - loss: 0.0878 - accuracy: 0.9700 - val_loss: 0.1190 - val_accuracy: 0.9400\n",
      "Epoch 91/1000\n",
      "100/100 [==============================] - 0s 229us/sample - loss: 0.1866 - accuracy: 0.9100 - val_loss: 0.0601 - val_accuracy: 0.9800\n",
      "Epoch 92/1000\n",
      "100/100 [==============================] - 0s 209us/sample - loss: 0.1819 - accuracy: 0.9400 - val_loss: 0.1990 - val_accuracy: 0.9200\n",
      "Epoch 93/1000\n",
      "100/100 [==============================] - 0s 199us/sample - loss: 0.1239 - accuracy: 0.9500 - val_loss: 0.0469 - val_accuracy: 1.0000\n",
      "Epoch 94/1000\n",
      "100/100 [==============================] - 0s 209us/sample - loss: 0.2014 - accuracy: 0.9400 - val_loss: 0.2420 - val_accuracy: 0.9200\n",
      "Epoch 95/1000\n",
      "100/100 [==============================] - 0s 229us/sample - loss: 0.1926 - accuracy: 0.9500 - val_loss: 0.0315 - val_accuracy: 1.0000\n",
      "Epoch 96/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.1138 - accuracy: 0.9700 - val_loss: 0.1534 - val_accuracy: 0.9200\n",
      "Epoch 97/1000\n",
      "100/100 [==============================] - 0s 209us/sample - loss: 0.1319 - accuracy: 0.9500 - val_loss: 0.0587 - val_accuracy: 1.0000\n",
      "Epoch 98/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.1268 - accuracy: 0.9400 - val_loss: 0.0888 - val_accuracy: 0.9600\n",
      "Epoch 99/1000\n",
      "100/100 [==============================] - 0s 209us/sample - loss: 0.0960 - accuracy: 0.9600 - val_loss: 0.0399 - val_accuracy: 1.0000\n",
      "Epoch 100/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.0880 - accuracy: 0.9800 - val_loss: 0.1064 - val_accuracy: 0.9400\n",
      "Epoch 101/1000\n",
      "100/100 [==============================] - 0s 199us/sample - loss: 0.0995 - accuracy: 0.9300 - val_loss: 0.0201 - val_accuracy: 1.0000\n",
      "Epoch 102/1000\n",
      "100/100 [==============================] - 0s 209us/sample - loss: 0.0987 - accuracy: 0.9700 - val_loss: 0.0545 - val_accuracy: 0.9600\n",
      "Epoch 103/1000\n",
      "100/100 [==============================] - 0s 189us/sample - loss: 0.0805 - accuracy: 0.9600 - val_loss: 0.0201 - val_accuracy: 1.0000\n",
      "Epoch 104/1000\n",
      "100/100 [==============================] - 0s 209us/sample - loss: 0.1157 - accuracy: 0.9400 - val_loss: 0.2529 - val_accuracy: 0.9000\n",
      "Epoch 105/1000\n",
      "100/100 [==============================] - 0s 449us/sample - loss: 0.2014 - accuracy: 0.9000 - val_loss: 0.1295 - val_accuracy: 0.9000\n",
      "Epoch 106/1000\n",
      "100/100 [==============================] - 0s 180us/sample - loss: 0.2531 - accuracy: 0.9200 - val_loss: 0.7825 - val_accuracy: 0.7400\n",
      "Epoch 107/1000\n",
      "100/100 [==============================] - 0s 209us/sample - loss: 0.4161 - accuracy: 0.8500 - val_loss: 0.3397 - val_accuracy: 0.8800\n",
      "Epoch 108/1000\n",
      "100/100 [==============================] - 0s 239us/sample - loss: 0.3676 - accuracy: 0.8800 - val_loss: 0.6605 - val_accuracy: 0.6000\n",
      "Epoch 109/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.3370 - accuracy: 0.8000 - val_loss: 0.1493 - val_accuracy: 0.8800\n",
      "Epoch 110/1000\n",
      "100/100 [==============================] - 0s 199us/sample - loss: 0.3103 - accuracy: 0.8800 - val_loss: 0.1837 - val_accuracy: 0.9200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 111/1000\n",
      "100/100 [==============================] - 0s 209us/sample - loss: 0.4595 - accuracy: 0.7800 - val_loss: 0.1028 - val_accuracy: 0.9800\n",
      "Epoch 112/1000\n",
      "100/100 [==============================] - 0s 239us/sample - loss: 0.3907 - accuracy: 0.8700 - val_loss: 0.1516 - val_accuracy: 0.9200\n",
      "Epoch 113/1000\n",
      "100/100 [==============================] - 0s 189us/sample - loss: 0.4175 - accuracy: 0.7900 - val_loss: 0.0571 - val_accuracy: 0.9800\n",
      "Epoch 114/1000\n",
      "100/100 [==============================] - 0s 199us/sample - loss: 0.1706 - accuracy: 0.9400 - val_loss: 0.0439 - val_accuracy: 1.0000\n",
      "Epoch 115/1000\n",
      "100/100 [==============================] - 0s 229us/sample - loss: 0.0815 - accuracy: 0.9600 - val_loss: 0.0508 - val_accuracy: 0.9600\n",
      "Epoch 116/1000\n",
      "100/100 [==============================] - 0s 199us/sample - loss: 0.1027 - accuracy: 0.9600 - val_loss: 0.0554 - val_accuracy: 0.9600\n",
      "Epoch 117/1000\n",
      "100/100 [==============================] - 0s 189us/sample - loss: 0.1263 - accuracy: 0.9500 - val_loss: 0.0240 - val_accuracy: 1.0000\n",
      "Epoch 118/1000\n",
      "100/100 [==============================] - 0s 189us/sample - loss: 0.0769 - accuracy: 0.9800 - val_loss: 0.0238 - val_accuracy: 1.0000\n",
      "Epoch 119/1000\n",
      "100/100 [==============================] - 0s 199us/sample - loss: 0.0935 - accuracy: 0.9700 - val_loss: 0.1127 - val_accuracy: 0.9400\n",
      "Epoch 120/1000\n",
      "100/100 [==============================] - 0s 189us/sample - loss: 0.0996 - accuracy: 0.9500 - val_loss: 0.0261 - val_accuracy: 1.0000\n",
      "Epoch 121/1000\n",
      "100/100 [==============================] - 0s 199us/sample - loss: 0.0777 - accuracy: 0.9700 - val_loss: 0.0392 - val_accuracy: 0.9800\n",
      "Epoch 122/1000\n",
      "100/100 [==============================] - 0s 209us/sample - loss: 0.0696 - accuracy: 0.9800 - val_loss: 0.0162 - val_accuracy: 1.0000\n",
      "Epoch 123/1000\n",
      "100/100 [==============================] - 0s 179us/sample - loss: 0.1003 - accuracy: 0.9500 - val_loss: 0.0160 - val_accuracy: 1.0000\n",
      "Epoch 124/1000\n",
      "100/100 [==============================] - 0s 199us/sample - loss: 0.2797 - accuracy: 0.9000 - val_loss: 0.4434 - val_accuracy: 0.8400\n",
      "Epoch 125/1000\n",
      "100/100 [==============================] - 0s 199us/sample - loss: 0.2885 - accuracy: 0.8900 - val_loss: 0.0763 - val_accuracy: 0.9800\n",
      "Epoch 126/1000\n",
      "100/100 [==============================] - 0s 199us/sample - loss: 0.1908 - accuracy: 0.9500 - val_loss: 0.2952 - val_accuracy: 0.9000\n",
      "Epoch 127/1000\n",
      "100/100 [==============================] - 0s 189us/sample - loss: 0.2023 - accuracy: 0.9000 - val_loss: 0.0613 - val_accuracy: 0.9800\n",
      "Epoch 128/1000\n",
      "100/100 [==============================] - 0s 209us/sample - loss: 0.2052 - accuracy: 0.9100 - val_loss: 0.2770 - val_accuracy: 0.9000\n",
      "Epoch 129/1000\n",
      "100/100 [==============================] - 0s 199us/sample - loss: 0.2380 - accuracy: 0.8900 - val_loss: 0.0331 - val_accuracy: 1.0000\n",
      "Epoch 130/1000\n",
      "100/100 [==============================] - 0s 189us/sample - loss: 0.1246 - accuracy: 0.9500 - val_loss: 0.1766 - val_accuracy: 0.9200\n",
      "Epoch 131/1000\n",
      "100/100 [==============================] - 0s 199us/sample - loss: 0.1983 - accuracy: 0.9000 - val_loss: 0.0293 - val_accuracy: 1.0000\n",
      "Epoch 132/1000\n",
      "100/100 [==============================] - 0s 200us/sample - loss: 0.1127 - accuracy: 0.9500 - val_loss: 0.0702 - val_accuracy: 0.9400\n",
      "Epoch 133/1000\n",
      "100/100 [==============================] - 0s 199us/sample - loss: 0.1655 - accuracy: 0.9000 - val_loss: 0.0298 - val_accuracy: 1.0000\n",
      "Epoch 134/1000\n",
      "100/100 [==============================] - 0s 190us/sample - loss: 0.1672 - accuracy: 0.9400 - val_loss: 0.0673 - val_accuracy: 0.9800\n",
      "Epoch 135/1000\n",
      "100/100 [==============================] - 0s 199us/sample - loss: 0.1123 - accuracy: 0.9500 - val_loss: 0.1052 - val_accuracy: 0.9800\n",
      "Epoch 136/1000\n",
      "100/100 [==============================] - 0s 209us/sample - loss: 0.0965 - accuracy: 0.9600 - val_loss: 0.0379 - val_accuracy: 0.9800\n",
      "Epoch 137/1000\n",
      "100/100 [==============================] - 0s 199us/sample - loss: 0.0982 - accuracy: 0.9700 - val_loss: 0.1050 - val_accuracy: 0.9200\n",
      "Epoch 138/1000\n",
      "100/100 [==============================] - 0s 209us/sample - loss: 0.1366 - accuracy: 0.9400 - val_loss: 0.0192 - val_accuracy: 1.0000\n",
      "Epoch 139/1000\n",
      "100/100 [==============================] - 0s 209us/sample - loss: 0.0959 - accuracy: 0.9600 - val_loss: 0.0295 - val_accuracy: 1.0000\n",
      "Epoch 140/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.1196 - accuracy: 0.9500 - val_loss: 0.0349 - val_accuracy: 1.0000\n",
      "Epoch 141/1000\n",
      "100/100 [==============================] - 0s 189us/sample - loss: 0.1285 - accuracy: 0.9300 - val_loss: 0.0455 - val_accuracy: 0.9800\n",
      "Epoch 142/1000\n",
      "100/100 [==============================] - 0s 209us/sample - loss: 0.0784 - accuracy: 0.9600 - val_loss: 0.0355 - val_accuracy: 1.0000\n",
      "Epoch 143/1000\n",
      "100/100 [==============================] - 0s 209us/sample - loss: 0.1012 - accuracy: 0.9600 - val_loss: 0.0259 - val_accuracy: 1.0000\n",
      "Epoch 144/1000\n",
      "100/100 [==============================] - 0s 189us/sample - loss: 0.0912 - accuracy: 0.9500 - val_loss: 0.0366 - val_accuracy: 1.0000\n",
      "Epoch 145/1000\n",
      "100/100 [==============================] - 0s 209us/sample - loss: 0.0836 - accuracy: 0.9700 - val_loss: 0.0560 - val_accuracy: 0.9600\n",
      "Epoch 146/1000\n",
      "100/100 [==============================] - 0s 199us/sample - loss: 0.1065 - accuracy: 0.9500 - val_loss: 0.0451 - val_accuracy: 0.9800\n",
      "Epoch 147/1000\n",
      "100/100 [==============================] - 0s 199us/sample - loss: 0.0730 - accuracy: 0.9800 - val_loss: 0.0371 - val_accuracy: 1.0000\n",
      "Epoch 148/1000\n",
      "100/100 [==============================] - 0s 249us/sample - loss: 0.0708 - accuracy: 0.9800 - val_loss: 0.0247 - val_accuracy: 1.0000\n",
      "Epoch 149/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.0760 - accuracy: 0.9700 - val_loss: 0.0399 - val_accuracy: 0.9800\n",
      "Epoch 150/1000\n",
      "100/100 [==============================] - 0s 229us/sample - loss: 0.0810 - accuracy: 0.9600 - val_loss: 0.0351 - val_accuracy: 1.0000\n",
      "Epoch 151/1000\n",
      "100/100 [==============================] - 0s 209us/sample - loss: 0.0735 - accuracy: 0.9800 - val_loss: 0.0494 - val_accuracy: 0.9600\n",
      "Epoch 152/1000\n",
      "100/100 [==============================] - 0s 180us/sample - loss: 0.0764 - accuracy: 0.9500 - val_loss: 0.0397 - val_accuracy: 0.9800\n",
      "Epoch 153/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.0861 - accuracy: 0.9600 - val_loss: 0.0173 - val_accuracy: 1.0000\n",
      "Epoch 154/1000\n",
      "100/100 [==============================] - 0s 200us/sample - loss: 0.1078 - accuracy: 0.9600 - val_loss: 0.0834 - val_accuracy: 0.9400\n",
      "Epoch 155/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.1152 - accuracy: 0.9600 - val_loss: 0.0150 - val_accuracy: 1.0000\n",
      "Epoch 156/1000\n",
      "100/100 [==============================] - 0s 199us/sample - loss: 0.1496 - accuracy: 0.9400 - val_loss: 0.1388 - val_accuracy: 0.9400\n",
      "Epoch 157/1000\n",
      "100/100 [==============================] - 0s 229us/sample - loss: 0.1756 - accuracy: 0.9100 - val_loss: 0.0316 - val_accuracy: 1.0000\n",
      "Epoch 158/1000\n",
      "100/100 [==============================] - 0s 199us/sample - loss: 0.3480 - accuracy: 0.9000 - val_loss: 0.1613 - val_accuracy: 0.9200\n",
      "Epoch 159/1000\n",
      "100/100 [==============================] - 0s 199us/sample - loss: 0.3740 - accuracy: 0.8600 - val_loss: 0.0253 - val_accuracy: 1.0000\n",
      "Epoch 160/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.1777 - accuracy: 0.9300 - val_loss: 0.0662 - val_accuracy: 1.0000\n",
      "Epoch 161/1000\n",
      "100/100 [==============================] - 0s 229us/sample - loss: 0.1424 - accuracy: 0.9600 - val_loss: 0.0739 - val_accuracy: 1.0000\n",
      "Epoch 162/1000\n",
      "100/100 [==============================] - 0s 209us/sample - loss: 0.1210 - accuracy: 0.9600 - val_loss: 0.0571 - val_accuracy: 1.0000\n",
      "Epoch 163/1000\n",
      "100/100 [==============================] - 0s 209us/sample - loss: 0.1098 - accuracy: 0.9600 - val_loss: 0.1153 - val_accuracy: 0.9600\n",
      "Epoch 164/1000\n",
      "100/100 [==============================] - 0s 209us/sample - loss: 0.0982 - accuracy: 0.9500 - val_loss: 0.0529 - val_accuracy: 1.0000\n",
      "Epoch 165/1000\n",
      "100/100 [==============================] - 0s 189us/sample - loss: 0.1262 - accuracy: 0.9500 - val_loss: 0.1470 - val_accuracy: 0.9400\n",
      "Epoch 166/1000\n",
      "100/100 [==============================] - 0s 199us/sample - loss: 0.1512 - accuracy: 0.9600 - val_loss: 0.0492 - val_accuracy: 1.0000\n",
      "Epoch 167/1000\n",
      "100/100 [==============================] - 0s 239us/sample - loss: 0.1207 - accuracy: 0.9500 - val_loss: 0.0599 - val_accuracy: 1.0000\n",
      "Epoch 168/1000\n",
      "100/100 [==============================] - 0s 189us/sample - loss: 0.1090 - accuracy: 0.9600 - val_loss: 0.0512 - val_accuracy: 1.0000\n",
      "Epoch 169/1000\n",
      "100/100 [==============================] - 0s 199us/sample - loss: 0.1100 - accuracy: 0.9600 - val_loss: 0.1097 - val_accuracy: 0.9400\n",
      "Epoch 170/1000\n",
      "100/100 [==============================] - 0s 199us/sample - loss: 0.2224 - accuracy: 0.9000 - val_loss: 0.0473 - val_accuracy: 1.0000\n",
      "Epoch 171/1000\n",
      "100/100 [==============================] - 0s 229us/sample - loss: 0.2121 - accuracy: 0.9000 - val_loss: 0.1331 - val_accuracy: 0.9400\n",
      "Epoch 172/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.2651 - accuracy: 0.8900 - val_loss: 0.0648 - val_accuracy: 1.0000\n",
      "Epoch 173/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.1047 - accuracy: 0.9600 - val_loss: 0.0422 - val_accuracy: 1.0000\n",
      "Epoch 174/1000\n",
      "100/100 [==============================] - 0s 190us/sample - loss: 0.0964 - accuracy: 0.9600 - val_loss: 0.1596 - val_accuracy: 0.9200\n",
      "Epoch 175/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.1179 - accuracy: 0.9600 - val_loss: 0.0536 - val_accuracy: 1.0000\n",
      "Epoch 176/1000\n",
      "100/100 [==============================] - 0s 199us/sample - loss: 0.1534 - accuracy: 0.9300 - val_loss: 0.0829 - val_accuracy: 0.9600\n",
      "Epoch 177/1000\n",
      "100/100 [==============================] - 0s 190us/sample - loss: 0.0950 - accuracy: 0.9600 - val_loss: 0.0483 - val_accuracy: 1.0000\n",
      "Epoch 178/1000\n",
      "100/100 [==============================] - 0s 199us/sample - loss: 0.0820 - accuracy: 0.9700 - val_loss: 0.0423 - val_accuracy: 1.0000\n",
      "Epoch 179/1000\n",
      "100/100 [==============================] - 0s 279us/sample - loss: 0.0933 - accuracy: 0.9600 - val_loss: 0.0552 - val_accuracy: 1.0000\n",
      "Epoch 180/1000\n",
      "100/100 [==============================] - 0s 279us/sample - loss: 0.0786 - accuracy: 0.9700 - val_loss: 0.0349 - val_accuracy: 1.0000\n",
      "Epoch 181/1000\n",
      "100/100 [==============================] - 0s 309us/sample - loss: 0.0867 - accuracy: 0.9800 - val_loss: 0.0664 - val_accuracy: 0.9800\n",
      "Epoch 182/1000\n",
      "100/100 [==============================] - 0s 259us/sample - loss: 0.0851 - accuracy: 0.9800 - val_loss: 0.0427 - val_accuracy: 1.0000\n",
      "Epoch 183/1000\n",
      "100/100 [==============================] - 0s 269us/sample - loss: 0.0800 - accuracy: 0.9700 - val_loss: 0.0612 - val_accuracy: 1.0000\n",
      "Epoch 184/1000\n",
      "100/100 [==============================] - 0s 239us/sample - loss: 0.0759 - accuracy: 0.9700 - val_loss: 0.0326 - val_accuracy: 1.0000\n",
      "Epoch 185/1000\n",
      "100/100 [==============================] - 0s 289us/sample - loss: 0.0841 - accuracy: 0.9700 - val_loss: 0.0600 - val_accuracy: 1.0000\n",
      "Epoch 186/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0773 - accuracy: 0.96 - 0s 229us/sample - loss: 0.1220 - accuracy: 0.9600 - val_loss: 0.0261 - val_accuracy: 1.0000\n",
      "Epoch 187/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1351 - accuracy: 0.93 - 0s 249us/sample - loss: 0.1136 - accuracy: 0.9600 - val_loss: 0.0428 - val_accuracy: 1.0000\n",
      "Epoch 188/1000\n",
      "100/100 [==============================] - 0s 529us/sample - loss: 0.0712 - accuracy: 0.9700 - val_loss: 0.0913 - val_accuracy: 0.9400\n",
      "Epoch 189/1000\n",
      "100/100 [==============================] - 0s 279us/sample - loss: 0.0874 - accuracy: 0.9600 - val_loss: 0.0373 - val_accuracy: 1.0000\n",
      "Epoch 190/1000\n",
      "100/100 [==============================] - 0s 259us/sample - loss: 0.0740 - accuracy: 0.9700 - val_loss: 0.0624 - val_accuracy: 0.9800\n",
      "Epoch 191/1000\n",
      "100/100 [==============================] - 0s 289us/sample - loss: 0.0793 - accuracy: 0.9800 - val_loss: 0.0527 - val_accuracy: 1.0000\n",
      "Epoch 192/1000\n",
      "100/100 [==============================] - 0s 249us/sample - loss: 0.0745 - accuracy: 0.9800 - val_loss: 0.0553 - val_accuracy: 1.0000\n",
      "Epoch 193/1000\n",
      "100/100 [==============================] - 0s 209us/sample - loss: 0.0796 - accuracy: 0.9800 - val_loss: 0.0320 - val_accuracy: 1.0000\n",
      "Epoch 194/1000\n",
      "100/100 [==============================] - 0s 209us/sample - loss: 0.0732 - accuracy: 0.9800 - val_loss: 0.0847 - val_accuracy: 0.9400\n",
      "Epoch 195/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.0833 - accuracy: 0.9600 - val_loss: 0.0313 - val_accuracy: 1.0000\n",
      "Epoch 196/1000\n",
      "100/100 [==============================] - 0s 269us/sample - loss: 0.0762 - accuracy: 0.9700 - val_loss: 0.0666 - val_accuracy: 0.9600\n",
      "Epoch 197/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.0803 - accuracy: 0.9700 - val_loss: 0.0257 - val_accuracy: 1.0000\n",
      "Epoch 198/1000\n",
      "100/100 [==============================] - 0s 279us/sample - loss: 0.0915 - accuracy: 0.9700 - val_loss: 0.0555 - val_accuracy: 0.9800\n",
      "Epoch 199/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.0837 - accuracy: 0.9700 - val_loss: 0.0351 - val_accuracy: 1.0000\n",
      "Epoch 200/1000\n",
      "100/100 [==============================] - 0s 269us/sample - loss: 0.0786 - accuracy: 0.9700 - val_loss: 0.0346 - val_accuracy: 1.0000\n",
      "Epoch 201/1000\n",
      "100/100 [==============================] - 0s 259us/sample - loss: 0.0765 - accuracy: 0.9800 - val_loss: 0.0588 - val_accuracy: 0.9800\n",
      "Epoch 202/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.0822 - accuracy: 0.9700 - val_loss: 0.0452 - val_accuracy: 1.0000\n",
      "Epoch 203/1000\n",
      "100/100 [==============================] - 0s 239us/sample - loss: 0.0710 - accuracy: 0.9800 - val_loss: 0.0687 - val_accuracy: 0.9600\n",
      "Epoch 204/1000\n",
      "100/100 [==============================] - 0s 229us/sample - loss: 0.0729 - accuracy: 0.9700 - val_loss: 0.0234 - val_accuracy: 1.0000\n",
      "Epoch 205/1000\n",
      "100/100 [==============================] - 0s 189us/sample - loss: 0.0879 - accuracy: 0.9700 - val_loss: 0.0364 - val_accuracy: 1.0000\n",
      "Epoch 206/1000\n",
      "100/100 [==============================] - 0s 239us/sample - loss: 0.0742 - accuracy: 0.9700 - val_loss: 0.0798 - val_accuracy: 0.9400\n",
      "Epoch 207/1000\n",
      "100/100 [==============================] - 0s 209us/sample - loss: 0.1087 - accuracy: 0.9500 - val_loss: 0.0258 - val_accuracy: 1.0000\n",
      "Epoch 208/1000\n",
      "100/100 [==============================] - 0s 239us/sample - loss: 0.0767 - accuracy: 0.9700 - val_loss: 0.0607 - val_accuracy: 0.9600\n",
      "Epoch 209/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.0911 - accuracy: 0.9500 - val_loss: 0.0301 - val_accuracy: 1.0000\n",
      "Epoch 210/1000\n",
      "100/100 [==============================] - 0s 249us/sample - loss: 0.0861 - accuracy: 0.9800 - val_loss: 0.0370 - val_accuracy: 1.0000\n",
      "Epoch 211/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.0668 - accuracy: 0.9700 - val_loss: 0.0720 - val_accuracy: 0.9600\n",
      "Epoch 212/1000\n",
      "100/100 [==============================] - 0s 229us/sample - loss: 0.0858 - accuracy: 0.9600 - val_loss: 0.0268 - val_accuracy: 1.0000\n",
      "Epoch 213/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.0772 - accuracy: 0.9700 - val_loss: 0.0450 - val_accuracy: 1.0000\n",
      "Epoch 214/1000\n",
      "100/100 [==============================] - 0s 279us/sample - loss: 0.0700 - accuracy: 0.9800 - val_loss: 0.0278 - val_accuracy: 1.0000\n",
      "Epoch 215/1000\n",
      "100/100 [==============================] - 0s 269us/sample - loss: 0.0734 - accuracy: 0.9700 - val_loss: 0.0260 - val_accuracy: 1.0000\n",
      "Epoch 216/1000\n",
      "100/100 [==============================] - 0s 339us/sample - loss: 0.0734 - accuracy: 0.9700 - val_loss: 0.0541 - val_accuracy: 0.9800\n",
      "Epoch 217/1000\n",
      "100/100 [==============================] - 0s 499us/sample - loss: 0.0754 - accuracy: 0.9700 - val_loss: 0.0330 - val_accuracy: 1.0000\n",
      "Epoch 218/1000\n",
      "100/100 [==============================] - 0s 269us/sample - loss: 0.0803 - accuracy: 0.9700 - val_loss: 0.0749 - val_accuracy: 0.9600\n",
      "Epoch 219/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s 359us/sample - loss: 0.1039 - accuracy: 0.9600 - val_loss: 0.0358 - val_accuracy: 1.0000\n",
      "Epoch 220/1000\n",
      "100/100 [==============================] - 0s 249us/sample - loss: 0.1302 - accuracy: 0.9400 - val_loss: 0.0497 - val_accuracy: 0.9800\n",
      "Epoch 221/1000\n",
      "100/100 [==============================] - 0s 239us/sample - loss: 0.1374 - accuracy: 0.9400 - val_loss: 0.0266 - val_accuracy: 1.0000\n",
      "Epoch 222/1000\n",
      "100/100 [==============================] - 0s 249us/sample - loss: 0.1024 - accuracy: 0.9500 - val_loss: 0.0464 - val_accuracy: 1.0000\n",
      "Epoch 223/1000\n",
      "100/100 [==============================] - 0s 289us/sample - loss: 0.1006 - accuracy: 0.9600 - val_loss: 0.0732 - val_accuracy: 0.9600\n",
      "Epoch 224/1000\n",
      "100/100 [==============================] - 0s 289us/sample - loss: 0.0608 - accuracy: 0.9700 - val_loss: 0.0208 - val_accuracy: 1.0000\n",
      "Epoch 225/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.1122 - accuracy: 0.9500 - val_loss: 0.0939 - val_accuracy: 0.9400\n",
      "Epoch 226/1000\n",
      "100/100 [==============================] - 0s 249us/sample - loss: 0.0989 - accuracy: 0.9600 - val_loss: 0.0192 - val_accuracy: 1.0000\n",
      "Epoch 227/1000\n",
      "100/100 [==============================] - 0s 239us/sample - loss: 0.1103 - accuracy: 0.9500 - val_loss: 0.0631 - val_accuracy: 0.9600\n",
      "Epoch 228/1000\n",
      "100/100 [==============================] - 0s 229us/sample - loss: 0.0868 - accuracy: 0.9600 - val_loss: 0.0195 - val_accuracy: 1.0000\n",
      "Epoch 229/1000\n",
      "100/100 [==============================] - 0s 259us/sample - loss: 0.1421 - accuracy: 0.9500 - val_loss: 0.0365 - val_accuracy: 1.0000\n",
      "Epoch 230/1000\n",
      "100/100 [==============================] - 0s 229us/sample - loss: 0.0794 - accuracy: 0.9600 - val_loss: 0.0387 - val_accuracy: 1.0000\n",
      "Epoch 231/1000\n",
      "100/100 [==============================] - 0s 329us/sample - loss: 0.1461 - accuracy: 0.9500 - val_loss: 0.0454 - val_accuracy: 1.0000\n",
      "Epoch 232/1000\n",
      "100/100 [==============================] - 0s 239us/sample - loss: 0.0875 - accuracy: 0.9700 - val_loss: 0.0402 - val_accuracy: 1.0000\n",
      "Epoch 233/1000\n",
      "100/100 [==============================] - 0s 239us/sample - loss: 0.1053 - accuracy: 0.9600 - val_loss: 0.0256 - val_accuracy: 1.0000\n",
      "Epoch 234/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.0827 - accuracy: 0.9700 - val_loss: 0.0704 - val_accuracy: 0.9600\n",
      "Epoch 235/1000\n",
      "100/100 [==============================] - 0s 239us/sample - loss: 0.0866 - accuracy: 0.9700 - val_loss: 0.0206 - val_accuracy: 1.0000\n",
      "Epoch 236/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.0820 - accuracy: 0.9800 - val_loss: 0.0501 - val_accuracy: 0.9800\n",
      "Epoch 237/1000\n",
      "100/100 [==============================] - 0s 239us/sample - loss: 0.0693 - accuracy: 0.9800 - val_loss: 0.0284 - val_accuracy: 1.0000\n",
      "Epoch 238/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.0901 - accuracy: 0.9600 - val_loss: 0.0241 - val_accuracy: 1.0000\n",
      "Epoch 239/1000\n",
      "100/100 [==============================] - 0s 229us/sample - loss: 0.1549 - accuracy: 0.9500 - val_loss: 0.0569 - val_accuracy: 0.9600\n",
      "Epoch 240/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.1933 - accuracy: 0.9200 - val_loss: 0.0242 - val_accuracy: 1.0000\n",
      "Epoch 241/1000\n",
      "100/100 [==============================] - 0s 249us/sample - loss: 0.2240 - accuracy: 0.9300 - val_loss: 0.0254 - val_accuracy: 1.0000\n",
      "Epoch 242/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.1993 - accuracy: 0.9100 - val_loss: 0.1032 - val_accuracy: 0.9400\n",
      "Epoch 243/1000\n",
      "100/100 [==============================] - 0s 209us/sample - loss: 0.2930 - accuracy: 0.9000 - val_loss: 0.0368 - val_accuracy: 1.0000\n",
      "Epoch 244/1000\n",
      "100/100 [==============================] - 0s 249us/sample - loss: 0.1122 - accuracy: 0.9300 - val_loss: 0.1709 - val_accuracy: 0.9200\n",
      "Epoch 245/1000\n",
      "100/100 [==============================] - 0s 209us/sample - loss: 0.1162 - accuracy: 0.9300 - val_loss: 0.0266 - val_accuracy: 1.0000\n",
      "Epoch 246/1000\n",
      "100/100 [==============================] - 0s 229us/sample - loss: 0.0739 - accuracy: 0.9700 - val_loss: 0.0932 - val_accuracy: 0.9400\n",
      "Epoch 247/1000\n",
      "100/100 [==============================] - 0s 229us/sample - loss: 0.0816 - accuracy: 0.9700 - val_loss: 0.0241 - val_accuracy: 1.0000\n",
      "Epoch 248/1000\n",
      "100/100 [==============================] - 0s 389us/sample - loss: 0.1062 - accuracy: 0.9500 - val_loss: 0.0491 - val_accuracy: 0.9800\n",
      "Epoch 249/1000\n",
      "100/100 [==============================] - 0s 239us/sample - loss: 0.0902 - accuracy: 0.9500 - val_loss: 0.0245 - val_accuracy: 1.0000\n",
      "Epoch 250/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.1491 - accuracy: 0.9400 - val_loss: 0.0326 - val_accuracy: 1.0000\n",
      "Epoch 251/1000\n",
      "100/100 [==============================] - 0s 249us/sample - loss: 0.1791 - accuracy: 0.9400 - val_loss: 0.0981 - val_accuracy: 0.9400\n",
      "Epoch 252/1000\n",
      "100/100 [==============================] - 0s 249us/sample - loss: 0.0903 - accuracy: 0.9700 - val_loss: 0.0224 - val_accuracy: 1.0000\n",
      "Epoch 253/1000\n",
      "100/100 [==============================] - 0s 249us/sample - loss: 0.1254 - accuracy: 0.9600 - val_loss: 0.0670 - val_accuracy: 0.9600\n",
      "Epoch 254/1000\n",
      "100/100 [==============================] - 0s 239us/sample - loss: 0.1242 - accuracy: 0.9500 - val_loss: 0.0233 - val_accuracy: 1.0000\n",
      "Epoch 255/1000\n",
      "100/100 [==============================] - 0s 229us/sample - loss: 0.1005 - accuracy: 0.9400 - val_loss: 0.0783 - val_accuracy: 0.9400\n",
      "Epoch 256/1000\n",
      "100/100 [==============================] - 0s 239us/sample - loss: 0.1018 - accuracy: 0.9600 - val_loss: 0.0328 - val_accuracy: 1.0000\n",
      "Epoch 257/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.0899 - accuracy: 0.9700 - val_loss: 0.1050 - val_accuracy: 0.9400\n",
      "Epoch 258/1000\n",
      "100/100 [==============================] - 0s 249us/sample - loss: 0.0793 - accuracy: 0.9700 - val_loss: 0.0226 - val_accuracy: 1.0000\n",
      "Epoch 259/1000\n",
      "100/100 [==============================] - 0s 239us/sample - loss: 0.1168 - accuracy: 0.9500 - val_loss: 0.0430 - val_accuracy: 1.0000\n",
      "Epoch 260/1000\n",
      "100/100 [==============================] - 0s 319us/sample - loss: 0.0716 - accuracy: 0.9600 - val_loss: 0.0493 - val_accuracy: 0.9800\n",
      "Epoch 261/1000\n",
      "100/100 [==============================] - 0s 259us/sample - loss: 0.0750 - accuracy: 0.9700 - val_loss: 0.0203 - val_accuracy: 1.0000\n",
      "Epoch 262/1000\n",
      "100/100 [==============================] - 0s 239us/sample - loss: 0.0921 - accuracy: 0.9600 - val_loss: 0.0337 - val_accuracy: 1.0000\n",
      "Epoch 263/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.1023 - accuracy: 0.9500 - val_loss: 0.0246 - val_accuracy: 1.0000\n",
      "Epoch 264/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.0850 - accuracy: 0.9500 - val_loss: 0.0646 - val_accuracy: 0.9600\n",
      "Epoch 265/1000\n",
      "100/100 [==============================] - 0s 209us/sample - loss: 0.0729 - accuracy: 0.9600 - val_loss: 0.0194 - val_accuracy: 1.0000\n",
      "Epoch 266/1000\n",
      "100/100 [==============================] - 0s 239us/sample - loss: 0.0803 - accuracy: 0.9700 - val_loss: 0.0810 - val_accuracy: 0.9400\n",
      "Epoch 267/1000\n",
      "100/100 [==============================] - 0s 209us/sample - loss: 0.1097 - accuracy: 0.9600 - val_loss: 0.0450 - val_accuracy: 0.9800\n",
      "Epoch 268/1000\n",
      "100/100 [==============================] - 0s 229us/sample - loss: 0.0794 - accuracy: 0.9800 - val_loss: 0.0281 - val_accuracy: 1.0000\n",
      "Epoch 269/1000\n",
      "100/100 [==============================] - 0s 239us/sample - loss: 0.0700 - accuracy: 0.9700 - val_loss: 0.0589 - val_accuracy: 0.9600\n",
      "Epoch 270/1000\n",
      "100/100 [==============================] - 0s 259us/sample - loss: 0.0759 - accuracy: 0.9600 - val_loss: 0.0170 - val_accuracy: 1.0000\n",
      "Epoch 271/1000\n",
      "100/100 [==============================] - 0s 229us/sample - loss: 0.1271 - accuracy: 0.9400 - val_loss: 0.0170 - val_accuracy: 1.0000\n",
      "Epoch 272/1000\n",
      "100/100 [==============================] - 0s 259us/sample - loss: 0.1051 - accuracy: 0.9600 - val_loss: 0.0725 - val_accuracy: 0.9600\n",
      "Epoch 273/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.0890 - accuracy: 0.9700 - val_loss: 0.0183 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 274/1000\n",
      "100/100 [==============================] - 0s 499us/sample - loss: 0.0657 - accuracy: 0.9700 - val_loss: 0.1146 - val_accuracy: 0.9400\n",
      "Epoch 275/1000\n",
      "100/100 [==============================] - 0s 199us/sample - loss: 0.0978 - accuracy: 0.9600 - val_loss: 0.0221 - val_accuracy: 1.0000\n",
      "Epoch 276/1000\n",
      "100/100 [==============================] - 0s 309us/sample - loss: 0.0731 - accuracy: 0.9700 - val_loss: 0.0444 - val_accuracy: 0.9800\n",
      "Epoch 277/1000\n",
      "100/100 [==============================] - 0s 259us/sample - loss: 0.0714 - accuracy: 0.9700 - val_loss: 0.0338 - val_accuracy: 1.0000\n",
      "Epoch 278/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.0774 - accuracy: 0.9800 - val_loss: 0.0346 - val_accuracy: 1.0000\n",
      "Epoch 279/1000\n",
      "100/100 [==============================] - 0s 229us/sample - loss: 0.0875 - accuracy: 0.9700 - val_loss: 0.0766 - val_accuracy: 0.9400\n",
      "Epoch 280/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.0867 - accuracy: 0.9500 - val_loss: 0.0175 - val_accuracy: 1.0000\n",
      "Epoch 281/1000\n",
      "100/100 [==============================] - 0s 209us/sample - loss: 0.0831 - accuracy: 0.9700 - val_loss: 0.0560 - val_accuracy: 0.9600\n",
      "Epoch 282/1000\n",
      "100/100 [==============================] - 0s 239us/sample - loss: 0.0767 - accuracy: 0.9700 - val_loss: 0.0278 - val_accuracy: 1.0000\n",
      "Epoch 283/1000\n",
      "100/100 [==============================] - 0s 199us/sample - loss: 0.0764 - accuracy: 0.9700 - val_loss: 0.0300 - val_accuracy: 1.0000\n",
      "Epoch 284/1000\n",
      "100/100 [==============================] - 0s 249us/sample - loss: 0.0807 - accuracy: 0.9600 - val_loss: 0.0392 - val_accuracy: 1.0000\n",
      "Epoch 285/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.0637 - accuracy: 0.9700 - val_loss: 0.0212 - val_accuracy: 1.0000\n",
      "Epoch 286/1000\n",
      "100/100 [==============================] - 0s 239us/sample - loss: 0.0723 - accuracy: 0.9700 - val_loss: 0.0561 - val_accuracy: 0.9600\n",
      "Epoch 287/1000\n",
      "100/100 [==============================] - 0s 249us/sample - loss: 0.0774 - accuracy: 0.9700 - val_loss: 0.0305 - val_accuracy: 1.0000\n",
      "Epoch 288/1000\n",
      "100/100 [==============================] - 0s 209us/sample - loss: 0.0788 - accuracy: 0.9600 - val_loss: 0.0330 - val_accuracy: 1.0000\n",
      "Epoch 289/1000\n",
      "100/100 [==============================] - 0s 239us/sample - loss: 0.1006 - accuracy: 0.9500 - val_loss: 0.0383 - val_accuracy: 1.0000\n",
      "Epoch 290/1000\n",
      "100/100 [==============================] - 0s 239us/sample - loss: 0.0913 - accuracy: 0.9600 - val_loss: 0.0156 - val_accuracy: 1.0000\n",
      "Epoch 291/1000\n",
      "100/100 [==============================] - 0s 269us/sample - loss: 0.0767 - accuracy: 0.9700 - val_loss: 0.1247 - val_accuracy: 0.9400\n",
      "Epoch 292/1000\n",
      "100/100 [==============================] - 0s 239us/sample - loss: 0.0916 - accuracy: 0.9700 - val_loss: 0.0150 - val_accuracy: 1.0000\n",
      "Epoch 293/1000\n",
      "100/100 [==============================] - 0s 209us/sample - loss: 0.2193 - accuracy: 0.9300 - val_loss: 0.0257 - val_accuracy: 1.0000\n",
      "Epoch 294/1000\n",
      "100/100 [==============================] - 0s 239us/sample - loss: 0.1071 - accuracy: 0.9500 - val_loss: 0.0801 - val_accuracy: 0.9400\n",
      "Epoch 295/1000\n",
      "100/100 [==============================] - 0s 229us/sample - loss: 0.0634 - accuracy: 0.9700 - val_loss: 0.0187 - val_accuracy: 1.0000\n",
      "Epoch 296/1000\n",
      "100/100 [==============================] - 0s 239us/sample - loss: 0.1112 - accuracy: 0.9500 - val_loss: 0.0646 - val_accuracy: 0.9600\n",
      "Epoch 297/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.0716 - accuracy: 0.9700 - val_loss: 0.0307 - val_accuracy: 1.0000\n",
      "Epoch 298/1000\n",
      "100/100 [==============================] - 0s 289us/sample - loss: 0.0755 - accuracy: 0.9700 - val_loss: 0.0356 - val_accuracy: 1.0000\n",
      "Epoch 299/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.0749 - accuracy: 0.9700 - val_loss: 0.0547 - val_accuracy: 0.9600\n",
      "Epoch 300/1000\n",
      "100/100 [==============================] - 0s 249us/sample - loss: 0.0842 - accuracy: 0.9700 - val_loss: 0.0205 - val_accuracy: 1.0000\n",
      "Epoch 301/1000\n",
      "100/100 [==============================] - 0s 239us/sample - loss: 0.0888 - accuracy: 0.9600 - val_loss: 0.0212 - val_accuracy: 1.0000\n",
      "Epoch 302/1000\n",
      "100/100 [==============================] - 0s 239us/sample - loss: 0.1114 - accuracy: 0.9400 - val_loss: 0.0166 - val_accuracy: 1.0000\n",
      "Epoch 303/1000\n",
      "100/100 [==============================] - 0s 249us/sample - loss: 0.0687 - accuracy: 0.9800 - val_loss: 0.1622 - val_accuracy: 0.9200\n",
      "Epoch 304/1000\n",
      "100/100 [==============================] - 0s 259us/sample - loss: 0.1178 - accuracy: 0.9500 - val_loss: 0.0167 - val_accuracy: 1.0000\n",
      "Epoch 305/1000\n",
      "100/100 [==============================] - 0s 229us/sample - loss: 0.1294 - accuracy: 0.9500 - val_loss: 0.0368 - val_accuracy: 1.0000\n",
      "Epoch 306/1000\n",
      "100/100 [==============================] - 0s 229us/sample - loss: 0.0673 - accuracy: 0.9800 - val_loss: 0.0672 - val_accuracy: 0.9600\n",
      "Epoch 307/1000\n",
      "100/100 [==============================] - 0s 229us/sample - loss: 0.0725 - accuracy: 0.9700 - val_loss: 0.0278 - val_accuracy: 1.0000\n",
      "Epoch 308/1000\n",
      "100/100 [==============================] - 0s 229us/sample - loss: 0.0827 - accuracy: 0.9600 - val_loss: 0.0332 - val_accuracy: 1.0000\n",
      "Epoch 309/1000\n",
      "100/100 [==============================] - 0s 209us/sample - loss: 0.0985 - accuracy: 0.9600 - val_loss: 0.0369 - val_accuracy: 1.0000\n",
      "Epoch 310/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.1142 - accuracy: 0.9500 - val_loss: 0.0189 - val_accuracy: 1.0000\n",
      "Epoch 311/1000\n",
      "100/100 [==============================] - 0s 209us/sample - loss: 0.1060 - accuracy: 0.9600 - val_loss: 0.1616 - val_accuracy: 0.9200\n",
      "Epoch 312/1000\n",
      "100/100 [==============================] - 0s 239us/sample - loss: 0.1302 - accuracy: 0.9400 - val_loss: 0.0178 - val_accuracy: 1.0000\n",
      "Epoch 313/1000\n",
      "100/100 [==============================] - 0s 189us/sample - loss: 0.1048 - accuracy: 0.9500 - val_loss: 0.0606 - val_accuracy: 0.9600\n",
      "Epoch 314/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.0992 - accuracy: 0.9600 - val_loss: 0.0178 - val_accuracy: 1.0000\n",
      "Epoch 315/1000\n",
      "100/100 [==============================] - 0s 239us/sample - loss: 0.2214 - accuracy: 0.9500 - val_loss: 0.0173 - val_accuracy: 1.0000\n",
      "Epoch 316/1000\n",
      "100/100 [==============================] - 0s 229us/sample - loss: 0.0770 - accuracy: 0.9700 - val_loss: 0.1399 - val_accuracy: 0.9400\n",
      "Epoch 317/1000\n",
      "100/100 [==============================] - 0s 209us/sample - loss: 0.0996 - accuracy: 0.9700 - val_loss: 0.0169 - val_accuracy: 1.0000\n",
      "Epoch 318/1000\n",
      "100/100 [==============================] - 0s 239us/sample - loss: 0.0927 - accuracy: 0.9600 - val_loss: 0.0565 - val_accuracy: 0.9600\n",
      "Epoch 319/1000\n",
      "100/100 [==============================] - 0s 259us/sample - loss: 0.0746 - accuracy: 0.9700 - val_loss: 0.0302 - val_accuracy: 1.0000\n",
      "Epoch 320/1000\n",
      "100/100 [==============================] - 0s 229us/sample - loss: 0.1090 - accuracy: 0.9500 - val_loss: 0.0425 - val_accuracy: 0.9800\n",
      "Epoch 321/1000\n",
      "100/100 [==============================] - 0s 249us/sample - loss: 0.1741 - accuracy: 0.9300 - val_loss: 0.0322 - val_accuracy: 1.0000\n",
      "Epoch 322/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.0897 - accuracy: 0.9700 - val_loss: 0.0492 - val_accuracy: 1.0000\n",
      "Epoch 323/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.1436 - accuracy: 0.9400 - val_loss: 0.1780 - val_accuracy: 0.9200\n",
      "Epoch 324/1000\n",
      "100/100 [==============================] - 0s 279us/sample - loss: 0.1684 - accuracy: 0.9300 - val_loss: 0.0162 - val_accuracy: 1.0000\n",
      "Epoch 325/1000\n",
      "100/100 [==============================] - 0s 229us/sample - loss: 0.1482 - accuracy: 0.9400 - val_loss: 0.0452 - val_accuracy: 0.9800\n",
      "Epoch 326/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.1641 - accuracy: 0.9400 - val_loss: 0.1978 - val_accuracy: 0.9000\n",
      "Epoch 327/1000\n",
      "100/100 [==============================] - 0s 199us/sample - loss: 0.1549 - accuracy: 0.9300 - val_loss: 0.0157 - val_accuracy: 1.0000\n",
      "Epoch 328/1000\n",
      "100/100 [==============================] - 0s 209us/sample - loss: 0.0814 - accuracy: 0.9500 - val_loss: 0.0982 - val_accuracy: 0.9400\n",
      "Epoch 329/1000\n",
      "100/100 [==============================] - 0s 209us/sample - loss: 0.0802 - accuracy: 0.9500 - val_loss: 0.0165 - val_accuracy: 1.0000\n",
      "Epoch 330/1000\n",
      "100/100 [==============================] - 0s 259us/sample - loss: 0.1292 - accuracy: 0.9500 - val_loss: 0.0371 - val_accuracy: 1.0000\n",
      "Epoch 331/1000\n",
      "100/100 [==============================] - 0s 199us/sample - loss: 0.0903 - accuracy: 0.9700 - val_loss: 0.0346 - val_accuracy: 1.0000\n",
      "Epoch 332/1000\n",
      "100/100 [==============================] - 0s 199us/sample - loss: 0.0883 - accuracy: 0.9700 - val_loss: 0.0184 - val_accuracy: 1.0000\n",
      "Epoch 333/1000\n",
      "100/100 [==============================] - 0s 189us/sample - loss: 0.1212 - accuracy: 0.9500 - val_loss: 0.1830 - val_accuracy: 0.9200\n",
      "Epoch 334/1000\n",
      "100/100 [==============================] - 0s 209us/sample - loss: 0.1558 - accuracy: 0.9300 - val_loss: 0.0159 - val_accuracy: 1.0000\n",
      "Epoch 335/1000\n",
      "100/100 [==============================] - 0s 199us/sample - loss: 0.1565 - accuracy: 0.9400 - val_loss: 0.0342 - val_accuracy: 1.0000\n",
      "Epoch 336/1000\n",
      "100/100 [==============================] - 0s 229us/sample - loss: 0.1344 - accuracy: 0.9400 - val_loss: 0.0207 - val_accuracy: 1.0000\n",
      "Epoch 337/1000\n",
      "100/100 [==============================] - 0s 259us/sample - loss: 0.1877 - accuracy: 0.9400 - val_loss: 0.0181 - val_accuracy: 1.0000\n",
      "Epoch 338/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.1136 - accuracy: 0.9500 - val_loss: 0.0853 - val_accuracy: 0.9400\n",
      "Epoch 339/1000\n",
      "100/100 [==============================] - 0s 209us/sample - loss: 0.0644 - accuracy: 0.9800 - val_loss: 0.0160 - val_accuracy: 1.0000\n",
      "Epoch 340/1000\n",
      "100/100 [==============================] - 0s 249us/sample - loss: 0.1047 - accuracy: 0.9500 - val_loss: 0.0550 - val_accuracy: 0.9600\n",
      "Epoch 341/1000\n",
      "100/100 [==============================] - 0s 190us/sample - loss: 0.1038 - accuracy: 0.9600 - val_loss: 0.0395 - val_accuracy: 1.0000\n",
      "Epoch 342/1000\n",
      "100/100 [==============================] - 0s 249us/sample - loss: 0.0620 - accuracy: 0.9800 - val_loss: 0.0150 - val_accuracy: 1.0000\n",
      "Epoch 343/1000\n",
      "100/100 [==============================] - 0s 189us/sample - loss: 0.0909 - accuracy: 0.9500 - val_loss: 0.1012 - val_accuracy: 0.9400\n",
      "Epoch 344/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.1449 - accuracy: 0.9200 - val_loss: 0.0147 - val_accuracy: 1.0000\n",
      "Epoch 345/1000\n",
      "100/100 [==============================] - 0s 309us/sample - loss: 0.1901 - accuracy: 0.9300 - val_loss: 0.0153 - val_accuracy: 1.0000\n",
      "Epoch 346/1000\n",
      "100/100 [==============================] - 0s 199us/sample - loss: 0.0951 - accuracy: 0.9700 - val_loss: 0.1090 - val_accuracy: 0.9400\n",
      "Epoch 347/1000\n",
      "100/100 [==============================] - 0s 229us/sample - loss: 0.0997 - accuracy: 0.9400 - val_loss: 0.0146 - val_accuracy: 1.0000\n",
      "Epoch 348/1000\n",
      "100/100 [==============================] - 0s 239us/sample - loss: 0.0935 - accuracy: 0.9600 - val_loss: 0.0575 - val_accuracy: 0.9600\n",
      "Epoch 349/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.0771 - accuracy: 0.9600 - val_loss: 0.0405 - val_accuracy: 1.0000\n",
      "Epoch 350/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.1014 - accuracy: 0.9600 - val_loss: 0.0323 - val_accuracy: 1.0000\n",
      "Epoch 351/1000\n",
      "100/100 [==============================] - 0s 199us/sample - loss: 0.0726 - accuracy: 0.9700 - val_loss: 0.0878 - val_accuracy: 0.9400\n",
      "Epoch 352/1000\n",
      "100/100 [==============================] - 0s 229us/sample - loss: 0.1184 - accuracy: 0.9600 - val_loss: 0.0196 - val_accuracy: 1.0000\n",
      "Epoch 353/1000\n",
      "100/100 [==============================] - 0s 209us/sample - loss: 0.0936 - accuracy: 0.9600 - val_loss: 0.0293 - val_accuracy: 1.0000\n",
      "Epoch 354/1000\n",
      "100/100 [==============================] - 0s 229us/sample - loss: 0.0769 - accuracy: 0.9600 - val_loss: 0.1063 - val_accuracy: 0.9400\n",
      "Epoch 355/1000\n",
      "100/100 [==============================] - 0s 189us/sample - loss: 0.0790 - accuracy: 0.9500 - val_loss: 0.0149 - val_accuracy: 1.0000\n",
      "Epoch 356/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.0740 - accuracy: 0.9700 - val_loss: 0.0723 - val_accuracy: 0.9400\n",
      "Epoch 357/1000\n",
      "100/100 [==============================] - 0s 209us/sample - loss: 0.0819 - accuracy: 0.9500 - val_loss: 0.0394 - val_accuracy: 1.0000\n",
      "Epoch 358/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.0618 - accuracy: 0.9800 - val_loss: 0.0205 - val_accuracy: 1.0000\n",
      "Epoch 359/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.0670 - accuracy: 0.9700 - val_loss: 0.0536 - val_accuracy: 0.9600\n",
      "Epoch 360/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.0693 - accuracy: 0.9700 - val_loss: 0.0522 - val_accuracy: 0.9600\n",
      "Epoch 361/1000\n",
      "100/100 [==============================] - 0s 239us/sample - loss: 0.0771 - accuracy: 0.9500 - val_loss: 0.0162 - val_accuracy: 1.0000\n",
      "Epoch 362/1000\n",
      "100/100 [==============================] - 0s 249us/sample - loss: 0.0916 - accuracy: 0.9700 - val_loss: 0.0120 - val_accuracy: 1.0000\n",
      "Epoch 363/1000\n",
      "100/100 [==============================] - 0s 199us/sample - loss: 0.1408 - accuracy: 0.9400 - val_loss: 0.0488 - val_accuracy: 0.9800\n",
      "Epoch 364/1000\n",
      "100/100 [==============================] - 0s 239us/sample - loss: 0.0743 - accuracy: 0.9800 - val_loss: 0.0130 - val_accuracy: 1.0000\n",
      "Epoch 365/1000\n",
      "100/100 [==============================] - 0s 209us/sample - loss: 0.1262 - accuracy: 0.9500 - val_loss: 0.1183 - val_accuracy: 0.9400\n",
      "Epoch 366/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.1021 - accuracy: 0.9500 - val_loss: 0.0166 - val_accuracy: 1.0000\n",
      "Epoch 367/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.0788 - accuracy: 0.9600 - val_loss: 0.0412 - val_accuracy: 0.9800\n",
      "Epoch 368/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.0696 - accuracy: 0.9800 - val_loss: 0.0546 - val_accuracy: 0.9600\n",
      "Epoch 369/1000\n",
      "100/100 [==============================] - 0s 209us/sample - loss: 0.0930 - accuracy: 0.9700 - val_loss: 0.0264 - val_accuracy: 1.0000\n",
      "Epoch 370/1000\n",
      "100/100 [==============================] - 0s 209us/sample - loss: 0.1701 - accuracy: 0.9500 - val_loss: 0.0197 - val_accuracy: 1.0000\n",
      "Epoch 371/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.1078 - accuracy: 0.9500 - val_loss: 0.0604 - val_accuracy: 0.9600\n",
      "Epoch 372/1000\n",
      "100/100 [==============================] - 0s 199us/sample - loss: 0.1782 - accuracy: 0.9700 - val_loss: 0.0160 - val_accuracy: 1.0000\n",
      "Epoch 373/1000\n",
      "100/100 [==============================] - 0s 199us/sample - loss: 0.2049 - accuracy: 0.9200 - val_loss: 0.3131 - val_accuracy: 0.8600\n",
      "Epoch 374/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.1838 - accuracy: 0.9200 - val_loss: 0.0474 - val_accuracy: 1.0000\n",
      "Epoch 375/1000\n",
      "100/100 [==============================] - 0s 209us/sample - loss: 0.1786 - accuracy: 0.9400 - val_loss: 0.0726 - val_accuracy: 0.9600\n",
      "Epoch 376/1000\n",
      "100/100 [==============================] - 0s 249us/sample - loss: 0.1373 - accuracy: 0.9400 - val_loss: 0.0489 - val_accuracy: 0.9800\n",
      "Epoch 377/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.0589 - accuracy: 0.9700 - val_loss: 0.0141 - val_accuracy: 1.0000\n",
      "Epoch 378/1000\n",
      "100/100 [==============================] - 0s 279us/sample - loss: 0.0976 - accuracy: 0.9400 - val_loss: 0.0455 - val_accuracy: 0.9800\n",
      "Epoch 379/1000\n",
      "100/100 [==============================] - 0s 229us/sample - loss: 0.0644 - accuracy: 0.9800 - val_loss: 0.0462 - val_accuracy: 0.9800\n",
      "Epoch 380/1000\n",
      "100/100 [==============================] - 0s 209us/sample - loss: 0.0730 - accuracy: 0.9700 - val_loss: 0.0214 - val_accuracy: 1.0000\n",
      "Epoch 381/1000\n",
      "100/100 [==============================] - 0s 199us/sample - loss: 0.0760 - accuracy: 0.9700 - val_loss: 0.0266 - val_accuracy: 1.0000\n",
      "Epoch 382/1000\n",
      "100/100 [==============================] - 0s 209us/sample - loss: 0.0630 - accuracy: 0.9700 - val_loss: 0.0691 - val_accuracy: 0.9600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 383/1000\n",
      "100/100 [==============================] - 0s 209us/sample - loss: 0.0677 - accuracy: 0.9700 - val_loss: 0.0264 - val_accuracy: 1.0000\n",
      "Epoch 384/1000\n",
      "100/100 [==============================] - 0s 259us/sample - loss: 0.0655 - accuracy: 0.9800 - val_loss: 0.0350 - val_accuracy: 1.0000\n",
      "Epoch 385/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.0633 - accuracy: 0.9800 - val_loss: 0.0274 - val_accuracy: 1.0000\n",
      "Epoch 386/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.0665 - accuracy: 0.9800 - val_loss: 0.0322 - val_accuracy: 1.0000\n",
      "Epoch 387/1000\n",
      "100/100 [==============================] - 0s 209us/sample - loss: 0.0627 - accuracy: 0.9800 - val_loss: 0.0209 - val_accuracy: 1.0000\n",
      "Epoch 388/1000\n",
      "100/100 [==============================] - 0s 200us/sample - loss: 0.0793 - accuracy: 0.9700 - val_loss: 0.0385 - val_accuracy: 0.9800\n",
      "Epoch 389/1000\n",
      "100/100 [==============================] - 0s 209us/sample - loss: 0.1575 - accuracy: 0.9300 - val_loss: 0.0302 - val_accuracy: 1.0000\n",
      "Epoch 390/1000\n",
      "100/100 [==============================] - 0s 209us/sample - loss: 0.0706 - accuracy: 0.9700 - val_loss: 0.0113 - val_accuracy: 1.0000\n",
      "Epoch 391/1000\n",
      "100/100 [==============================] - 0s 180us/sample - loss: 0.0825 - accuracy: 0.9700 - val_loss: 0.0773 - val_accuracy: 0.9400\n",
      "Epoch 392/1000\n",
      "100/100 [==============================] - 0s 229us/sample - loss: 0.1035 - accuracy: 0.9600 - val_loss: 0.0275 - val_accuracy: 1.0000\n",
      "Epoch 393/1000\n",
      "100/100 [==============================] - 0s 209us/sample - loss: 0.0981 - accuracy: 0.9400 - val_loss: 0.0172 - val_accuracy: 1.0000\n",
      "Epoch 394/1000\n",
      "100/100 [==============================] - 0s 209us/sample - loss: 0.0646 - accuracy: 0.9700 - val_loss: 0.1124 - val_accuracy: 0.9400\n",
      "Epoch 395/1000\n",
      "100/100 [==============================] - 0s 249us/sample - loss: 0.0903 - accuracy: 0.9500 - val_loss: 0.0191 - val_accuracy: 1.0000\n",
      "Epoch 396/1000\n",
      "100/100 [==============================] - 0s 209us/sample - loss: 0.0775 - accuracy: 0.9700 - val_loss: 0.0944 - val_accuracy: 0.9400\n",
      "Epoch 397/1000\n",
      "100/100 [==============================] - 0s 229us/sample - loss: 0.2538 - accuracy: 0.8700 - val_loss: 0.0170 - val_accuracy: 1.0000\n",
      "Epoch 398/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.2555 - accuracy: 0.9100 - val_loss: 0.0277 - val_accuracy: 1.0000\n",
      "Epoch 399/1000\n",
      "100/100 [==============================] - 0s 209us/sample - loss: 0.1756 - accuracy: 0.9300 - val_loss: 0.4859 - val_accuracy: 0.8200\n",
      "Epoch 400/1000\n",
      "100/100 [==============================] - 0s 229us/sample - loss: 0.2866 - accuracy: 0.8800 - val_loss: 0.0488 - val_accuracy: 1.0000\n",
      "Epoch 401/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.2674 - accuracy: 0.9200 - val_loss: 0.0286 - val_accuracy: 1.0000\n",
      "Epoch 402/1000\n",
      "100/100 [==============================] - 0s 239us/sample - loss: 0.1904 - accuracy: 0.9300 - val_loss: 0.0615 - val_accuracy: 0.9600\n",
      "Epoch 403/1000\n",
      "100/100 [==============================] - 0s 249us/sample - loss: 0.1524 - accuracy: 0.9500 - val_loss: 0.0380 - val_accuracy: 1.0000\n",
      "Epoch 404/1000\n",
      "100/100 [==============================] - 0s 239us/sample - loss: 0.2064 - accuracy: 0.9400 - val_loss: 0.2547 - val_accuracy: 0.8800\n",
      "Epoch 405/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.1830 - accuracy: 0.9000 - val_loss: 0.0267 - val_accuracy: 1.0000\n",
      "Epoch 406/1000\n",
      "100/100 [==============================] - 0s 229us/sample - loss: 0.1452 - accuracy: 0.9500 - val_loss: 0.0932 - val_accuracy: 0.9400\n",
      "Epoch 407/1000\n",
      "100/100 [==============================] - 0s 229us/sample - loss: 0.1111 - accuracy: 0.9500 - val_loss: 0.0337 - val_accuracy: 1.0000\n",
      "Epoch 408/1000\n",
      "100/100 [==============================] - 0s 180us/sample - loss: 0.0594 - accuracy: 0.9800 - val_loss: 0.0135 - val_accuracy: 1.0000\n",
      "Epoch 409/1000\n",
      "100/100 [==============================] - 0s 199us/sample - loss: 0.0856 - accuracy: 0.9700 - val_loss: 0.0549 - val_accuracy: 0.9600\n",
      "Epoch 410/1000\n",
      "100/100 [==============================] - 0s 239us/sample - loss: 0.0771 - accuracy: 0.9600 - val_loss: 0.0619 - val_accuracy: 0.9600\n",
      "Epoch 411/1000\n",
      "100/100 [==============================] - 0s 229us/sample - loss: 0.0689 - accuracy: 0.9700 - val_loss: 0.0244 - val_accuracy: 1.0000\n",
      "Epoch 412/1000\n",
      "100/100 [==============================] - 0s 209us/sample - loss: 0.0685 - accuracy: 0.9600 - val_loss: 0.0380 - val_accuracy: 1.0000\n",
      "Epoch 413/1000\n",
      "100/100 [==============================] - 0s 209us/sample - loss: 0.0940 - accuracy: 0.9600 - val_loss: 0.0547 - val_accuracy: 0.9600\n",
      "Epoch 414/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.1066 - accuracy: 0.9500 - val_loss: 0.0173 - val_accuracy: 1.0000\n",
      "Epoch 415/1000\n",
      "100/100 [==============================] - 0s 199us/sample - loss: 0.0916 - accuracy: 0.9400 - val_loss: 0.0646 - val_accuracy: 0.9600\n",
      "Epoch 416/1000\n",
      "100/100 [==============================] - 0s 209us/sample - loss: 0.1008 - accuracy: 0.9600 - val_loss: 0.0181 - val_accuracy: 1.0000\n",
      "Epoch 417/1000\n",
      "100/100 [==============================] - 0s 209us/sample - loss: 0.0655 - accuracy: 0.9800 - val_loss: 0.0522 - val_accuracy: 0.9600\n",
      "Epoch 418/1000\n",
      "100/100 [==============================] - 0s 249us/sample - loss: 0.0714 - accuracy: 0.9700 - val_loss: 0.0462 - val_accuracy: 0.9800\n",
      "Epoch 419/1000\n",
      "100/100 [==============================] - 0s 239us/sample - loss: 0.0651 - accuracy: 0.9700 - val_loss: 0.0590 - val_accuracy: 0.9600\n",
      "Epoch 420/1000\n",
      "100/100 [==============================] - 0s 249us/sample - loss: 0.0666 - accuracy: 0.9800 - val_loss: 0.0238 - val_accuracy: 1.0000\n",
      "Epoch 421/1000\n",
      "100/100 [==============================] - 0s 249us/sample - loss: 0.0751 - accuracy: 0.9700 - val_loss: 0.0307 - val_accuracy: 1.0000\n",
      "Epoch 422/1000\n",
      "100/100 [==============================] - 0s 199us/sample - loss: 0.0619 - accuracy: 0.9700 - val_loss: 0.0431 - val_accuracy: 0.9800\n",
      "Epoch 423/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.0725 - accuracy: 0.9700 - val_loss: 0.0188 - val_accuracy: 1.0000\n",
      "Epoch 424/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.0697 - accuracy: 0.9800 - val_loss: 0.0514 - val_accuracy: 0.9600\n",
      "Epoch 425/1000\n",
      "100/100 [==============================] - 0s 239us/sample - loss: 0.0702 - accuracy: 0.9700 - val_loss: 0.0237 - val_accuracy: 1.0000\n",
      "Epoch 426/1000\n",
      "100/100 [==============================] - 0s 209us/sample - loss: 0.0671 - accuracy: 0.9700 - val_loss: 0.0495 - val_accuracy: 0.9600\n",
      "Epoch 427/1000\n",
      "100/100 [==============================] - 0s 229us/sample - loss: 0.0752 - accuracy: 0.9600 - val_loss: 0.0236 - val_accuracy: 1.0000\n",
      "Epoch 428/1000\n",
      "100/100 [==============================] - 0s 199us/sample - loss: 0.0758 - accuracy: 0.9600 - val_loss: 0.0106 - val_accuracy: 1.0000\n",
      "Epoch 429/1000\n",
      "100/100 [==============================] - 0s 309us/sample - loss: 0.0892 - accuracy: 0.9700 - val_loss: 0.1196 - val_accuracy: 0.9400\n",
      "Epoch 430/1000\n",
      "100/100 [==============================] - 0s 189us/sample - loss: 0.0995 - accuracy: 0.9600 - val_loss: 0.0322 - val_accuracy: 1.0000\n",
      "Epoch 431/1000\n",
      "100/100 [==============================] - 0s 199us/sample - loss: 0.0618 - accuracy: 0.9800 - val_loss: 0.0275 - val_accuracy: 1.0000\n",
      "Epoch 432/1000\n",
      "100/100 [==============================] - 0s 199us/sample - loss: 0.0636 - accuracy: 0.9800 - val_loss: 0.0305 - val_accuracy: 1.0000\n",
      "Epoch 433/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.0635 - accuracy: 0.9800 - val_loss: 0.0229 - val_accuracy: 1.0000\n",
      "Epoch 434/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.0736 - accuracy: 0.9800 - val_loss: 0.0314 - val_accuracy: 1.0000\n",
      "Epoch 435/1000\n",
      "100/100 [==============================] - 0s 209us/sample - loss: 0.0653 - accuracy: 0.9600 - val_loss: 0.1137 - val_accuracy: 0.9400\n",
      "Epoch 436/1000\n",
      "100/100 [==============================] - 0s 239us/sample - loss: 0.1125 - accuracy: 0.9500 - val_loss: 0.0121 - val_accuracy: 1.0000\n",
      "Epoch 437/1000\n",
      "100/100 [==============================] - 0s 359us/sample - loss: 0.1683 - accuracy: 0.9400 - val_loss: 0.0465 - val_accuracy: 0.9800\n",
      "Epoch 438/1000\n",
      "100/100 [==============================] - 0s 190us/sample - loss: 0.1576 - accuracy: 0.9300 - val_loss: 0.1437 - val_accuracy: 0.9400\n",
      "Epoch 439/1000\n",
      "100/100 [==============================] - 0s 229us/sample - loss: 0.1207 - accuracy: 0.9700 - val_loss: 0.0201 - val_accuracy: 1.0000\n",
      "Epoch 440/1000\n",
      "100/100 [==============================] - 0s 199us/sample - loss: 0.1208 - accuracy: 0.9600 - val_loss: 0.0996 - val_accuracy: 0.9400\n",
      "Epoch 441/1000\n",
      "100/100 [==============================] - 0s 199us/sample - loss: 0.1119 - accuracy: 0.9600 - val_loss: 0.0503 - val_accuracy: 0.9600\n",
      "Epoch 442/1000\n",
      "100/100 [==============================] - 0s 269us/sample - loss: 0.0970 - accuracy: 0.9700 - val_loss: 0.0119 - val_accuracy: 1.0000\n",
      "Epoch 443/1000\n",
      "100/100 [==============================] - 0s 269us/sample - loss: 0.1036 - accuracy: 0.9500 - val_loss: 0.1110 - val_accuracy: 0.9400\n",
      "Epoch 444/1000\n",
      "100/100 [==============================] - 0s 209us/sample - loss: 0.1152 - accuracy: 0.9600 - val_loss: 0.0239 - val_accuracy: 1.0000\n",
      "Epoch 445/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.1015 - accuracy: 0.9500 - val_loss: 0.0103 - val_accuracy: 1.0000\n",
      "Epoch 446/1000\n",
      "100/100 [==============================] - 0s 229us/sample - loss: 0.0989 - accuracy: 0.9600 - val_loss: 0.1406 - val_accuracy: 0.9400\n",
      "Epoch 447/1000\n",
      "100/100 [==============================] - 0s 170us/sample - loss: 0.0925 - accuracy: 0.9600 - val_loss: 0.0110 - val_accuracy: 1.0000\n",
      "Epoch 448/1000\n",
      "100/100 [==============================] - 0s 249us/sample - loss: 0.1389 - accuracy: 0.9600 - val_loss: 0.0137 - val_accuracy: 1.0000\n",
      "Epoch 449/1000\n",
      "100/100 [==============================] - 0s 199us/sample - loss: 0.0790 - accuracy: 0.9700 - val_loss: 0.1753 - val_accuracy: 0.9200\n",
      "Epoch 450/1000\n",
      "100/100 [==============================] - 0s 259us/sample - loss: 0.1152 - accuracy: 0.9600 - val_loss: 0.0166 - val_accuracy: 1.0000\n",
      "Epoch 451/1000\n",
      "100/100 [==============================] - 0s 209us/sample - loss: 0.0755 - accuracy: 0.9700 - val_loss: 0.0577 - val_accuracy: 0.9600\n",
      "Epoch 452/1000\n",
      "100/100 [==============================] - 0s 229us/sample - loss: 0.1294 - accuracy: 0.9600 - val_loss: 0.0443 - val_accuracy: 0.9800\n",
      "Epoch 453/1000\n",
      "100/100 [==============================] - 0s 239us/sample - loss: 0.0674 - accuracy: 0.9900 - val_loss: 0.0113 - val_accuracy: 1.0000\n",
      "Epoch 454/1000\n",
      "100/100 [==============================] - 0s 239us/sample - loss: 0.0843 - accuracy: 0.9600 - val_loss: 0.0650 - val_accuracy: 0.9600\n",
      "Epoch 455/1000\n",
      "100/100 [==============================] - 0s 229us/sample - loss: 0.0690 - accuracy: 0.9700 - val_loss: 0.0162 - val_accuracy: 1.0000\n",
      "Epoch 456/1000\n",
      "100/100 [==============================] - 0s 229us/sample - loss: 0.0713 - accuracy: 0.9700 - val_loss: 0.0419 - val_accuracy: 0.9800\n",
      "Epoch 457/1000\n",
      "100/100 [==============================] - 0s 239us/sample - loss: 0.0610 - accuracy: 0.9800 - val_loss: 0.0287 - val_accuracy: 1.0000\n",
      "Epoch 458/1000\n",
      "100/100 [==============================] - 0s 199us/sample - loss: 0.0627 - accuracy: 0.9700 - val_loss: 0.0326 - val_accuracy: 1.0000\n",
      "Epoch 459/1000\n",
      "100/100 [==============================] - 0s 289us/sample - loss: 0.0600 - accuracy: 0.9800 - val_loss: 0.0389 - val_accuracy: 0.9800\n",
      "Epoch 460/1000\n",
      "100/100 [==============================] - 0s 299us/sample - loss: 0.0708 - accuracy: 0.9700 - val_loss: 0.0224 - val_accuracy: 1.0000\n",
      "Epoch 461/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.0650 - accuracy: 0.9800 - val_loss: 0.0296 - val_accuracy: 1.0000\n",
      "Epoch 462/1000\n",
      "100/100 [==============================] - 0s 229us/sample - loss: 0.0722 - accuracy: 0.9600 - val_loss: 0.0394 - val_accuracy: 0.9800\n",
      "Epoch 463/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.0555 - accuracy: 0.9800 - val_loss: 0.0129 - val_accuracy: 1.0000\n",
      "Epoch 464/1000\n",
      "100/100 [==============================] - 0s 229us/sample - loss: 0.0756 - accuracy: 0.9700 - val_loss: 0.0360 - val_accuracy: 1.0000\n",
      "Epoch 465/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.0891 - accuracy: 0.9500 - val_loss: 0.0480 - val_accuracy: 0.9800\n",
      "Epoch 466/1000\n",
      "100/100 [==============================] - 0s 229us/sample - loss: 0.1041 - accuracy: 0.9600 - val_loss: 0.0185 - val_accuracy: 1.0000\n",
      "Epoch 467/1000\n",
      "100/100 [==============================] - 0s 209us/sample - loss: 0.0867 - accuracy: 0.9600 - val_loss: 0.0364 - val_accuracy: 1.0000\n",
      "Epoch 468/1000\n",
      "100/100 [==============================] - 0s 239us/sample - loss: 0.0782 - accuracy: 0.9700 - val_loss: 0.0127 - val_accuracy: 1.0000\n",
      "Epoch 469/1000\n",
      "100/100 [==============================] - 0s 209us/sample - loss: 0.0732 - accuracy: 0.9800 - val_loss: 0.0942 - val_accuracy: 0.9400\n",
      "Epoch 470/1000\n",
      "100/100 [==============================] - 0s 229us/sample - loss: 0.0857 - accuracy: 0.9500 - val_loss: 0.0245 - val_accuracy: 1.0000\n",
      "Epoch 471/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.0650 - accuracy: 0.9800 - val_loss: 0.0175 - val_accuracy: 1.0000\n",
      "Epoch 472/1000\n",
      "100/100 [==============================] - 0s 209us/sample - loss: 0.0599 - accuracy: 0.9800 - val_loss: 0.0764 - val_accuracy: 0.9400\n",
      "Epoch 473/1000\n",
      "100/100 [==============================] - 0s 239us/sample - loss: 0.0787 - accuracy: 0.9600 - val_loss: 0.0277 - val_accuracy: 1.0000\n",
      "Epoch 474/1000\n",
      "100/100 [==============================] - 0s 209us/sample - loss: 0.0730 - accuracy: 0.9700 - val_loss: 0.0167 - val_accuracy: 1.0000\n",
      "Epoch 475/1000\n",
      "100/100 [==============================] - 0s 229us/sample - loss: 0.0591 - accuracy: 0.9800 - val_loss: 0.0642 - val_accuracy: 0.9600\n",
      "Epoch 476/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.0817 - accuracy: 0.9700 - val_loss: 0.0391 - val_accuracy: 0.9800\n",
      "Epoch 477/1000\n",
      "100/100 [==============================] - 0s 239us/sample - loss: 0.0761 - accuracy: 0.9700 - val_loss: 0.0100 - val_accuracy: 1.0000\n",
      "Epoch 478/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.0774 - accuracy: 0.9700 - val_loss: 0.0599 - val_accuracy: 0.9600\n",
      "Epoch 479/1000\n",
      "100/100 [==============================] - 0s 199us/sample - loss: 0.0815 - accuracy: 0.9600 - val_loss: 0.0423 - val_accuracy: 0.9800\n",
      "Epoch 480/1000\n",
      "100/100 [==============================] - 0s 239us/sample - loss: 0.0872 - accuracy: 0.9700 - val_loss: 0.0513 - val_accuracy: 0.9600\n",
      "Epoch 481/1000\n",
      "100/100 [==============================] - 0s 200us/sample - loss: 0.1794 - accuracy: 0.9000 - val_loss: 0.0555 - val_accuracy: 0.9600\n",
      "Epoch 482/1000\n",
      "100/100 [==============================] - 0s 209us/sample - loss: 0.0551 - accuracy: 0.9800 - val_loss: 0.0336 - val_accuracy: 1.0000\n",
      "Epoch 483/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.1867 - accuracy: 0.9500 - val_loss: 0.1003 - val_accuracy: 0.9400\n",
      "Epoch 484/1000\n",
      "100/100 [==============================] - 0s 189us/sample - loss: 0.1259 - accuracy: 0.9400 - val_loss: 0.0211 - val_accuracy: 1.0000\n",
      "Epoch 485/1000\n",
      "100/100 [==============================] - 0s 259us/sample - loss: 0.1316 - accuracy: 0.9700 - val_loss: 0.0108 - val_accuracy: 1.0000\n",
      "Epoch 486/1000\n",
      "100/100 [==============================] - 0s 189us/sample - loss: 0.0663 - accuracy: 0.9800 - val_loss: 0.2234 - val_accuracy: 0.9000\n",
      "Epoch 487/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.1570 - accuracy: 0.9200 - val_loss: 0.0135 - val_accuracy: 1.0000\n",
      "Epoch 488/1000\n",
      "100/100 [==============================] - 0s 229us/sample - loss: 0.0856 - accuracy: 0.9700 - val_loss: 0.0171 - val_accuracy: 1.0000\n",
      "Epoch 489/1000\n",
      "100/100 [==============================] - 0s 209us/sample - loss: 0.0663 - accuracy: 0.9800 - val_loss: 0.0592 - val_accuracy: 0.9600\n",
      "Epoch 490/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.0693 - accuracy: 0.9700 - val_loss: 0.0203 - val_accuracy: 1.0000\n",
      "Epoch 491/1000\n",
      "100/100 [==============================] - 0s 239us/sample - loss: 0.0845 - accuracy: 0.9700 - val_loss: 0.0253 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 492/1000\n",
      "100/100 [==============================] - 0s 250us/sample - loss: 0.0871 - accuracy: 0.9700 - val_loss: 0.0641 - val_accuracy: 0.9600\n",
      "Epoch 493/1000\n",
      "100/100 [==============================] - 0s 209us/sample - loss: 0.0864 - accuracy: 0.9600 - val_loss: 0.0272 - val_accuracy: 1.0000\n",
      "Epoch 494/1000\n",
      "100/100 [==============================] - 0s 209us/sample - loss: 0.0688 - accuracy: 0.9600 - val_loss: 0.0679 - val_accuracy: 0.9600\n",
      "Epoch 495/1000\n",
      "100/100 [==============================] - 0s 209us/sample - loss: 0.0601 - accuracy: 0.9700 - val_loss: 0.0139 - val_accuracy: 1.0000\n",
      "Epoch 496/1000\n",
      "100/100 [==============================] - 0s 239us/sample - loss: 0.0821 - accuracy: 0.9700 - val_loss: 0.0340 - val_accuracy: 1.0000\n",
      "Epoch 497/1000\n",
      "100/100 [==============================] - 0s 199us/sample - loss: 0.0760 - accuracy: 0.9600 - val_loss: 0.1002 - val_accuracy: 0.9400\n",
      "Epoch 498/1000\n",
      "100/100 [==============================] - 0s 209us/sample - loss: 0.0698 - accuracy: 0.9700 - val_loss: 0.0112 - val_accuracy: 1.0000\n",
      "Epoch 499/1000\n",
      "100/100 [==============================] - 0s 279us/sample - loss: 0.0863 - accuracy: 0.9700 - val_loss: 0.0228 - val_accuracy: 1.0000\n",
      "Epoch 500/1000\n",
      "100/100 [==============================] - 0s 249us/sample - loss: 0.0693 - accuracy: 0.9700 - val_loss: 0.0407 - val_accuracy: 0.9800\n",
      "Epoch 501/1000\n",
      "100/100 [==============================] - 0s 239us/sample - loss: 0.0838 - accuracy: 0.9700 - val_loss: 0.0213 - val_accuracy: 1.0000\n",
      "Epoch 502/1000\n",
      "100/100 [==============================] - 0s 229us/sample - loss: 0.0934 - accuracy: 0.9500 - val_loss: 0.0768 - val_accuracy: 0.9400\n",
      "Epoch 503/1000\n",
      "100/100 [==============================] - 0s 199us/sample - loss: 0.0607 - accuracy: 0.9800 - val_loss: 0.0109 - val_accuracy: 1.0000\n",
      "Epoch 504/1000\n",
      "100/100 [==============================] - 0s 229us/sample - loss: 0.0972 - accuracy: 0.9700 - val_loss: 0.0376 - val_accuracy: 0.9800\n",
      "Epoch 505/1000\n",
      "100/100 [==============================] - 0s 199us/sample - loss: 0.1053 - accuracy: 0.9500 - val_loss: 0.0166 - val_accuracy: 1.0000\n",
      "Epoch 506/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.1850 - accuracy: 0.9500 - val_loss: 0.0107 - val_accuracy: 1.0000\n",
      "Epoch 507/1000\n",
      "100/100 [==============================] - 0s 209us/sample - loss: 0.0715 - accuracy: 0.9700 - val_loss: 0.1968 - val_accuracy: 0.9200\n",
      "Epoch 508/1000\n",
      "100/100 [==============================] - 0s 189us/sample - loss: 0.1031 - accuracy: 0.9500 - val_loss: 0.0102 - val_accuracy: 1.0000\n",
      "Epoch 509/1000\n",
      "100/100 [==============================] - 0s 209us/sample - loss: 0.0839 - accuracy: 0.9700 - val_loss: 0.0344 - val_accuracy: 1.0000\n",
      "Epoch 510/1000\n",
      "100/100 [==============================] - 0s 199us/sample - loss: 0.0665 - accuracy: 0.9600 - val_loss: 0.0603 - val_accuracy: 0.9600\n",
      "Epoch 511/1000\n",
      "100/100 [==============================] - 0s 229us/sample - loss: 0.0594 - accuracy: 0.9800 - val_loss: 0.0138 - val_accuracy: 1.0000\n",
      "Epoch 512/1000\n",
      "100/100 [==============================] - 0s 209us/sample - loss: 0.0709 - accuracy: 0.9700 - val_loss: 0.0325 - val_accuracy: 1.0000\n",
      "Epoch 513/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.0775 - accuracy: 0.9700 - val_loss: 0.0357 - val_accuracy: 1.0000\n",
      "Epoch 514/1000\n",
      "100/100 [==============================] - 0s 239us/sample - loss: 0.0761 - accuracy: 0.9800 - val_loss: 0.0089 - val_accuracy: 1.0000\n",
      "Epoch 515/1000\n",
      "100/100 [==============================] - 0s 239us/sample - loss: 0.0966 - accuracy: 0.9500 - val_loss: 0.0945 - val_accuracy: 0.9400\n",
      "Epoch 516/1000\n",
      "100/100 [==============================] - 0s 269us/sample - loss: 0.1469 - accuracy: 0.9000 - val_loss: 0.0706 - val_accuracy: 0.9600\n",
      "Epoch 517/1000\n",
      "100/100 [==============================] - 0s 199us/sample - loss: 0.1267 - accuracy: 0.9400 - val_loss: 0.0094 - val_accuracy: 1.0000\n",
      "Epoch 518/1000\n",
      "100/100 [==============================] - 0s 209us/sample - loss: 0.0730 - accuracy: 0.9700 - val_loss: 0.1774 - val_accuracy: 0.9200\n",
      "Epoch 519/1000\n",
      "100/100 [==============================] - 0s 199us/sample - loss: 0.1569 - accuracy: 0.9300 - val_loss: 0.0199 - val_accuracy: 1.0000\n",
      "Epoch 520/1000\n",
      "100/100 [==============================] - 0s 229us/sample - loss: 0.0795 - accuracy: 0.9700 - val_loss: 0.0309 - val_accuracy: 1.0000\n",
      "Epoch 521/1000\n",
      "100/100 [==============================] - 0s 209us/sample - loss: 0.0957 - accuracy: 0.9500 - val_loss: 0.0416 - val_accuracy: 0.9800\n",
      "Epoch 522/1000\n",
      "100/100 [==============================] - 0s 199us/sample - loss: 0.0608 - accuracy: 0.9800 - val_loss: 0.0111 - val_accuracy: 1.0000\n",
      "Epoch 523/1000\n",
      "100/100 [==============================] - 0s 209us/sample - loss: 0.0928 - accuracy: 0.9500 - val_loss: 0.0583 - val_accuracy: 0.9600\n",
      "Epoch 524/1000\n",
      "100/100 [==============================] - 0s 239us/sample - loss: 0.1115 - accuracy: 0.9500 - val_loss: 0.0602 - val_accuracy: 0.9600\n",
      "Epoch 525/1000\n",
      "100/100 [==============================] - 0s 279us/sample - loss: 0.0930 - accuracy: 0.9600 - val_loss: 0.0129 - val_accuracy: 1.0000\n",
      "Epoch 526/1000\n",
      "100/100 [==============================] - 0s 259us/sample - loss: 0.1160 - accuracy: 0.9500 - val_loss: 0.0661 - val_accuracy: 0.9600\n",
      "Epoch 527/1000\n",
      "100/100 [==============================] - 0s 229us/sample - loss: 0.0920 - accuracy: 0.9600 - val_loss: 0.0358 - val_accuracy: 1.0000\n",
      "Epoch 528/1000\n",
      "100/100 [==============================] - 0s 239us/sample - loss: 0.1702 - accuracy: 0.9400 - val_loss: 0.0159 - val_accuracy: 1.0000\n",
      "Epoch 529/1000\n",
      "100/100 [==============================] - 0s 209us/sample - loss: 0.1272 - accuracy: 0.9400 - val_loss: 0.1340 - val_accuracy: 0.9400\n",
      "Epoch 530/1000\n",
      "100/100 [==============================] - 0s 180us/sample - loss: 0.0833 - accuracy: 0.9700 - val_loss: 0.0192 - val_accuracy: 1.0000\n",
      "Epoch 531/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.1686 - accuracy: 0.9500 - val_loss: 0.0568 - val_accuracy: 0.9600\n",
      "Epoch 532/1000\n",
      "100/100 [==============================] - 0s 229us/sample - loss: 0.1007 - accuracy: 0.9500 - val_loss: 0.0794 - val_accuracy: 0.9400\n",
      "Epoch 533/1000\n",
      "100/100 [==============================] - 0s 249us/sample - loss: 0.0629 - accuracy: 0.9700 - val_loss: 0.0108 - val_accuracy: 1.0000\n",
      "Epoch 534/1000\n",
      "100/100 [==============================] - 0s 199us/sample - loss: 0.0819 - accuracy: 0.9700 - val_loss: 0.0432 - val_accuracy: 0.9800\n",
      "Epoch 535/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.1032 - accuracy: 0.9500 - val_loss: 0.0302 - val_accuracy: 1.0000\n",
      "Epoch 536/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.0873 - accuracy: 0.9700 - val_loss: 0.0181 - val_accuracy: 1.0000\n",
      "Epoch 537/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.0713 - accuracy: 0.9700 - val_loss: 0.1491 - val_accuracy: 0.9400\n",
      "Epoch 538/1000\n",
      "100/100 [==============================] - 0s 209us/sample - loss: 0.0967 - accuracy: 0.9700 - val_loss: 0.0181 - val_accuracy: 1.0000\n",
      "Epoch 539/1000\n",
      "100/100 [==============================] - 0s 259us/sample - loss: 0.0669 - accuracy: 0.9600 - val_loss: 0.0205 - val_accuracy: 1.0000\n",
      "Epoch 540/1000\n",
      "100/100 [==============================] - 0s 249us/sample - loss: 0.0667 - accuracy: 0.9700 - val_loss: 0.0275 - val_accuracy: 1.0000\n",
      "Epoch 541/1000\n",
      "100/100 [==============================] - 0s 229us/sample - loss: 0.0610 - accuracy: 0.9800 - val_loss: 0.0538 - val_accuracy: 0.9600\n",
      "Epoch 542/1000\n",
      "100/100 [==============================] - 0s 309us/sample - loss: 0.0871 - accuracy: 0.9500 - val_loss: 0.0266 - val_accuracy: 1.0000\n",
      "Epoch 543/1000\n",
      "100/100 [==============================] - 0s 339us/sample - loss: 0.0925 - accuracy: 0.9700 - val_loss: 0.0155 - val_accuracy: 1.0000\n",
      "Epoch 544/1000\n",
      "100/100 [==============================] - 0s 339us/sample - loss: 0.0548 - accuracy: 0.9800 - val_loss: 0.0938 - val_accuracy: 0.9400\n",
      "Epoch 545/1000\n",
      "100/100 [==============================] - 0s 239us/sample - loss: 0.1165 - accuracy: 0.9500 - val_loss: 0.0504 - val_accuracy: 0.9600\n",
      "Epoch 546/1000\n",
      "100/100 [==============================] - 0s 249us/sample - loss: 0.0606 - accuracy: 0.9700 - val_loss: 0.0104 - val_accuracy: 1.0000\n",
      "Epoch 547/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.0841 - accuracy: 0.9700 - val_loss: 0.0627 - val_accuracy: 0.9600\n",
      "Epoch 548/1000\n",
      "100/100 [==============================] - 0s 239us/sample - loss: 0.0853 - accuracy: 0.9500 - val_loss: 0.0442 - val_accuracy: 0.9800\n",
      "Epoch 549/1000\n",
      "100/100 [==============================] - 0s 229us/sample - loss: 0.0807 - accuracy: 0.9600 - val_loss: 0.0183 - val_accuracy: 1.0000\n",
      "Epoch 550/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.0747 - accuracy: 0.9700 - val_loss: 0.0484 - val_accuracy: 0.9600\n",
      "Epoch 551/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1173 - accuracy: 0.93 - 0s 229us/sample - loss: 0.0967 - accuracy: 0.9500 - val_loss: 0.0114 - val_accuracy: 1.0000\n",
      "Epoch 552/1000\n",
      "100/100 [==============================] - 0s 249us/sample - loss: 0.0772 - accuracy: 0.9700 - val_loss: 0.0410 - val_accuracy: 0.9800\n",
      "Epoch 553/1000\n",
      "100/100 [==============================] - 0s 249us/sample - loss: 0.0587 - accuracy: 0.9800 - val_loss: 0.0251 - val_accuracy: 1.0000\n",
      "Epoch 554/1000\n",
      "100/100 [==============================] - 0s 309us/sample - loss: 0.0628 - accuracy: 0.9700 - val_loss: 0.0394 - val_accuracy: 0.9800\n",
      "Epoch 555/1000\n",
      "100/100 [==============================] - 0s 259us/sample - loss: 0.0596 - accuracy: 0.9700 - val_loss: 0.0443 - val_accuracy: 0.9800\n",
      "Epoch 556/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.0613 - accuracy: 0.9700 - val_loss: 0.0270 - val_accuracy: 1.0000\n",
      "Epoch 557/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.0696 - accuracy: 0.9800 - val_loss: 0.0290 - val_accuracy: 1.0000\n",
      "Epoch 558/1000\n",
      "100/100 [==============================] - 0s 269us/sample - loss: 0.0684 - accuracy: 0.9700 - val_loss: 0.0410 - val_accuracy: 0.9800\n",
      "Epoch 559/1000\n",
      "100/100 [==============================] - 0s 249us/sample - loss: 0.0589 - accuracy: 0.9800 - val_loss: 0.0204 - val_accuracy: 1.0000\n",
      "Epoch 560/1000\n",
      "100/100 [==============================] - 0s 299us/sample - loss: 0.0741 - accuracy: 0.9700 - val_loss: 0.0188 - val_accuracy: 1.0000\n",
      "Epoch 561/1000\n",
      "100/100 [==============================] - 0s 229us/sample - loss: 0.1260 - accuracy: 0.9400 - val_loss: 0.0159 - val_accuracy: 1.0000\n",
      "Epoch 562/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.1267 - accuracy: 0.9400 - val_loss: 0.0664 - val_accuracy: 0.9600\n",
      "Epoch 563/1000\n",
      "100/100 [==============================] - 0s 259us/sample - loss: 0.0903 - accuracy: 0.9500 - val_loss: 0.0088 - val_accuracy: 1.0000\n",
      "Epoch 564/1000\n",
      "100/100 [==============================] - 0s 249us/sample - loss: 0.0985 - accuracy: 0.9500 - val_loss: 0.0961 - val_accuracy: 0.9400\n",
      "Epoch 565/1000\n",
      "100/100 [==============================] - 0s 269us/sample - loss: 0.1426 - accuracy: 0.9200 - val_loss: 0.0899 - val_accuracy: 0.9400\n",
      "Epoch 566/1000\n",
      "100/100 [==============================] - 0s 289us/sample - loss: 0.0614 - accuracy: 0.9800 - val_loss: 0.0094 - val_accuracy: 1.0000\n",
      "Epoch 567/1000\n",
      "100/100 [==============================] - 0s 259us/sample - loss: 0.1001 - accuracy: 0.9600 - val_loss: 0.0232 - val_accuracy: 1.0000\n",
      "Epoch 568/1000\n",
      "100/100 [==============================] - 0s 229us/sample - loss: 0.0794 - accuracy: 0.9500 - val_loss: 0.0214 - val_accuracy: 1.0000\n",
      "Epoch 569/1000\n",
      "100/100 [==============================] - 0s 319us/sample - loss: 0.1317 - accuracy: 0.9700 - val_loss: 0.0092 - val_accuracy: 1.0000\n",
      "Epoch 570/1000\n",
      "100/100 [==============================] - 0s 279us/sample - loss: 0.1464 - accuracy: 0.9500 - val_loss: 0.1448 - val_accuracy: 0.9400\n",
      "Epoch 571/1000\n",
      "100/100 [==============================] - 0s 229us/sample - loss: 0.0905 - accuracy: 0.9800 - val_loss: 0.0096 - val_accuracy: 1.0000\n",
      "Epoch 572/1000\n",
      "100/100 [==============================] - 0s 229us/sample - loss: 0.0844 - accuracy: 0.9500 - val_loss: 0.0441 - val_accuracy: 0.9800\n",
      "Epoch 573/1000\n",
      "100/100 [==============================] - 0s 229us/sample - loss: 0.0612 - accuracy: 0.9700 - val_loss: 0.0263 - val_accuracy: 1.0000\n",
      "Epoch 574/1000\n",
      "100/100 [==============================] - 0s 509us/sample - loss: 0.0657 - accuracy: 0.9700 - val_loss: 0.0255 - val_accuracy: 1.0000\n",
      "Epoch 575/1000\n",
      "100/100 [==============================] - 0s 299us/sample - loss: 0.0613 - accuracy: 0.9800 - val_loss: 0.0334 - val_accuracy: 1.0000\n",
      "Epoch 576/1000\n",
      "100/100 [==============================] - 0s 209us/sample - loss: 0.0634 - accuracy: 0.9800 - val_loss: 0.0293 - val_accuracy: 1.0000\n",
      "Epoch 577/1000\n",
      "100/100 [==============================] - 0s 259us/sample - loss: 0.0585 - accuracy: 0.9800 - val_loss: 0.0441 - val_accuracy: 0.9800\n",
      "Epoch 578/1000\n",
      "100/100 [==============================] - 0s 229us/sample - loss: 0.0606 - accuracy: 0.9800 - val_loss: 0.0240 - val_accuracy: 1.0000\n",
      "Epoch 579/1000\n",
      "100/100 [==============================] - 0s 359us/sample - loss: 0.0591 - accuracy: 0.9800 - val_loss: 0.0145 - val_accuracy: 1.0000\n",
      "Epoch 580/1000\n",
      "100/100 [==============================] - 0s 259us/sample - loss: 0.0730 - accuracy: 0.9700 - val_loss: 0.0371 - val_accuracy: 0.9800\n",
      "Epoch 581/1000\n",
      "100/100 [==============================] - 0s 239us/sample - loss: 0.0601 - accuracy: 0.9800 - val_loss: 0.0345 - val_accuracy: 1.0000\n",
      "Epoch 582/1000\n",
      "100/100 [==============================] - 0s 220us/sample - loss: 0.0640 - accuracy: 0.9800 - val_loss: 0.0214 - val_accuracy: 1.0000\n",
      "Epoch 583/1000\n",
      "100/100 [==============================] - 0s 269us/sample - loss: 0.0619 - accuracy: 0.9700 - val_loss: 0.0410 - val_accuracy: 0.9800\n",
      "Epoch 584/1000\n",
      "100/100 [==============================] - 0s 259us/sample - loss: 0.0617 - accuracy: 0.9700 - val_loss: 0.0376 - val_accuracy: 0.9800\n",
      "Epoch 585/1000\n",
      "100/100 [==============================] - 0s 209us/sample - loss: 0.0603 - accuracy: 0.9700 - val_loss: 0.0140 - val_accuracy: 1.0000\n",
      "Epoch 586/1000\n",
      "100/100 [==============================] - 0s 239us/sample - loss: 0.0812 - accuracy: 0.9700 - val_loss: 0.1026 - val_accuracy: 0.9400\n",
      "Epoch 587/1000\n",
      "100/100 [==============================] - 0s 229us/sample - loss: 0.2998 - accuracy: 0.8900 - val_loss: 0.0472 - val_accuracy: 0.9600\n",
      "Epoch 588/1000\n",
      "100/100 [==============================] - 0s 249us/sample - loss: 0.0772 - accuracy: 0.9700 - val_loss: 0.0127 - val_accuracy: 1.0000\n",
      "Epoch 589/1000\n",
      "100/100 [==============================] - 0s 229us/sample - loss: 0.1188 - accuracy: 0.9600 - val_loss: 0.1527 - val_accuracy: 0.9200\n",
      "Epoch 590/1000\n",
      "100/100 [==============================] - 0s 299us/sample - loss: 0.1242 - accuracy: 0.9600 - val_loss: 0.0146 - val_accuracy: 1.0000\n",
      "Epoch 591/1000\n",
      "100/100 [==============================] - 0s 319us/sample - loss: 0.1252 - accuracy: 0.9500 - val_loss: 0.0149 - val_accuracy: 1.0000\n",
      "Epoch 592/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.1284 - accuracy: 0.9500 - val_loss: 0.1708 - val_accuracy: 0.9200\n",
      "Epoch 593/1000\n",
      "100/100 [==============================] - 0s 409us/sample - loss: 0.1015 - accuracy: 0.9600 - val_loss: 0.0095 - val_accuracy: 1.0000\n",
      "Epoch 594/1000\n",
      "100/100 [==============================] - 0s 349us/sample - loss: 0.1999 - accuracy: 0.9400 - val_loss: 0.0284 - val_accuracy: 1.0000\n",
      "Epoch 595/1000\n",
      "100/100 [==============================] - 0s 229us/sample - loss: 0.1578 - accuracy: 0.9600 - val_loss: 0.1000 - val_accuracy: 0.9400\n",
      "Epoch 596/1000\n",
      "100/100 [==============================] - 0s 279us/sample - loss: 0.1121 - accuracy: 0.9600 - val_loss: 0.0129 - val_accuracy: 1.0000\n",
      "Epoch 597/1000\n",
      "100/100 [==============================] - 0s 259us/sample - loss: 0.0992 - accuracy: 0.9800 - val_loss: 0.1186 - val_accuracy: 0.9400\n",
      "Epoch 598/1000\n",
      "100/100 [==============================] - 0s 239us/sample - loss: 0.2025 - accuracy: 0.8900 - val_loss: 0.0114 - val_accuracy: 1.0000\n",
      "Epoch 599/1000\n",
      "100/100 [==============================] - 0s 259us/sample - loss: 0.2140 - accuracy: 0.9300 - val_loss: 0.0278 - val_accuracy: 1.0000\n",
      "Epoch 600/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s 219us/sample - loss: 0.1452 - accuracy: 0.9400 - val_loss: 0.1662 - val_accuracy: 0.9200\n",
      "Epoch 601/1000\n",
      "100/100 [==============================] - 0s 279us/sample - loss: 0.1688 - accuracy: 0.9200 - val_loss: 0.0412 - val_accuracy: 0.9800\n",
      "Epoch 602/1000\n",
      "100/100 [==============================] - 0s 239us/sample - loss: 0.0754 - accuracy: 0.9800 - val_loss: 0.0165 - val_accuracy: 1.0000\n",
      "Epoch 603/1000\n",
      "100/100 [==============================] - 0s 269us/sample - loss: 0.1612 - accuracy: 0.9500 - val_loss: 0.0833 - val_accuracy: 0.9400\n",
      "Epoch 604/1000\n",
      "100/100 [==============================] - 0s 229us/sample - loss: 0.0867 - accuracy: 0.9600 - val_loss: 0.0451 - val_accuracy: 0.9800\n",
      "Epoch 605/1000\n",
      "100/100 [==============================] - 0s 279us/sample - loss: 0.0993 - accuracy: 0.9600 - val_loss: 0.0091 - val_accuracy: 1.0000\n",
      "Epoch 606/1000\n",
      "100/100 [==============================] - 0s 259us/sample - loss: 0.0906 - accuracy: 0.9500 - val_loss: 0.1067 - val_accuracy: 0.9400\n",
      "Epoch 607/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.0866 - accuracy: 0.9600 - val_loss: 0.0252 - val_accuracy: 1.0000\n",
      "Epoch 608/1000\n",
      "100/100 [==============================] - 0s 359us/sample - loss: 0.0615 - accuracy: 0.9800 - val_loss: 0.0606 - val_accuracy: 0.9600\n",
      "Epoch 609/1000\n",
      "100/100 [==============================] - 0s 249us/sample - loss: 0.0885 - accuracy: 0.9600 - val_loss: 0.0372 - val_accuracy: 0.9800\n",
      "Epoch 610/1000\n",
      "100/100 [==============================] - 0s 249us/sample - loss: 0.0969 - accuracy: 0.9600 - val_loss: 0.0135 - val_accuracy: 1.0000\n",
      "Epoch 611/1000\n",
      "100/100 [==============================] - 0s 239us/sample - loss: 0.0664 - accuracy: 0.9800 - val_loss: 0.1108 - val_accuracy: 0.9400\n",
      "Epoch 612/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.0958 - accuracy: 0.9600 - val_loss: 0.0358 - val_accuracy: 1.0000\n",
      "Epoch 613/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.0620 - accuracy: 0.9800 - val_loss: 0.0194 - val_accuracy: 1.0000\n",
      "Epoch 614/1000\n",
      "100/100 [==============================] - 0s 229us/sample - loss: 0.1010 - accuracy: 0.9700 - val_loss: 0.0147 - val_accuracy: 1.0000\n",
      "Epoch 615/1000\n",
      "100/100 [==============================] - 0s 269us/sample - loss: 0.0940 - accuracy: 0.9500 - val_loss: 0.0626 - val_accuracy: 0.9600\n",
      "Epoch 616/1000\n",
      "100/100 [==============================] - 0s 379us/sample - loss: 0.0792 - accuracy: 0.9700 - val_loss: 0.0098 - val_accuracy: 1.0000\n",
      "Epoch 617/1000\n",
      "100/100 [==============================] - 0s 259us/sample - loss: 0.0925 - accuracy: 0.9600 - val_loss: 0.0728 - val_accuracy: 0.9600\n",
      "Epoch 618/1000\n",
      "100/100 [==============================] - 0s 239us/sample - loss: 0.0700 - accuracy: 0.9700 - val_loss: 0.0326 - val_accuracy: 1.0000\n",
      "Epoch 619/1000\n",
      "100/100 [==============================] - 0s 269us/sample - loss: 0.0631 - accuracy: 0.9700 - val_loss: 0.0170 - val_accuracy: 1.0000\n",
      "Epoch 620/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.0665 - accuracy: 0.9800 - val_loss: 0.0354 - val_accuracy: 1.0000\n",
      "Epoch 621/1000\n",
      "100/100 [==============================] - 0s 249us/sample - loss: 0.0599 - accuracy: 0.9700 - val_loss: 0.0562 - val_accuracy: 0.9600\n",
      "Epoch 622/1000\n",
      "100/100 [==============================] - 0s 239us/sample - loss: 0.0740 - accuracy: 0.9700 - val_loss: 0.0270 - val_accuracy: 1.0000\n",
      "Epoch 623/1000\n",
      "100/100 [==============================] - 0s 259us/sample - loss: 0.0695 - accuracy: 0.9600 - val_loss: 0.0139 - val_accuracy: 1.0000\n",
      "Epoch 624/1000\n",
      "100/100 [==============================] - 0s 269us/sample - loss: 0.0710 - accuracy: 0.9700 - val_loss: 0.0591 - val_accuracy: 0.9600\n",
      "Epoch 625/1000\n",
      "100/100 [==============================] - 0s 259us/sample - loss: 0.0687 - accuracy: 0.9800 - val_loss: 0.0234 - val_accuracy: 1.0000\n",
      "Epoch 626/1000\n",
      "100/100 [==============================] - 0s 239us/sample - loss: 0.0621 - accuracy: 0.9700 - val_loss: 0.0375 - val_accuracy: 0.9800\n",
      "Epoch 627/1000\n",
      "100/100 [==============================] - 0s 289us/sample - loss: 0.0624 - accuracy: 0.9700 - val_loss: 0.0192 - val_accuracy: 1.0000\n",
      "Epoch 628/1000\n",
      "100/100 [==============================] - 0s 249us/sample - loss: 0.0824 - accuracy: 0.9800 - val_loss: 0.0126 - val_accuracy: 1.0000\n",
      "Epoch 629/1000\n",
      "100/100 [==============================] - 0s 319us/sample - loss: 0.0742 - accuracy: 0.9600 - val_loss: 0.0500 - val_accuracy: 0.9600\n",
      "Epoch 630/1000\n",
      "100/100 [==============================] - 0s 339us/sample - loss: 0.0780 - accuracy: 0.9500 - val_loss: 0.0231 - val_accuracy: 1.0000\n",
      "Epoch 631/1000\n",
      "100/100 [==============================] - 0s 289us/sample - loss: 0.0613 - accuracy: 0.9800 - val_loss: 0.1126 - val_accuracy: 0.9400\n",
      "Epoch 632/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.0943 - accuracy: 0.9600 - val_loss: 0.0160 - val_accuracy: 1.0000\n",
      "Epoch 633/1000\n",
      "100/100 [==============================] - 0s 229us/sample - loss: 0.0820 - accuracy: 0.9700 - val_loss: 0.0138 - val_accuracy: 1.0000\n",
      "Epoch 634/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.0659 - accuracy: 0.9800 - val_loss: 0.0568 - val_accuracy: 0.9600\n",
      "Epoch 635/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.0645 - accuracy: 0.9700 - val_loss: 0.0315 - val_accuracy: 1.0000\n",
      "Epoch 636/1000\n",
      "100/100 [==============================] - 0s 618us/sample - loss: 0.0651 - accuracy: 0.9800 - val_loss: 0.0261 - val_accuracy: 1.0000\n",
      "Epoch 637/1000\n",
      "100/100 [==============================] - 0s 239us/sample - loss: 0.0591 - accuracy: 0.9800 - val_loss: 0.0252 - val_accuracy: 1.0000\n",
      "Epoch 638/1000\n",
      "100/100 [==============================] - 0s 239us/sample - loss: 0.0735 - accuracy: 0.9700 - val_loss: 0.0325 - val_accuracy: 1.0000\n",
      "Epoch 639/1000\n",
      "100/100 [==============================] - 0s 229us/sample - loss: 0.0630 - accuracy: 0.9700 - val_loss: 0.0291 - val_accuracy: 1.0000\n",
      "Epoch 640/1000\n",
      "100/100 [==============================] - 0s 229us/sample - loss: 0.0623 - accuracy: 0.9700 - val_loss: 0.0458 - val_accuracy: 0.9600\n",
      "Epoch 641/1000\n",
      "100/100 [==============================] - 0s 239us/sample - loss: 0.0684 - accuracy: 0.9700 - val_loss: 0.0115 - val_accuracy: 1.0000\n",
      "Epoch 642/1000\n",
      "100/100 [==============================] - 0s 269us/sample - loss: 0.2517 - accuracy: 0.9200 - val_loss: 0.0260 - val_accuracy: 1.0000\n",
      "Epoch 643/1000\n",
      "100/100 [==============================] - 0s 539us/sample - loss: 0.2823 - accuracy: 0.8700 - val_loss: 0.2595 - val_accuracy: 0.8800\n",
      "Epoch 644/1000\n",
      "100/100 [==============================] - 0s 239us/sample - loss: 0.0962 - accuracy: 0.9400 - val_loss: 0.0178 - val_accuracy: 1.0000\n",
      "Epoch 645/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.3360 - accuracy: 0.9100 - val_loss: 0.0367 - val_accuracy: 0.9800\n",
      "Epoch 646/1000\n",
      "100/100 [==============================] - 0s 249us/sample - loss: 0.1759 - accuracy: 0.9200 - val_loss: 0.1085 - val_accuracy: 0.9400\n",
      "Epoch 647/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.0937 - accuracy: 0.9700 - val_loss: 0.0135 - val_accuracy: 1.0000\n",
      "Epoch 648/1000\n",
      "100/100 [==============================] - 0s 239us/sample - loss: 0.0698 - accuracy: 0.9800 - val_loss: 0.0906 - val_accuracy: 0.9400\n",
      "Epoch 649/1000\n",
      "100/100 [==============================] - 0s 229us/sample - loss: 0.0688 - accuracy: 0.9700 - val_loss: 0.0120 - val_accuracy: 1.0000\n",
      "Epoch 650/1000\n",
      "100/100 [==============================] - 0s 259us/sample - loss: 0.0979 - accuracy: 0.9600 - val_loss: 0.0127 - val_accuracy: 1.0000\n",
      "Epoch 651/1000\n",
      "100/100 [==============================] - 0s 259us/sample - loss: 0.0599 - accuracy: 0.9800 - val_loss: 0.0647 - val_accuracy: 0.9600\n",
      "Epoch 652/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.0678 - accuracy: 0.9700 - val_loss: 0.0270 - val_accuracy: 1.0000\n",
      "Epoch 653/1000\n",
      "100/100 [==============================] - 0s 259us/sample - loss: 0.0625 - accuracy: 0.9800 - val_loss: 0.0208 - val_accuracy: 1.0000\n",
      "Epoch 654/1000\n",
      "100/100 [==============================] - 0s 229us/sample - loss: 0.0606 - accuracy: 0.9800 - val_loss: 0.0652 - val_accuracy: 0.9600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 655/1000\n",
      "100/100 [==============================] - 0s 229us/sample - loss: 0.0967 - accuracy: 0.9600 - val_loss: 0.0603 - val_accuracy: 0.9600\n",
      "Epoch 656/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0680 - accuracy: 0.96 - 0s 209us/sample - loss: 0.0513 - accuracy: 0.9800 - val_loss: 0.0087 - val_accuracy: 1.0000\n",
      "Epoch 657/1000\n",
      "100/100 [==============================] - 0s 249us/sample - loss: 0.1154 - accuracy: 0.9600 - val_loss: 0.0175 - val_accuracy: 1.0000\n",
      "Epoch 658/1000\n",
      "100/100 [==============================] - 0s 239us/sample - loss: 0.0564 - accuracy: 0.9800 - val_loss: 0.0632 - val_accuracy: 0.9600\n",
      "Epoch 659/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.0634 - accuracy: 0.9700 - val_loss: 0.0163 - val_accuracy: 1.0000\n",
      "Epoch 660/1000\n",
      "100/100 [==============================] - 0s 249us/sample - loss: 0.0747 - accuracy: 0.9700 - val_loss: 0.0140 - val_accuracy: 1.0000\n",
      "Epoch 661/1000\n",
      "100/100 [==============================] - 0s 209us/sample - loss: 0.0825 - accuracy: 0.9700 - val_loss: 0.0522 - val_accuracy: 0.9600\n",
      "Epoch 662/1000\n",
      "100/100 [==============================] - 0s 239us/sample - loss: 0.0682 - accuracy: 0.9700 - val_loss: 0.0271 - val_accuracy: 1.0000\n",
      "Epoch 663/1000\n",
      "100/100 [==============================] - 0s 259us/sample - loss: 0.0662 - accuracy: 0.9800 - val_loss: 0.0397 - val_accuracy: 0.9800\n",
      "Epoch 664/1000\n",
      "100/100 [==============================] - 0s 229us/sample - loss: 0.0832 - accuracy: 0.9700 - val_loss: 0.0252 - val_accuracy: 1.0000\n",
      "Epoch 665/1000\n",
      "100/100 [==============================] - 0s 209us/sample - loss: 0.0712 - accuracy: 0.9600 - val_loss: 0.1031 - val_accuracy: 0.9400\n",
      "Epoch 666/1000\n",
      "100/100 [==============================] - 0s 209us/sample - loss: 0.0763 - accuracy: 0.9600 - val_loss: 0.0122 - val_accuracy: 1.0000\n",
      "Epoch 667/1000\n",
      "100/100 [==============================] - 0s 189us/sample - loss: 0.0877 - accuracy: 0.9700 - val_loss: 0.0242 - val_accuracy: 1.0000\n",
      "Epoch 668/1000\n",
      "100/100 [==============================] - 0s 180us/sample - loss: 0.0637 - accuracy: 0.9800 - val_loss: 0.1107 - val_accuracy: 0.9400\n",
      "Epoch 669/1000\n",
      "100/100 [==============================] - 0s 199us/sample - loss: 0.0759 - accuracy: 0.9700 - val_loss: 0.0110 - val_accuracy: 1.0000\n",
      "Epoch 670/1000\n",
      "100/100 [==============================] - 0s 229us/sample - loss: 0.1023 - accuracy: 0.9500 - val_loss: 0.0147 - val_accuracy: 1.0000\n",
      "Epoch 671/1000\n",
      "100/100 [==============================] - 0s 229us/sample - loss: 0.0951 - accuracy: 0.9500 - val_loss: 0.0475 - val_accuracy: 0.9600\n",
      "Epoch 672/1000\n",
      "100/100 [==============================] - 0s 469us/sample - loss: 0.0599 - accuracy: 0.9800 - val_loss: 0.0078 - val_accuracy: 1.0000\n",
      "Epoch 673/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.0924 - accuracy: 0.9700 - val_loss: 0.0564 - val_accuracy: 0.9600\n",
      "Epoch 674/1000\n",
      "100/100 [==============================] - 0s 229us/sample - loss: 0.0944 - accuracy: 0.9500 - val_loss: 0.0234 - val_accuracy: 1.0000\n",
      "Epoch 675/1000\n",
      "100/100 [==============================] - 0s 239us/sample - loss: 0.0540 - accuracy: 0.9900 - val_loss: 0.0086 - val_accuracy: 1.0000\n",
      "Epoch 676/1000\n",
      "100/100 [==============================] - 0s 189us/sample - loss: 0.1596 - accuracy: 0.9500 - val_loss: 0.0422 - val_accuracy: 0.9800\n",
      "Epoch 677/1000\n",
      "100/100 [==============================] - 0s 200us/sample - loss: 0.1179 - accuracy: 0.9600 - val_loss: 0.0633 - val_accuracy: 0.9600\n",
      "Epoch 678/1000\n",
      "100/100 [==============================] - 0s 229us/sample - loss: 0.0559 - accuracy: 0.9800 - val_loss: 0.0132 - val_accuracy: 1.0000\n",
      "Epoch 679/1000\n",
      "100/100 [==============================] - 0s 229us/sample - loss: 0.0722 - accuracy: 0.9800 - val_loss: 0.0423 - val_accuracy: 0.9800\n",
      "Epoch 680/1000\n",
      "100/100 [==============================] - 0s 209us/sample - loss: 0.0677 - accuracy: 0.9800 - val_loss: 0.0185 - val_accuracy: 1.0000\n",
      "Epoch 681/1000\n",
      "100/100 [==============================] - 0s 239us/sample - loss: 0.0675 - accuracy: 0.9800 - val_loss: 0.0412 - val_accuracy: 0.9800\n",
      "Epoch 682/1000\n",
      "100/100 [==============================] - 0s 249us/sample - loss: 0.0586 - accuracy: 0.9800 - val_loss: 0.0321 - val_accuracy: 1.0000\n",
      "Epoch 683/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.0648 - accuracy: 0.9700 - val_loss: 0.0186 - val_accuracy: 1.0000\n",
      "Epoch 684/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.0881 - accuracy: 0.9600 - val_loss: 0.0334 - val_accuracy: 1.0000\n",
      "Epoch 685/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.0756 - accuracy: 0.9600 - val_loss: 0.0499 - val_accuracy: 0.9600\n",
      "Epoch 686/1000\n",
      "100/100 [==============================] - 0s 229us/sample - loss: 0.0738 - accuracy: 0.9600 - val_loss: 0.0224 - val_accuracy: 1.0000\n",
      "Epoch 687/1000\n",
      "100/100 [==============================] - 0s 229us/sample - loss: 0.0566 - accuracy: 0.9800 - val_loss: 0.0777 - val_accuracy: 0.9400\n",
      "Epoch 688/1000\n",
      "100/100 [==============================] - 0s 249us/sample - loss: 0.0743 - accuracy: 0.9700 - val_loss: 0.0229 - val_accuracy: 1.0000\n",
      "Epoch 689/1000\n",
      "100/100 [==============================] - 0s 209us/sample - loss: 0.0752 - accuracy: 0.9700 - val_loss: 0.0239 - val_accuracy: 1.0000\n",
      "Epoch 690/1000\n",
      "100/100 [==============================] - 0s 269us/sample - loss: 0.0810 - accuracy: 0.9600 - val_loss: 0.1070 - val_accuracy: 0.9400\n",
      "Epoch 691/1000\n",
      "100/100 [==============================] - 0s 259us/sample - loss: 0.0736 - accuracy: 0.9600 - val_loss: 0.0077 - val_accuracy: 1.0000\n",
      "Epoch 692/1000\n",
      "100/100 [==============================] - 0s 209us/sample - loss: 0.1240 - accuracy: 0.9500 - val_loss: 0.0238 - val_accuracy: 1.0000\n",
      "Epoch 693/1000\n",
      "100/100 [==============================] - 0s 249us/sample - loss: 0.0765 - accuracy: 0.9800 - val_loss: 0.1293 - val_accuracy: 0.9400\n",
      "Epoch 694/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.0901 - accuracy: 0.9700 - val_loss: 0.0129 - val_accuracy: 1.0000\n",
      "Epoch 695/1000\n",
      "100/100 [==============================] - 0s 229us/sample - loss: 0.0708 - accuracy: 0.9700 - val_loss: 0.0193 - val_accuracy: 1.0000\n",
      "Epoch 696/1000\n",
      "100/100 [==============================] - 0s 209us/sample - loss: 0.0606 - accuracy: 0.9700 - val_loss: 0.0443 - val_accuracy: 0.9800\n",
      "Epoch 697/1000\n",
      "100/100 [==============================] - 0s 229us/sample - loss: 0.0656 - accuracy: 0.9700 - val_loss: 0.0349 - val_accuracy: 0.9800\n",
      "Epoch 698/1000\n",
      "100/100 [==============================] - 0s 229us/sample - loss: 0.0544 - accuracy: 0.9800 - val_loss: 0.0116 - val_accuracy: 1.0000\n",
      "Epoch 699/1000\n",
      "100/100 [==============================] - 0s 269us/sample - loss: 0.0776 - accuracy: 0.9700 - val_loss: 0.0345 - val_accuracy: 0.9800\n",
      "Epoch 700/1000\n",
      "100/100 [==============================] - 0s 209us/sample - loss: 0.0617 - accuracy: 0.9700 - val_loss: 0.0657 - val_accuracy: 0.9600\n",
      "Epoch 701/1000\n",
      "100/100 [==============================] - 0s 239us/sample - loss: 0.0746 - accuracy: 0.9700 - val_loss: 0.0221 - val_accuracy: 1.0000\n",
      "Epoch 702/1000\n",
      "100/100 [==============================] - 0s 229us/sample - loss: 0.0969 - accuracy: 0.9700 - val_loss: 0.0101 - val_accuracy: 1.0000\n",
      "Epoch 703/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.0668 - accuracy: 0.9700 - val_loss: 0.1191 - val_accuracy: 0.9400\n",
      "Epoch 704/1000\n",
      "100/100 [==============================] - 0s 239us/sample - loss: 0.0829 - accuracy: 0.9700 - val_loss: 0.0153 - val_accuracy: 1.0000\n",
      "Epoch 705/1000\n",
      "100/100 [==============================] - 0s 229us/sample - loss: 0.0781 - accuracy: 0.9700 - val_loss: 0.0188 - val_accuracy: 1.0000\n",
      "Epoch 706/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.0533 - accuracy: 0.9800 - val_loss: 0.0876 - val_accuracy: 0.9400\n",
      "Epoch 707/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.1105 - accuracy: 0.9600 - val_loss: 0.0397 - val_accuracy: 0.9800\n",
      "Epoch 708/1000\n",
      "100/100 [==============================] - 0s 199us/sample - loss: 0.1034 - accuracy: 0.9700 - val_loss: 0.0073 - val_accuracy: 1.0000\n",
      "Epoch 709/1000\n",
      "100/100 [==============================] - 0s 199us/sample - loss: 0.0848 - accuracy: 0.9600 - val_loss: 0.0721 - val_accuracy: 0.9600\n",
      "Epoch 710/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.0761 - accuracy: 0.9600 - val_loss: 0.0361 - val_accuracy: 0.9800\n",
      "Epoch 711/1000\n",
      "100/100 [==============================] - 0s 229us/sample - loss: 0.0586 - accuracy: 0.9800 - val_loss: 0.0221 - val_accuracy: 1.0000\n",
      "Epoch 712/1000\n",
      "100/100 [==============================] - 0s 209us/sample - loss: 0.0651 - accuracy: 0.9800 - val_loss: 0.0241 - val_accuracy: 1.0000\n",
      "Epoch 713/1000\n",
      "100/100 [==============================] - 0s 199us/sample - loss: 0.0856 - accuracy: 0.9800 - val_loss: 0.0173 - val_accuracy: 1.0000\n",
      "Epoch 714/1000\n",
      "100/100 [==============================] - 0s 209us/sample - loss: 0.0594 - accuracy: 0.9800 - val_loss: 0.0529 - val_accuracy: 0.9600\n",
      "Epoch 715/1000\n",
      "100/100 [==============================] - 0s 170us/sample - loss: 0.0593 - accuracy: 0.9800 - val_loss: 0.0209 - val_accuracy: 1.0000\n",
      "Epoch 716/1000\n",
      "100/100 [==============================] - 0s 239us/sample - loss: 0.0735 - accuracy: 0.9600 - val_loss: 0.0295 - val_accuracy: 1.0000\n",
      "Epoch 717/1000\n",
      "100/100 [==============================] - 0s 209us/sample - loss: 0.0588 - accuracy: 0.9800 - val_loss: 0.0592 - val_accuracy: 0.9600\n",
      "Epoch 718/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.0710 - accuracy: 0.9700 - val_loss: 0.0329 - val_accuracy: 1.0000\n",
      "Epoch 719/1000\n",
      "100/100 [==============================] - 0s 199us/sample - loss: 0.0597 - accuracy: 0.9700 - val_loss: 0.0431 - val_accuracy: 0.9800\n",
      "Epoch 720/1000\n",
      "100/100 [==============================] - 0s 199us/sample - loss: 0.0587 - accuracy: 0.9800 - val_loss: 0.0216 - val_accuracy: 1.0000\n",
      "Epoch 721/1000\n",
      "100/100 [==============================] - 0s 259us/sample - loss: 0.0698 - accuracy: 0.9800 - val_loss: 0.0249 - val_accuracy: 1.0000\n",
      "Epoch 722/1000\n",
      "100/100 [==============================] - 0s 289us/sample - loss: 0.0595 - accuracy: 0.9700 - val_loss: 0.0561 - val_accuracy: 0.9600\n",
      "Epoch 723/1000\n",
      "100/100 [==============================] - 0s 199us/sample - loss: 0.0618 - accuracy: 0.9700 - val_loss: 0.0219 - val_accuracy: 1.0000\n",
      "Epoch 724/1000\n",
      "100/100 [==============================] - 0s 200us/sample - loss: 0.0645 - accuracy: 0.9800 - val_loss: 0.0131 - val_accuracy: 1.0000\n",
      "Epoch 725/1000\n",
      "100/100 [==============================] - 0s 199us/sample - loss: 0.0693 - accuracy: 0.9800 - val_loss: 0.0350 - val_accuracy: 0.9800\n",
      "Epoch 726/1000\n",
      "100/100 [==============================] - 0s 199us/sample - loss: 0.0611 - accuracy: 0.9800 - val_loss: 0.0245 - val_accuracy: 1.0000\n",
      "Epoch 727/1000\n",
      "100/100 [==============================] - 0s 199us/sample - loss: 0.0615 - accuracy: 0.9800 - val_loss: 0.0460 - val_accuracy: 0.9600\n",
      "Epoch 728/1000\n",
      "100/100 [==============================] - 0s 209us/sample - loss: 0.0721 - accuracy: 0.9700 - val_loss: 0.0308 - val_accuracy: 1.0000\n",
      "Epoch 729/1000\n",
      "100/100 [==============================] - 0s 180us/sample - loss: 0.0705 - accuracy: 0.9800 - val_loss: 0.0305 - val_accuracy: 1.0000\n",
      "Epoch 730/1000\n",
      "100/100 [==============================] - 0s 199us/sample - loss: 0.0961 - accuracy: 0.9600 - val_loss: 0.0099 - val_accuracy: 1.0000\n",
      "Epoch 731/1000\n",
      "100/100 [==============================] - 0s 229us/sample - loss: 0.0893 - accuracy: 0.9600 - val_loss: 0.0596 - val_accuracy: 0.9600\n",
      "Epoch 732/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.0648 - accuracy: 0.9700 - val_loss: 0.0152 - val_accuracy: 1.0000\n",
      "Epoch 733/1000\n",
      "100/100 [==============================] - 0s 209us/sample - loss: 0.0971 - accuracy: 0.9600 - val_loss: 0.0171 - val_accuracy: 1.0000\n",
      "Epoch 734/1000\n",
      "100/100 [==============================] - 0s 199us/sample - loss: 0.0563 - accuracy: 0.9800 - val_loss: 0.0863 - val_accuracy: 0.9400\n",
      "Epoch 735/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.1225 - accuracy: 0.9400 - val_loss: 0.0166 - val_accuracy: 1.0000\n",
      "Epoch 736/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.1498 - accuracy: 0.9600 - val_loss: 0.0135 - val_accuracy: 1.0000\n",
      "Epoch 737/1000\n",
      "100/100 [==============================] - 0s 209us/sample - loss: 0.1262 - accuracy: 0.9400 - val_loss: 0.1784 - val_accuracy: 0.9200\n",
      "Epoch 738/1000\n",
      "100/100 [==============================] - 0s 209us/sample - loss: 0.1854 - accuracy: 0.9100 - val_loss: 0.0236 - val_accuracy: 1.0000\n",
      "Epoch 739/1000\n",
      "100/100 [==============================] - 0s 199us/sample - loss: 0.1417 - accuracy: 0.9500 - val_loss: 0.0110 - val_accuracy: 1.0000\n",
      "Epoch 740/1000\n",
      "100/100 [==============================] - 0s 199us/sample - loss: 0.1275 - accuracy: 0.9500 - val_loss: 0.1219 - val_accuracy: 0.9400\n",
      "Epoch 741/1000\n",
      "100/100 [==============================] - 0s 229us/sample - loss: 0.0765 - accuracy: 0.9700 - val_loss: 0.0142 - val_accuracy: 1.0000\n",
      "Epoch 742/1000\n",
      "100/100 [==============================] - 0s 229us/sample - loss: 0.0671 - accuracy: 0.9700 - val_loss: 0.0148 - val_accuracy: 1.0000\n",
      "Epoch 743/1000\n",
      "100/100 [==============================] - 0s 239us/sample - loss: 0.0705 - accuracy: 0.9700 - val_loss: 0.0571 - val_accuracy: 0.9600\n",
      "Epoch 744/1000\n",
      "100/100 [==============================] - 0s 229us/sample - loss: 0.0694 - accuracy: 0.9600 - val_loss: 0.0325 - val_accuracy: 1.0000\n",
      "Epoch 745/1000\n",
      "100/100 [==============================] - 0s 209us/sample - loss: 0.0581 - accuracy: 0.9800 - val_loss: 0.0173 - val_accuracy: 1.0000\n",
      "Epoch 746/1000\n",
      "100/100 [==============================] - 0s 259us/sample - loss: 0.0628 - accuracy: 0.9700 - val_loss: 0.0255 - val_accuracy: 1.0000\n",
      "Epoch 747/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.0704 - accuracy: 0.9700 - val_loss: 0.0288 - val_accuracy: 1.0000\n",
      "Epoch 748/1000\n",
      "100/100 [==============================] - 0s 229us/sample - loss: 0.0705 - accuracy: 0.9700 - val_loss: 0.0207 - val_accuracy: 1.0000\n",
      "Epoch 749/1000\n",
      "100/100 [==============================] - 0s 199us/sample - loss: 0.0620 - accuracy: 0.9800 - val_loss: 0.0651 - val_accuracy: 0.9600\n",
      "Epoch 750/1000\n",
      "100/100 [==============================] - 0s 239us/sample - loss: 0.0643 - accuracy: 0.9700 - val_loss: 0.0202 - val_accuracy: 1.0000\n",
      "Epoch 751/1000\n",
      "100/100 [==============================] - 0s 180us/sample - loss: 0.0610 - accuracy: 0.9700 - val_loss: 0.0288 - val_accuracy: 1.0000\n",
      "Epoch 752/1000\n",
      "100/100 [==============================] - 0s 209us/sample - loss: 0.0584 - accuracy: 0.9800 - val_loss: 0.0406 - val_accuracy: 0.9800\n",
      "Epoch 753/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.0676 - accuracy: 0.9700 - val_loss: 0.0340 - val_accuracy: 1.0000\n",
      "Epoch 754/1000\n",
      "100/100 [==============================] - 0s 199us/sample - loss: 0.0612 - accuracy: 0.9600 - val_loss: 0.0109 - val_accuracy: 1.0000\n",
      "Epoch 755/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.0753 - accuracy: 0.9600 - val_loss: 0.0351 - val_accuracy: 0.9800\n",
      "Epoch 756/1000\n",
      "100/100 [==============================] - 0s 239us/sample - loss: 0.0626 - accuracy: 0.9800 - val_loss: 0.0215 - val_accuracy: 1.0000\n",
      "Epoch 757/1000\n",
      "100/100 [==============================] - 0s 239us/sample - loss: 0.0722 - accuracy: 0.9600 - val_loss: 0.0274 - val_accuracy: 1.0000\n",
      "Epoch 758/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.0569 - accuracy: 0.9800 - val_loss: 0.0506 - val_accuracy: 0.9600\n",
      "Epoch 759/1000\n",
      "100/100 [==============================] - 0s 199us/sample - loss: 0.0621 - accuracy: 0.9700 - val_loss: 0.0209 - val_accuracy: 1.0000\n",
      "Epoch 760/1000\n",
      "100/100 [==============================] - 0s 229us/sample - loss: 0.0615 - accuracy: 0.9700 - val_loss: 0.0277 - val_accuracy: 1.0000\n",
      "Epoch 761/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.0591 - accuracy: 0.9800 - val_loss: 0.0458 - val_accuracy: 0.9600\n",
      "Epoch 762/1000\n",
      "100/100 [==============================] - 0s 229us/sample - loss: 0.0605 - accuracy: 0.9800 - val_loss: 0.0337 - val_accuracy: 0.9800\n",
      "Epoch 763/1000\n",
      "100/100 [==============================] - 0s 259us/sample - loss: 0.0676 - accuracy: 0.9700 - val_loss: 0.0331 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 764/1000\n",
      "100/100 [==============================] - 0s 239us/sample - loss: 0.0855 - accuracy: 0.9600 - val_loss: 0.0160 - val_accuracy: 1.0000\n",
      "Epoch 765/1000\n",
      "100/100 [==============================] - 0s 249us/sample - loss: 0.0860 - accuracy: 0.9500 - val_loss: 0.0450 - val_accuracy: 0.9600\n",
      "Epoch 766/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.0508 - accuracy: 0.9800 - val_loss: 0.0089 - val_accuracy: 1.0000\n",
      "Epoch 767/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.0819 - accuracy: 0.9700 - val_loss: 0.0123 - val_accuracy: 1.0000\n",
      "Epoch 768/1000\n",
      "100/100 [==============================] - 0s 199us/sample - loss: 0.0634 - accuracy: 0.9800 - val_loss: 0.0525 - val_accuracy: 0.9600\n",
      "Epoch 769/1000\n",
      "100/100 [==============================] - 0s 190us/sample - loss: 0.0697 - accuracy: 0.9700 - val_loss: 0.0262 - val_accuracy: 1.0000\n",
      "Epoch 770/1000\n",
      "100/100 [==============================] - 0s 289us/sample - loss: 0.0681 - accuracy: 0.9700 - val_loss: 0.0083 - val_accuracy: 1.0000\n",
      "Epoch 771/1000\n",
      "100/100 [==============================] - 0s 209us/sample - loss: 0.0849 - accuracy: 0.9700 - val_loss: 0.0450 - val_accuracy: 0.9800\n",
      "Epoch 772/1000\n",
      "100/100 [==============================] - 0s 239us/sample - loss: 0.1096 - accuracy: 0.9600 - val_loss: 0.0464 - val_accuracy: 0.9600\n",
      "Epoch 773/1000\n",
      "100/100 [==============================] - 0s 229us/sample - loss: 0.0890 - accuracy: 0.9600 - val_loss: 0.0104 - val_accuracy: 1.0000\n",
      "Epoch 774/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.0596 - accuracy: 0.9700 - val_loss: 0.0859 - val_accuracy: 0.9400\n",
      "Epoch 775/1000\n",
      "100/100 [==============================] - 0s 209us/sample - loss: 0.0779 - accuracy: 0.9700 - val_loss: 0.0265 - val_accuracy: 1.0000\n",
      "Epoch 776/1000\n",
      "100/100 [==============================] - 0s 229us/sample - loss: 0.0648 - accuracy: 0.9800 - val_loss: 0.0092 - val_accuracy: 1.0000\n",
      "Epoch 777/1000\n",
      "100/100 [==============================] - 0s 209us/sample - loss: 0.0776 - accuracy: 0.9700 - val_loss: 0.0283 - val_accuracy: 1.0000\n",
      "Epoch 778/1000\n",
      "100/100 [==============================] - 0s 229us/sample - loss: 0.0696 - accuracy: 0.9600 - val_loss: 0.0204 - val_accuracy: 1.0000\n",
      "Epoch 779/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.0575 - accuracy: 0.9800 - val_loss: 0.0659 - val_accuracy: 0.9600\n",
      "Epoch 780/1000\n",
      "100/100 [==============================] - 0s 229us/sample - loss: 0.0736 - accuracy: 0.9700 - val_loss: 0.0420 - val_accuracy: 0.9800\n",
      "Epoch 781/1000\n",
      "100/100 [==============================] - 0s 289us/sample - loss: 0.0648 - accuracy: 0.9600 - val_loss: 0.0130 - val_accuracy: 1.0000\n",
      "Epoch 782/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.0557 - accuracy: 0.9800 - val_loss: 0.0720 - val_accuracy: 0.9600\n",
      "Epoch 783/1000\n",
      "100/100 [==============================] - 0s 209us/sample - loss: 0.0710 - accuracy: 0.9600 - val_loss: 0.0271 - val_accuracy: 1.0000\n",
      "Epoch 784/1000\n",
      "100/100 [==============================] - 0s 199us/sample - loss: 0.0829 - accuracy: 0.9800 - val_loss: 0.0222 - val_accuracy: 1.0000\n",
      "Epoch 785/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.0986 - accuracy: 0.9500 - val_loss: 0.1374 - val_accuracy: 0.9400\n",
      "Epoch 786/1000\n",
      "100/100 [==============================] - 0s 519us/sample - loss: 0.0823 - accuracy: 0.9700 - val_loss: 0.0079 - val_accuracy: 1.0000\n",
      "Epoch 787/1000\n",
      "100/100 [==============================] - 0s 299us/sample - loss: 0.1385 - accuracy: 0.9500 - val_loss: 0.0360 - val_accuracy: 0.9800\n",
      "Epoch 788/1000\n",
      "100/100 [==============================] - 0s 279us/sample - loss: 0.2008 - accuracy: 0.9000 - val_loss: 0.0751 - val_accuracy: 0.9600\n",
      "Epoch 789/1000\n",
      "100/100 [==============================] - 0s 309us/sample - loss: 0.0717 - accuracy: 0.9600 - val_loss: 0.0307 - val_accuracy: 1.0000\n",
      "Epoch 790/1000\n",
      "100/100 [==============================] - 0s 389us/sample - loss: 0.2255 - accuracy: 0.9400 - val_loss: 0.0594 - val_accuracy: 0.9600\n",
      "Epoch 791/1000\n",
      "100/100 [==============================] - 0s 259us/sample - loss: 0.1095 - accuracy: 0.9700 - val_loss: 0.0980 - val_accuracy: 0.9400\n",
      "Epoch 792/1000\n",
      "100/100 [==============================] - 0s 279us/sample - loss: 0.0712 - accuracy: 0.9700 - val_loss: 0.0057 - val_accuracy: 1.0000\n",
      "Epoch 793/1000\n",
      "100/100 [==============================] - 0s 239us/sample - loss: 0.1476 - accuracy: 0.9500 - val_loss: 0.0597 - val_accuracy: 0.9600\n",
      "Epoch 794/1000\n",
      "100/100 [==============================] - 0s 239us/sample - loss: 0.1425 - accuracy: 0.9500 - val_loss: 0.0442 - val_accuracy: 0.9800\n",
      "Epoch 795/1000\n",
      "100/100 [==============================] - 0s 259us/sample - loss: 0.0901 - accuracy: 0.9700 - val_loss: 0.0057 - val_accuracy: 1.0000\n",
      "Epoch 796/1000\n",
      "100/100 [==============================] - 0s 269us/sample - loss: 0.1015 - accuracy: 0.9600 - val_loss: 0.0562 - val_accuracy: 0.9600\n",
      "Epoch 797/1000\n",
      "100/100 [==============================] - 0s 229us/sample - loss: 0.0747 - accuracy: 0.9600 - val_loss: 0.0302 - val_accuracy: 1.0000\n",
      "Epoch 798/1000\n",
      "100/100 [==============================] - 0s 239us/sample - loss: 0.0563 - accuracy: 0.9700 - val_loss: 0.0112 - val_accuracy: 1.0000\n",
      "Epoch 799/1000\n",
      "100/100 [==============================] - 0s 439us/sample - loss: 0.0673 - accuracy: 0.9800 - val_loss: 0.0424 - val_accuracy: 0.9800\n",
      "Epoch 800/1000\n",
      "100/100 [==============================] - 0s 289us/sample - loss: 0.0604 - accuracy: 0.9600 - val_loss: 0.0604 - val_accuracy: 0.9600\n",
      "Epoch 801/1000\n",
      "100/100 [==============================] - 0s 279us/sample - loss: 0.0634 - accuracy: 0.9700 - val_loss: 0.0102 - val_accuracy: 1.0000\n",
      "Epoch 802/1000\n",
      "100/100 [==============================] - 0s 249us/sample - loss: 0.0701 - accuracy: 0.9700 - val_loss: 0.0317 - val_accuracy: 1.0000\n",
      "Epoch 803/1000\n",
      "100/100 [==============================] - 0s 299us/sample - loss: 0.0577 - accuracy: 0.9800 - val_loss: 0.0348 - val_accuracy: 0.9800\n",
      "Epoch 804/1000\n",
      "100/100 [==============================] - 0s 289us/sample - loss: 0.0647 - accuracy: 0.9800 - val_loss: 0.0323 - val_accuracy: 1.0000\n",
      "Epoch 805/1000\n",
      "100/100 [==============================] - 0s 229us/sample - loss: 0.0606 - accuracy: 0.9700 - val_loss: 0.0646 - val_accuracy: 0.9600\n",
      "Epoch 806/1000\n",
      "100/100 [==============================] - 0s 379us/sample - loss: 0.0639 - accuracy: 0.9700 - val_loss: 0.0199 - val_accuracy: 1.0000\n",
      "Epoch 807/1000\n",
      "100/100 [==============================] - 0s 259us/sample - loss: 0.0601 - accuracy: 0.9700 - val_loss: 0.0260 - val_accuracy: 1.0000\n",
      "Epoch 808/1000\n",
      "100/100 [==============================] - 0s 229us/sample - loss: 0.0725 - accuracy: 0.9700 - val_loss: 0.0203 - val_accuracy: 1.0000\n",
      "Epoch 809/1000\n",
      "100/100 [==============================] - 0s 279us/sample - loss: 0.1243 - accuracy: 0.9600 - val_loss: 0.0134 - val_accuracy: 1.0000\n",
      "Epoch 810/1000\n",
      "100/100 [==============================] - 0s 259us/sample - loss: 0.1085 - accuracy: 0.9400 - val_loss: 0.2612 - val_accuracy: 0.8800\n",
      "Epoch 811/1000\n",
      "100/100 [==============================] - 0s 309us/sample - loss: 0.1638 - accuracy: 0.9100 - val_loss: 0.0067 - val_accuracy: 1.0000\n",
      "Epoch 812/1000\n",
      "100/100 [==============================] - 0s 249us/sample - loss: 0.1027 - accuracy: 0.9600 - val_loss: 0.0544 - val_accuracy: 0.9600\n",
      "Epoch 813/1000\n",
      "100/100 [==============================] - 0s 239us/sample - loss: 0.0672 - accuracy: 0.9600 - val_loss: 0.0514 - val_accuracy: 0.9600\n",
      "Epoch 814/1000\n",
      "100/100 [==============================] - 0s 229us/sample - loss: 0.0829 - accuracy: 0.9600 - val_loss: 0.0417 - val_accuracy: 0.9800\n",
      "Epoch 815/1000\n",
      "100/100 [==============================] - 0s 299us/sample - loss: 0.0994 - accuracy: 0.9700 - val_loss: 0.0961 - val_accuracy: 0.9400\n",
      "Epoch 816/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.0634 - accuracy: 0.9700 - val_loss: 0.0066 - val_accuracy: 1.0000\n",
      "Epoch 817/1000\n",
      "100/100 [==============================] - 0s 229us/sample - loss: 0.1101 - accuracy: 0.9600 - val_loss: 0.0255 - val_accuracy: 1.0000\n",
      "Epoch 818/1000\n",
      "100/100 [==============================] - 0s 259us/sample - loss: 0.0684 - accuracy: 0.9700 - val_loss: 0.0698 - val_accuracy: 0.9600\n",
      "Epoch 819/1000\n",
      "100/100 [==============================] - 0s 199us/sample - loss: 0.0600 - accuracy: 0.9800 - val_loss: 0.0130 - val_accuracy: 1.0000\n",
      "Epoch 820/1000\n",
      "100/100 [==============================] - 0s 259us/sample - loss: 0.0839 - accuracy: 0.9700 - val_loss: 0.0232 - val_accuracy: 1.0000\n",
      "Epoch 821/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.0669 - accuracy: 0.9800 - val_loss: 0.0956 - val_accuracy: 0.9400\n",
      "Epoch 822/1000\n",
      "100/100 [==============================] - 0s 180us/sample - loss: 0.0639 - accuracy: 0.9600 - val_loss: 0.0088 - val_accuracy: 1.0000\n",
      "Epoch 823/1000\n",
      "100/100 [==============================] - 0s 229us/sample - loss: 0.0866 - accuracy: 0.9700 - val_loss: 0.0157 - val_accuracy: 1.0000\n",
      "Epoch 824/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.0782 - accuracy: 0.9800 - val_loss: 0.0736 - val_accuracy: 0.9600\n",
      "Epoch 825/1000\n",
      "100/100 [==============================] - 0s 199us/sample - loss: 0.0736 - accuracy: 0.9600 - val_loss: 0.0127 - val_accuracy: 1.0000\n",
      "Epoch 826/1000\n",
      "100/100 [==============================] - 0s 229us/sample - loss: 0.0679 - accuracy: 0.9700 - val_loss: 0.0303 - val_accuracy: 1.0000\n",
      "Epoch 827/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.0629 - accuracy: 0.9700 - val_loss: 0.0477 - val_accuracy: 0.9600\n",
      "Epoch 828/1000\n",
      "100/100 [==============================] - 0s 209us/sample - loss: 0.0623 - accuracy: 0.9700 - val_loss: 0.0203 - val_accuracy: 1.0000\n",
      "Epoch 829/1000\n",
      "100/100 [==============================] - 0s 199us/sample - loss: 0.0589 - accuracy: 0.9700 - val_loss: 0.0354 - val_accuracy: 0.9800\n",
      "Epoch 830/1000\n",
      "100/100 [==============================] - 0s 199us/sample - loss: 0.0607 - accuracy: 0.9700 - val_loss: 0.0359 - val_accuracy: 0.9800\n",
      "Epoch 831/1000\n",
      "100/100 [==============================] - 0s 199us/sample - loss: 0.0567 - accuracy: 0.9800 - val_loss: 0.0207 - val_accuracy: 1.0000\n",
      "Epoch 832/1000\n",
      "100/100 [==============================] - 0s 229us/sample - loss: 0.0601 - accuracy: 0.9800 - val_loss: 0.0237 - val_accuracy: 1.0000\n",
      "Epoch 833/1000\n",
      "100/100 [==============================] - 0s 239us/sample - loss: 0.0625 - accuracy: 0.9800 - val_loss: 0.0356 - val_accuracy: 0.9800\n",
      "Epoch 834/1000\n",
      "100/100 [==============================] - 0s 209us/sample - loss: 0.0582 - accuracy: 0.9800 - val_loss: 0.0239 - val_accuracy: 1.0000\n",
      "Epoch 835/1000\n",
      "100/100 [==============================] - 0s 239us/sample - loss: 0.0584 - accuracy: 0.9700 - val_loss: 0.0180 - val_accuracy: 1.0000\n",
      "Epoch 836/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.0740 - accuracy: 0.9700 - val_loss: 0.0335 - val_accuracy: 1.0000\n",
      "Epoch 837/1000\n",
      "100/100 [==============================] - 0s 229us/sample - loss: 0.0551 - accuracy: 0.9800 - val_loss: 0.0134 - val_accuracy: 1.0000\n",
      "Epoch 838/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.0721 - accuracy: 0.9600 - val_loss: 0.0219 - val_accuracy: 1.0000\n",
      "Epoch 839/1000\n",
      "100/100 [==============================] - 0s 199us/sample - loss: 0.0646 - accuracy: 0.9600 - val_loss: 0.0344 - val_accuracy: 0.9800\n",
      "Epoch 840/1000\n",
      "100/100 [==============================] - 0s 209us/sample - loss: 0.0618 - accuracy: 0.9600 - val_loss: 0.0631 - val_accuracy: 0.9600\n",
      "Epoch 841/1000\n",
      "100/100 [==============================] - 0s 209us/sample - loss: 0.0567 - accuracy: 0.9800 - val_loss: 0.0161 - val_accuracy: 1.0000\n",
      "Epoch 842/1000\n",
      "100/100 [==============================] - 0s 239us/sample - loss: 0.0629 - accuracy: 0.9700 - val_loss: 0.0517 - val_accuracy: 0.9600\n",
      "Epoch 843/1000\n",
      "100/100 [==============================] - 0s 209us/sample - loss: 0.1020 - accuracy: 0.9500 - val_loss: 0.0702 - val_accuracy: 0.9600\n",
      "Epoch 844/1000\n",
      "100/100 [==============================] - 0s 199us/sample - loss: 0.0660 - accuracy: 0.9800 - val_loss: 0.0202 - val_accuracy: 1.0000\n",
      "Epoch 845/1000\n",
      "100/100 [==============================] - 0s 189us/sample - loss: 0.0696 - accuracy: 0.9600 - val_loss: 0.0314 - val_accuracy: 1.0000\n",
      "Epoch 846/1000\n",
      "100/100 [==============================] - 0s 229us/sample - loss: 0.0607 - accuracy: 0.9700 - val_loss: 0.0491 - val_accuracy: 0.9600\n",
      "Epoch 847/1000\n",
      "100/100 [==============================] - 0s 239us/sample - loss: 0.0600 - accuracy: 0.9800 - val_loss: 0.0307 - val_accuracy: 1.0000\n",
      "Epoch 848/1000\n",
      "100/100 [==============================] - 0s 199us/sample - loss: 0.0574 - accuracy: 0.9800 - val_loss: 0.0313 - val_accuracy: 1.0000\n",
      "Epoch 849/1000\n",
      "100/100 [==============================] - 0s 199us/sample - loss: 0.0687 - accuracy: 0.9700 - val_loss: 0.0219 - val_accuracy: 1.0000\n",
      "Epoch 850/1000\n",
      "100/100 [==============================] - 0s 299us/sample - loss: 0.0648 - accuracy: 0.9800 - val_loss: 0.0435 - val_accuracy: 0.9800\n",
      "Epoch 851/1000\n",
      "100/100 [==============================] - 0s 229us/sample - loss: 0.0577 - accuracy: 0.9700 - val_loss: 0.0191 - val_accuracy: 1.0000\n",
      "Epoch 852/1000\n",
      "100/100 [==============================] - 0s 209us/sample - loss: 0.0634 - accuracy: 0.9700 - val_loss: 0.0230 - val_accuracy: 1.0000\n",
      "Epoch 853/1000\n",
      "100/100 [==============================] - 0s 249us/sample - loss: 0.0599 - accuracy: 0.9800 - val_loss: 0.0416 - val_accuracy: 0.9800\n",
      "Epoch 854/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.0875 - accuracy: 0.9600 - val_loss: 0.0528 - val_accuracy: 0.9600\n",
      "Epoch 855/1000\n",
      "100/100 [==============================] - 0s 209us/sample - loss: 0.0815 - accuracy: 0.9600 - val_loss: 0.0143 - val_accuracy: 1.0000\n",
      "Epoch 856/1000\n",
      "100/100 [==============================] - 0s 209us/sample - loss: 0.0596 - accuracy: 0.9700 - val_loss: 0.0621 - val_accuracy: 0.9600\n",
      "Epoch 857/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.0706 - accuracy: 0.9700 - val_loss: 0.0563 - val_accuracy: 0.9600\n",
      "Epoch 858/1000\n",
      "100/100 [==============================] - 0s 249us/sample - loss: 0.0744 - accuracy: 0.9600 - val_loss: 0.0279 - val_accuracy: 1.0000\n",
      "Epoch 859/1000\n",
      "100/100 [==============================] - 0s 199us/sample - loss: 0.0618 - accuracy: 0.9700 - val_loss: 0.0182 - val_accuracy: 1.0000\n",
      "Epoch 860/1000\n",
      "100/100 [==============================] - 0s 259us/sample - loss: 0.0595 - accuracy: 0.9700 - val_loss: 0.0495 - val_accuracy: 0.9600\n",
      "Epoch 861/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.0763 - accuracy: 0.9600 - val_loss: 0.0752 - val_accuracy: 0.9600\n",
      "Epoch 862/1000\n",
      "100/100 [==============================] - 0s 199us/sample - loss: 0.0665 - accuracy: 0.9600 - val_loss: 0.0125 - val_accuracy: 1.0000\n",
      "Epoch 863/1000\n",
      "100/100 [==============================] - 0s 209us/sample - loss: 0.0714 - accuracy: 0.9700 - val_loss: 0.0344 - val_accuracy: 0.9800\n",
      "Epoch 864/1000\n",
      "100/100 [==============================] - 0s 249us/sample - loss: 0.0602 - accuracy: 0.9700 - val_loss: 0.0609 - val_accuracy: 0.9600\n",
      "Epoch 865/1000\n",
      "100/100 [==============================] - 0s 209us/sample - loss: 0.0617 - accuracy: 0.9700 - val_loss: 0.0153 - val_accuracy: 1.0000\n",
      "Epoch 866/1000\n",
      "100/100 [==============================] - 0s 209us/sample - loss: 0.0684 - accuracy: 0.9700 - val_loss: 0.0247 - val_accuracy: 1.0000\n",
      "Epoch 867/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.0561 - accuracy: 0.9800 - val_loss: 0.0440 - val_accuracy: 0.9800\n",
      "Epoch 868/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.0592 - accuracy: 0.9700 - val_loss: 0.0235 - val_accuracy: 1.0000\n",
      "Epoch 869/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.0859 - accuracy: 0.9600 - val_loss: 0.0152 - val_accuracy: 1.0000\n",
      "Epoch 870/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.0542 - accuracy: 0.9800 - val_loss: 0.0874 - val_accuracy: 0.9400\n",
      "Epoch 871/1000\n",
      "100/100 [==============================] - 0s 249us/sample - loss: 0.1069 - accuracy: 0.9700 - val_loss: 0.0887 - val_accuracy: 0.9400\n",
      "Epoch 872/1000\n",
      "100/100 [==============================] - 0s 259us/sample - loss: 0.0737 - accuracy: 0.9700 - val_loss: 0.0145 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 873/1000\n",
      "100/100 [==============================] - 0s 229us/sample - loss: 0.0624 - accuracy: 0.9700 - val_loss: 0.0344 - val_accuracy: 0.9800\n",
      "Epoch 874/1000\n",
      "100/100 [==============================] - 0s 180us/sample - loss: 0.0568 - accuracy: 0.9800 - val_loss: 0.0412 - val_accuracy: 0.9800\n",
      "Epoch 875/1000\n",
      "100/100 [==============================] - 0s 239us/sample - loss: 0.0644 - accuracy: 0.9700 - val_loss: 0.0226 - val_accuracy: 1.0000\n",
      "Epoch 876/1000\n",
      "100/100 [==============================] - 0s 239us/sample - loss: 0.0699 - accuracy: 0.9800 - val_loss: 0.0144 - val_accuracy: 1.0000\n",
      "Epoch 877/1000\n",
      "100/100 [==============================] - 0s 199us/sample - loss: 0.0731 - accuracy: 0.9700 - val_loss: 0.0271 - val_accuracy: 1.0000\n",
      "Epoch 878/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.0912 - accuracy: 0.9600 - val_loss: 0.0207 - val_accuracy: 1.0000\n",
      "Epoch 879/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.0937 - accuracy: 0.9700 - val_loss: 0.1563 - val_accuracy: 0.9200\n",
      "Epoch 880/1000\n",
      "100/100 [==============================] - 0s 199us/sample - loss: 0.0948 - accuracy: 0.9600 - val_loss: 0.0079 - val_accuracy: 1.0000\n",
      "Epoch 881/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.0856 - accuracy: 0.9700 - val_loss: 0.0184 - val_accuracy: 1.0000\n",
      "Epoch 882/1000\n",
      "100/100 [==============================] - 0s 209us/sample - loss: 0.0611 - accuracy: 0.9600 - val_loss: 0.0410 - val_accuracy: 0.9800\n",
      "Epoch 883/1000\n",
      "100/100 [==============================] - 0s 189us/sample - loss: 0.0627 - accuracy: 0.9800 - val_loss: 0.0124 - val_accuracy: 1.0000\n",
      "Epoch 884/1000\n",
      "100/100 [==============================] - 0s 209us/sample - loss: 0.0807 - accuracy: 0.9700 - val_loss: 0.0280 - val_accuracy: 1.0000\n",
      "Epoch 885/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.0711 - accuracy: 0.9700 - val_loss: 0.0143 - val_accuracy: 1.0000\n",
      "Epoch 886/1000\n",
      "100/100 [==============================] - 0s 189us/sample - loss: 0.0601 - accuracy: 0.9700 - val_loss: 0.1350 - val_accuracy: 0.9400\n",
      "Epoch 887/1000\n",
      "100/100 [==============================] - 0s 189us/sample - loss: 0.1033 - accuracy: 0.9600 - val_loss: 0.0205 - val_accuracy: 1.0000\n",
      "Epoch 888/1000\n",
      "100/100 [==============================] - 0s 229us/sample - loss: 0.0798 - accuracy: 0.9600 - val_loss: 0.0150 - val_accuracy: 1.0000\n",
      "Epoch 889/1000\n",
      "100/100 [==============================] - 0s 189us/sample - loss: 0.1008 - accuracy: 0.9600 - val_loss: 0.0579 - val_accuracy: 0.9600\n",
      "Epoch 890/1000\n",
      "100/100 [==============================] - 0s 229us/sample - loss: 0.0733 - accuracy: 0.9600 - val_loss: 0.0088 - val_accuracy: 1.0000\n",
      "Epoch 891/1000\n",
      "100/100 [==============================] - 0s 209us/sample - loss: 0.0741 - accuracy: 0.9700 - val_loss: 0.0540 - val_accuracy: 0.9600\n",
      "Epoch 892/1000\n",
      "100/100 [==============================] - 0s 229us/sample - loss: 0.0698 - accuracy: 0.9700 - val_loss: 0.0361 - val_accuracy: 0.9800\n",
      "Epoch 893/1000\n",
      "100/100 [==============================] - 0s 209us/sample - loss: 0.0654 - accuracy: 0.9700 - val_loss: 0.0138 - val_accuracy: 1.0000\n",
      "Epoch 894/1000\n",
      "100/100 [==============================] - 0s 239us/sample - loss: 0.0629 - accuracy: 0.9600 - val_loss: 0.0378 - val_accuracy: 0.9800\n",
      "Epoch 895/1000\n",
      "100/100 [==============================] - 0s 229us/sample - loss: 0.0616 - accuracy: 0.9700 - val_loss: 0.0332 - val_accuracy: 1.0000\n",
      "Epoch 896/1000\n",
      "100/100 [==============================] - 0s 229us/sample - loss: 0.0640 - accuracy: 0.9700 - val_loss: 0.0575 - val_accuracy: 0.9600\n",
      "Epoch 897/1000\n",
      "100/100 [==============================] - 0s 229us/sample - loss: 0.0908 - accuracy: 0.9600 - val_loss: 0.0825 - val_accuracy: 0.9400\n",
      "Epoch 898/1000\n",
      "100/100 [==============================] - 0s 229us/sample - loss: 0.1176 - accuracy: 0.9500 - val_loss: 0.0063 - val_accuracy: 1.0000\n",
      "Epoch 899/1000\n",
      "100/100 [==============================] - 0s 199us/sample - loss: 0.1095 - accuracy: 0.9400 - val_loss: 0.1146 - val_accuracy: 0.9400\n",
      "Epoch 900/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.0864 - accuracy: 0.9700 - val_loss: 0.0096 - val_accuracy: 1.0000\n",
      "Epoch 901/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.0914 - accuracy: 0.9600 - val_loss: 0.0409 - val_accuracy: 0.9800\n",
      "Epoch 902/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.0919 - accuracy: 0.9700 - val_loss: 0.1514 - val_accuracy: 0.9200\n",
      "Epoch 903/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.0995 - accuracy: 0.9700 - val_loss: 0.0088 - val_accuracy: 1.0000\n",
      "Epoch 904/1000\n",
      "100/100 [==============================] - 0s 249us/sample - loss: 0.0671 - accuracy: 0.9700 - val_loss: 0.0777 - val_accuracy: 0.9400\n",
      "Epoch 905/1000\n",
      "100/100 [==============================] - 0s 199us/sample - loss: 0.1107 - accuracy: 0.9600 - val_loss: 0.0231 - val_accuracy: 1.0000\n",
      "Epoch 906/1000\n",
      "100/100 [==============================] - 0s 209us/sample - loss: 0.1128 - accuracy: 0.9500 - val_loss: 0.0075 - val_accuracy: 1.0000\n",
      "Epoch 907/1000\n",
      "100/100 [==============================] - 0s 239us/sample - loss: 0.0746 - accuracy: 0.9800 - val_loss: 0.0831 - val_accuracy: 0.9400\n",
      "Epoch 908/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.0804 - accuracy: 0.9500 - val_loss: 0.0453 - val_accuracy: 0.9800\n",
      "Epoch 909/1000\n",
      "100/100 [==============================] - 0s 229us/sample - loss: 0.0734 - accuracy: 0.9800 - val_loss: 0.0150 - val_accuracy: 1.0000\n",
      "Epoch 910/1000\n",
      "100/100 [==============================] - 0s 209us/sample - loss: 0.0421 - accuracy: 0.9800 - val_loss: 0.1342 - val_accuracy: 0.9400\n",
      "Epoch 911/1000\n",
      "100/100 [==============================] - 0s 209us/sample - loss: 0.1180 - accuracy: 0.9500 - val_loss: 0.0144 - val_accuracy: 1.0000\n",
      "Epoch 912/1000\n",
      "100/100 [==============================] - 0s 239us/sample - loss: 0.1607 - accuracy: 0.9500 - val_loss: 0.0105 - val_accuracy: 1.0000\n",
      "Epoch 913/1000\n",
      "100/100 [==============================] - 0s 249us/sample - loss: 0.1434 - accuracy: 0.9400 - val_loss: 0.1222 - val_accuracy: 0.9400\n",
      "Epoch 914/1000\n",
      "100/100 [==============================] - 0s 199us/sample - loss: 0.0825 - accuracy: 0.9500 - val_loss: 0.0090 - val_accuracy: 1.0000\n",
      "Epoch 915/1000\n",
      "100/100 [==============================] - 0s 229us/sample - loss: 0.1491 - accuracy: 0.9500 - val_loss: 0.0356 - val_accuracy: 0.9800\n",
      "Epoch 916/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.0815 - accuracy: 0.9700 - val_loss: 0.0476 - val_accuracy: 0.9600\n",
      "Epoch 917/1000\n",
      "100/100 [==============================] - 0s 279us/sample - loss: 0.0881 - accuracy: 0.9700 - val_loss: 0.0084 - val_accuracy: 1.0000\n",
      "Epoch 918/1000\n",
      "100/100 [==============================] - 0s 209us/sample - loss: 0.1065 - accuracy: 0.9600 - val_loss: 0.0638 - val_accuracy: 0.9600\n",
      "Epoch 919/1000\n",
      "100/100 [==============================] - 0s 209us/sample - loss: 0.0921 - accuracy: 0.9600 - val_loss: 0.0509 - val_accuracy: 0.9600\n",
      "Epoch 920/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.0559 - accuracy: 0.9700 - val_loss: 0.0112 - val_accuracy: 1.0000\n",
      "Epoch 921/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.0683 - accuracy: 0.9800 - val_loss: 0.0372 - val_accuracy: 0.9800\n",
      "Epoch 922/1000\n",
      "100/100 [==============================] - 0s 209us/sample - loss: 0.0849 - accuracy: 0.9600 - val_loss: 0.0416 - val_accuracy: 0.9800\n",
      "Epoch 923/1000\n",
      "100/100 [==============================] - 0s 199us/sample - loss: 0.1024 - accuracy: 0.9600 - val_loss: 0.0067 - val_accuracy: 1.0000\n",
      "Epoch 924/1000\n",
      "100/100 [==============================] - 0s 239us/sample - loss: 0.1027 - accuracy: 0.9500 - val_loss: 0.0692 - val_accuracy: 0.9600\n",
      "Epoch 925/1000\n",
      "100/100 [==============================] - 0s 239us/sample - loss: 0.0666 - accuracy: 0.9700 - val_loss: 0.0329 - val_accuracy: 1.0000\n",
      "Epoch 926/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.0601 - accuracy: 0.9800 - val_loss: 0.0327 - val_accuracy: 1.0000\n",
      "Epoch 927/1000\n",
      "100/100 [==============================] - 0s 209us/sample - loss: 0.0544 - accuracy: 0.9800 - val_loss: 0.0799 - val_accuracy: 0.9400\n",
      "Epoch 928/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.0695 - accuracy: 0.9700 - val_loss: 0.0220 - val_accuracy: 1.0000\n",
      "Epoch 929/1000\n",
      "100/100 [==============================] - 0s 199us/sample - loss: 0.0913 - accuracy: 0.9500 - val_loss: 0.0142 - val_accuracy: 1.0000\n",
      "Epoch 930/1000\n",
      "100/100 [==============================] - 0s 209us/sample - loss: 0.0699 - accuracy: 0.9800 - val_loss: 0.0268 - val_accuracy: 1.0000\n",
      "Epoch 931/1000\n",
      "100/100 [==============================] - 0s 199us/sample - loss: 0.0713 - accuracy: 0.9700 - val_loss: 0.0109 - val_accuracy: 1.0000\n",
      "Epoch 932/1000\n",
      "100/100 [==============================] - 0s 199us/sample - loss: 0.0711 - accuracy: 0.9700 - val_loss: 0.0443 - val_accuracy: 0.9800\n",
      "Epoch 933/1000\n",
      "100/100 [==============================] - 0s 229us/sample - loss: 0.0607 - accuracy: 0.9700 - val_loss: 0.0307 - val_accuracy: 1.0000\n",
      "Epoch 934/1000\n",
      "100/100 [==============================] - 0s 199us/sample - loss: 0.0834 - accuracy: 0.9700 - val_loss: 0.0160 - val_accuracy: 1.0000\n",
      "Epoch 935/1000\n",
      "100/100 [==============================] - 0s 199us/sample - loss: 0.0667 - accuracy: 0.9700 - val_loss: 0.0581 - val_accuracy: 0.9600\n",
      "Epoch 936/1000\n",
      "100/100 [==============================] - 0s 199us/sample - loss: 0.0664 - accuracy: 0.9700 - val_loss: 0.0135 - val_accuracy: 1.0000\n",
      "Epoch 937/1000\n",
      "100/100 [==============================] - 0s 229us/sample - loss: 0.0596 - accuracy: 0.9800 - val_loss: 0.0388 - val_accuracy: 0.9800\n",
      "Epoch 938/1000\n",
      "100/100 [==============================] - 0s 239us/sample - loss: 0.0559 - accuracy: 0.9800 - val_loss: 0.0199 - val_accuracy: 1.0000\n",
      "Epoch 939/1000\n",
      "100/100 [==============================] - 0s 229us/sample - loss: 0.0674 - accuracy: 0.9600 - val_loss: 0.0205 - val_accuracy: 1.0000\n",
      "Epoch 940/1000\n",
      "100/100 [==============================] - 0s 199us/sample - loss: 0.0564 - accuracy: 0.9800 - val_loss: 0.0411 - val_accuracy: 0.9800\n",
      "Epoch 941/1000\n",
      "100/100 [==============================] - 0s 249us/sample - loss: 0.0636 - accuracy: 0.9700 - val_loss: 0.0338 - val_accuracy: 0.9800\n",
      "Epoch 942/1000\n",
      "100/100 [==============================] - 0s 199us/sample - loss: 0.0534 - accuracy: 0.9800 - val_loss: 0.0095 - val_accuracy: 1.0000\n",
      "Epoch 943/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.0791 - accuracy: 0.9700 - val_loss: 0.0259 - val_accuracy: 1.0000\n",
      "Epoch 944/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.0576 - accuracy: 0.9800 - val_loss: 0.0596 - val_accuracy: 0.9600\n",
      "Epoch 945/1000\n",
      "100/100 [==============================] - 0s 229us/sample - loss: 0.0817 - accuracy: 0.9600 - val_loss: 0.0175 - val_accuracy: 1.0000\n",
      "Epoch 946/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.1950 - accuracy: 0.9400 - val_loss: 0.0077 - val_accuracy: 1.0000\n",
      "Epoch 947/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.0850 - accuracy: 0.9700 - val_loss: 0.1627 - val_accuracy: 0.9200\n",
      "Epoch 948/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.1715 - accuracy: 0.9200 - val_loss: 0.0208 - val_accuracy: 1.0000\n",
      "Epoch 949/1000\n",
      "100/100 [==============================] - 0s 209us/sample - loss: 0.1170 - accuracy: 0.9500 - val_loss: 0.0175 - val_accuracy: 1.0000\n",
      "Epoch 950/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.1815 - accuracy: 0.9200 - val_loss: 0.1551 - val_accuracy: 0.9200\n",
      "Epoch 951/1000\n",
      "100/100 [==============================] - 0s 209us/sample - loss: 0.2005 - accuracy: 0.9300 - val_loss: 0.0067 - val_accuracy: 1.0000\n",
      "Epoch 952/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.0960 - accuracy: 0.9700 - val_loss: 0.1635 - val_accuracy: 0.9200\n",
      "Epoch 953/1000\n",
      "100/100 [==============================] - 0s 209us/sample - loss: 0.1140 - accuracy: 0.9600 - val_loss: 0.0172 - val_accuracy: 1.0000\n",
      "Epoch 954/1000\n",
      "100/100 [==============================] - 0s 199us/sample - loss: 0.1091 - accuracy: 0.9400 - val_loss: 0.0089 - val_accuracy: 1.0000\n",
      "Epoch 955/1000\n",
      "100/100 [==============================] - 0s 229us/sample - loss: 0.0726 - accuracy: 0.9600 - val_loss: 0.1039 - val_accuracy: 0.9400\n",
      "Epoch 956/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.0819 - accuracy: 0.9700 - val_loss: 0.0247 - val_accuracy: 1.0000\n",
      "Epoch 957/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.1042 - accuracy: 0.9600 - val_loss: 0.0162 - val_accuracy: 1.0000\n",
      "Epoch 958/1000\n",
      "100/100 [==============================] - 0s 289us/sample - loss: 0.1040 - accuracy: 0.9700 - val_loss: 0.0585 - val_accuracy: 0.9600\n",
      "Epoch 959/1000\n",
      "100/100 [==============================] - 0s 229us/sample - loss: 0.0735 - accuracy: 0.9600 - val_loss: 0.0067 - val_accuracy: 1.0000\n",
      "Epoch 960/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.0922 - accuracy: 0.9600 - val_loss: 0.0898 - val_accuracy: 0.9400\n",
      "Epoch 961/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.0882 - accuracy: 0.9500 - val_loss: 0.0424 - val_accuracy: 0.9800\n",
      "Epoch 962/1000\n",
      "100/100 [==============================] - 0s 229us/sample - loss: 0.0551 - accuracy: 0.9700 - val_loss: 0.0067 - val_accuracy: 1.0000\n",
      "Epoch 963/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.1059 - accuracy: 0.9600 - val_loss: 0.0374 - val_accuracy: 0.9800\n",
      "Epoch 964/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.1059 - accuracy: 0.9500 - val_loss: 0.0525 - val_accuracy: 0.9600\n",
      "Epoch 965/1000\n",
      "100/100 [==============================] - 0s 289us/sample - loss: 0.1243 - accuracy: 0.9500 - val_loss: 0.0072 - val_accuracy: 1.0000\n",
      "Epoch 966/1000\n",
      "100/100 [==============================] - 0s 199us/sample - loss: 0.0637 - accuracy: 0.9700 - val_loss: 0.1576 - val_accuracy: 0.9200\n",
      "Epoch 967/1000\n",
      "100/100 [==============================] - 0s 209us/sample - loss: 0.1298 - accuracy: 0.9600 - val_loss: 0.0109 - val_accuracy: 1.0000\n",
      "Epoch 968/1000\n",
      "100/100 [==============================] - 0s 239us/sample - loss: 0.0952 - accuracy: 0.9700 - val_loss: 0.0061 - val_accuracy: 1.0000\n",
      "Epoch 969/1000\n",
      "100/100 [==============================] - 0s 199us/sample - loss: 0.1075 - accuracy: 0.9600 - val_loss: 0.2312 - val_accuracy: 0.9000\n",
      "Epoch 970/1000\n",
      "100/100 [==============================] - 0s 209us/sample - loss: 0.1706 - accuracy: 0.9200 - val_loss: 0.0096 - val_accuracy: 1.0000\n",
      "Epoch 971/1000\n",
      "100/100 [==============================] - 0s 249us/sample - loss: 0.1574 - accuracy: 0.9500 - val_loss: 0.0065 - val_accuracy: 1.0000\n",
      "Epoch 972/1000\n",
      "100/100 [==============================] - 0s 209us/sample - loss: 0.0569 - accuracy: 0.9900 - val_loss: 0.1214 - val_accuracy: 0.9400\n",
      "Epoch 973/1000\n",
      "100/100 [==============================] - 0s 189us/sample - loss: 0.1215 - accuracy: 0.9500 - val_loss: 0.0223 - val_accuracy: 1.0000\n",
      "Epoch 974/1000\n",
      "100/100 [==============================] - 0s 199us/sample - loss: 0.1113 - accuracy: 0.9500 - val_loss: 0.0066 - val_accuracy: 1.0000\n",
      "Epoch 975/1000\n",
      "100/100 [==============================] - 0s 229us/sample - loss: 0.1100 - accuracy: 0.9600 - val_loss: 0.0611 - val_accuracy: 0.9600\n",
      "Epoch 976/1000\n",
      "100/100 [==============================] - 0s 209us/sample - loss: 0.0885 - accuracy: 0.9700 - val_loss: 0.0674 - val_accuracy: 0.9600\n",
      "Epoch 977/1000\n",
      "100/100 [==============================] - 0s 190us/sample - loss: 0.0658 - accuracy: 0.9600 - val_loss: 0.0058 - val_accuracy: 1.0000\n",
      "Epoch 978/1000\n",
      "100/100 [==============================] - 0s 209us/sample - loss: 0.0892 - accuracy: 0.9700 - val_loss: 0.0517 - val_accuracy: 0.9600\n",
      "Epoch 979/1000\n",
      "100/100 [==============================] - 0s 229us/sample - loss: 0.0941 - accuracy: 0.9600 - val_loss: 0.0613 - val_accuracy: 0.9600\n",
      "Epoch 980/1000\n",
      "100/100 [==============================] - 0s 199us/sample - loss: 0.0546 - accuracy: 0.9700 - val_loss: 0.0065 - val_accuracy: 1.0000\n",
      "Epoch 981/1000\n",
      "100/100 [==============================] - 0s 229us/sample - loss: 0.0922 - accuracy: 0.9700 - val_loss: 0.0507 - val_accuracy: 0.9600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 982/1000\n",
      "100/100 [==============================] - 0s 209us/sample - loss: 0.1332 - accuracy: 0.9500 - val_loss: 0.2044 - val_accuracy: 0.9200\n",
      "Epoch 983/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.1310 - accuracy: 0.9500 - val_loss: 0.0060 - val_accuracy: 1.0000\n",
      "Epoch 984/1000\n",
      "100/100 [==============================] - 0s 189us/sample - loss: 0.1079 - accuracy: 0.9700 - val_loss: 0.0434 - val_accuracy: 0.9800\n",
      "Epoch 985/1000\n",
      "100/100 [==============================] - 0s 209us/sample - loss: 0.0709 - accuracy: 0.9600 - val_loss: 0.0680 - val_accuracy: 0.9600\n",
      "Epoch 986/1000\n",
      "100/100 [==============================] - 0s 199us/sample - loss: 0.0515 - accuracy: 0.9800 - val_loss: 0.0110 - val_accuracy: 1.0000\n",
      "Epoch 987/1000\n",
      "100/100 [==============================] - 0s 229us/sample - loss: 0.0749 - accuracy: 0.9700 - val_loss: 0.0208 - val_accuracy: 1.0000\n",
      "Epoch 988/1000\n",
      "100/100 [==============================] - 0s 199us/sample - loss: 0.0801 - accuracy: 0.9700 - val_loss: 0.0950 - val_accuracy: 0.9400\n",
      "Epoch 989/1000\n",
      "100/100 [==============================] - 0s 219us/sample - loss: 0.0780 - accuracy: 0.9700 - val_loss: 0.0175 - val_accuracy: 1.0000\n",
      "Epoch 990/1000\n",
      "100/100 [==============================] - 0s 199us/sample - loss: 0.0613 - accuracy: 0.9800 - val_loss: 0.0285 - val_accuracy: 1.0000\n",
      "Epoch 991/1000\n",
      "100/100 [==============================] - 0s 209us/sample - loss: 0.0623 - accuracy: 0.9700 - val_loss: 0.0428 - val_accuracy: 0.9800\n",
      "Epoch 992/1000\n",
      "100/100 [==============================] - 0s 229us/sample - loss: 0.0575 - accuracy: 0.9700 - val_loss: 0.0272 - val_accuracy: 1.0000\n",
      "Epoch 993/1000\n",
      "100/100 [==============================] - 0s 199us/sample - loss: 0.0604 - accuracy: 0.9700 - val_loss: 0.0448 - val_accuracy: 0.9800\n",
      "Epoch 994/1000\n",
      "100/100 [==============================] - 0s 209us/sample - loss: 0.0774 - accuracy: 0.9600 - val_loss: 0.0760 - val_accuracy: 0.9600\n",
      "Epoch 995/1000\n",
      "100/100 [==============================] - 0s 199us/sample - loss: 0.0809 - accuracy: 0.9500 - val_loss: 0.0146 - val_accuracy: 1.0000\n",
      "Epoch 996/1000\n",
      "100/100 [==============================] - 0s 269us/sample - loss: 0.0660 - accuracy: 0.9700 - val_loss: 0.0560 - val_accuracy: 0.9600\n",
      "Epoch 997/1000\n",
      "100/100 [==============================] - 0s 229us/sample - loss: 0.0730 - accuracy: 0.9600 - val_loss: 0.0305 - val_accuracy: 1.0000\n",
      "Epoch 998/1000\n",
      "100/100 [==============================] - 0s 189us/sample - loss: 0.0560 - accuracy: 0.9700 - val_loss: 0.0129 - val_accuracy: 1.0000\n",
      "Epoch 999/1000\n",
      "100/100 [==============================] - 0s 269us/sample - loss: 0.0675 - accuracy: 0.9600 - val_loss: 0.0295 - val_accuracy: 1.0000\n",
      "Epoch 1000/1000\n",
      "100/100 [==============================] - 0s 299us/sample - loss: 0.0571 - accuracy: 0.9800 - val_loss: 0.0215 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_inputs,train_outputs,validation_data=(val_inputs, val_outputs), epochs=1000,batch_size=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 0s 160us/sample - loss: 1.1058 - accuracy: 0.2800\n",
      "Test Loss: 1.106, Test accuracy: 0.280\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(val_inputs, val_outputs)\n",
    "print('Test Loss: %.3f, Test accuracy: %.3f' % (test_loss, test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title('Loss')\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO29ebwdVZnv/X323mdIckJGCCFzmIdAIAEhIB6UUW3UblvRth3avugrKtepG72Kr9jetift1hen7kt3vyqNCtoigojKYTAgBAhDAoEQEnISCJmTk+SMe90/qmrvVbVr2vvs4Zzi+X4+yaldtcaqVU/96llDiTEGRVEUJbvkWl0ARVEUpbGooVcURck4augVRVEyjhp6RVGUjKOGXlEUJeOooVcURck4augVRVEyjhp6JTOISI+I7BaRjlaXRVHGEmrolUwgIguB1wIGuLyJ+RaalZei1IoaeiUrvBd4EPgP4H3eThGZICL/JCKbRGSviNwvIhPcY+eJyEoR2SMim0Xk/e7+HhH5SyuN94vI/dZvIyJXichzwHPuvn9x09gnIo+IyGut8HkR+ZyIPC8i+93j80TkehH5J7sSIvILEfmfjThByqsXNfRKVngv8EP33yUiMsvd/4/AMmAFMB34K6AoIvOBO4BvAocDS4HVVeT3VuA1wEnu74fdNKYDNwI/EZFO99gngXcBbwQOA/4COAj8J/AuEckBiMhM4A3Af1VTcUVJQg29Mu4RkfOABcCPjTGPAM8D73YN6F8AVxtjthhjRowxK40xA8CfAb8xxvyXMWbIGLPTGFONof9bY8wuY8whAGPMD9w0ho0x/wR0AMe7Yf8S+LwxZp1xeNwN+xCwF8e4A1wB9Bhjto3ylCiKDzX0ShZ4H/BrY8wO9/eN7r6ZQCeO4Q8yL2J/WjbbP0TkUyLytOse2gNMcfNPyus/gfe42+8Bvj+KMilKKNqRpIxrXH/7O4C8iLzs7u4ApgKzgX7gaODxQNTNwFkRyR4AJlq/jwwJU1r21fXH/zWOMl9jjCmKyG5ArLyOBp4KSecHwFMichpwIvDfEWVSlJpRRa+Md94KjOD4ype6/04E7sPx298AfE1EjnI7Rc9xh1/+ELhQRN4hIgURmSEiS900VwN/LCITReQY4IMJZZgMDAPbgYKIXIvji/f4N+DLInKsOJwqIjMAjDG9OP797wO3eK4gRaknauiV8c77gH83xrxojHnZ+wf8fzh++GuAJ3GM6S7g74CcMeZFnM7RT7n7VwOnuWl+HRgEtuG4Vn6YUIY7cTp2nwU24bxF2K6drwE/Bn4N7AP+DzDBOv6fwBLUbaM0CNEPjyhKaxGR83FcOAuNMcVWl0fJHqroFaWFiEgbcDXwb2rklUahhl5RWoSInAjswek0/ucWF0fJMOq6URRFyTiq6BVFUTLOmBtHP3PmTLNw4cKa4x84cIBJkybVr0DjAK1z9nm11Re0ztXyyCOP7DDGHB52bMwZ+oULF7Jq1aqa4/f09NDd3V2/Ao0DtM7Z59VWX9A6V4uIbIo6pq4bRVGUjKOGXlEUJeOooVcURck4Y85HryiKUgtDQ0P09vbS39/f6qLUzJQpU3j66adjw3R2djJ37lza2tpSp6uGXlGUTNDb28vkyZNZuHAhIpIcYQyyf/9+Jk+eHHncGMPOnTvp7e1l0aJFqdNV142iKJmgv7+fGTNmjFsjnwYRYcaMGVW/taihVxQlM2TZyHvUUsfMGvqntuxl9eY9rS6GoihKy8msoX/zN+/nrdf/vtXFUBTlVcKePXv41re+VXW8N77xjezZ01hRmllDryiK0kyiDP3IyEhsvNtvv52pU6c2qliAjrpRFEWpC9dccw3PP/88S5cupa2tja6uLmbPns3q1atZu3Ytb33rW9m8eTP9/f1cffXVXHnllUB52Ze+vj4uueQSzj//fFauXMmcOXP4+c9/zoQJExJyTkYNvaIomeNLv1jD2q376prmSUcdxhf/6OTI41/96ld56qmnWL16NT09PbzpTW/iqaeeKg2DvOGGG5g+fTqHDh3izDPP5E/+5E+YMWOGL43nn3+eH/3oR/zrv/4r73jHO7jlllt4z3veM+qyq6FXFEVpAGeddZZvrPs3vvENfvaznwGwefNmnnvuuQpDv2DBApYudb5Rv2zZMjZu3FiXsqihVxQlc8Qp72ZhLzfc09PDb37zGx544AEmTpxId3d36Fj4jo6O0nY+n+fQoUN1KYt2xiqKotSByZMns3///tBje/fuZdq0aUycOJFnnnmGBx98sKllU0WvKIpSB2bMmMG5557LKaecwoQJE5g1a1bp2KWXXsp3vvMdTj31VI4//njOPvvsppYtM4Z+pGjY2TfAwLB+A1dRlNZw4403hu7v6OjgjjvuCD3m+eFnzpzJH/7wh9L+T3/603UrV2ZcN7sPDnLW//4t920ZbnVRFEVRxhSZMfS5V8EaF4qiKLWQIUPv/DXquVEURfGRGUMvOJa+2OJyKIqijDWyY+gzUxNFUZT6khnz6Pnoi+q6URRF8ZEZQ+91xRrU0iuK0nxqXaYY4J//+Z85ePBgnUtUJpWhF5FLRWSdiKwXkWtiwr1dRIyILLf2fdaNt05ELqlHocMojbpRO68oSgsYy4Y+ccKUiOSB64GLgF7gYRG51RizNhBuMvBx4A/WvpOAK4CTgaOA34jIccaY+AWaa8Cz89oZqyhKK7CXKb7ooos44ogj+PGPf8zAwABve9vb+NKXvsSBAwd4xzveQW9vLyMjI3zhC19g27ZtbN26lQsuuIBp06Zx77331r1saWbGngWsN8ZsABCRm4C3AGsD4b4M/D1gT+d6C3CTMWYAeEFE1rvpPTDaggcRHV6pZIQne/fy0MZdfPC8RcmBX2X8+OHNzJs+kXOOnhEf8I5r4OUn65v5kUvgsq9GHraXKf71r3/NzTffzEMPPYQxhssvv5x7772X7du3c9RRR/HLX/4ScNbAmTJlCl/72te4++67fYua1ZM0hn4OsNn63Qu8xg4gIqcD84wxt4nIpwNxHwzEnRPMQESuBK4EmDVrFj09PakKbzPs9sIODA764teS1nijr6/vVVFPmyzX+f2/OgDA0cObSvuyXN8owur8V+65+Y9LJ1WEnzJlSmlRsY6hQXIj9Z0lXxwaZCBi0TJwylssFtm/fz+33XYbd955J6eddlrp2JNPPsk555zDXXfdxSc+8QkuvfRSVqxYwf79+zHG0NfXR6FQiFwYzaa/v7+q9pDG0IdNOS3pZhHJAV8H3l9t3NIOY74HfA9g+fLlpru7O0Wx/AyPFOHXd9DW1k53dzf8ynli1pLWeKOnp+dVUU+bTNc5pO1mur4RhNY55r5++umnmTx5svPj8q81pEztMce6urrI5XJMnjyZtrY2Pve5z/GhD32oItyjjz7K7bffzpe//GUuvvhirr32WkSErq4u8vl8uQ4xdHZ2cvrpp6cud5rO2F5gnvV7LrDV+j0ZOAXoEZGNwNnArW6HbFLcuuF1xqrnRlGUVmAvU3zJJZdwww030NfXB8CWLVt45ZVX2Lp1KxMnTuQ973kPn/70p3n00Ucr4jaCNIr+YeBYEVkEbMHpXH23d9AYsxeY6f0WkR7g08aYVSJyCLhRRL6G0xl7LPBQ/YpfRn30iqK0EnuZ4ssuu4x3v/vdnHPOOYCj9n/wgx+wfv16PvOZz5DL5Whra+Pb3/42AFdeeSWXXXYZRxxxRGs6Y40xwyLyUeBOIA/cYIxZIyLXAauMMbfGxF0jIj/G6bgdBq5qxIgbAFFFryhKiwkuU3z11Vf7fh999NFccknlKPOPfexjfOxjH2uYqk+1Hr0x5nbg9sC+ayPCdgd+fwX4So3lq4qcqKJXFEUJkpmZseD46dXOK1nBqGpR6kSmDL2oolcyhK7bVD2vhodjLXXMmKFXRa/UB2MMG3ccaGqeI0XDpp3lPIuvAqNVTzo7O9m5c2emjb0xhp07d9LZ2VlVvMx8MxZcH32rC6Fkgu8/uIlrf76Gn35kBWfMn9aUPP/lN8/yjd+tL/1WQ18dc+fOpbe3l+3bt7e6KDXT39+faMQ7OzuZO3duVelmytALkumnudI8Htm0G4AXdx5smqF/YMNO329tytXR1tbGokXje9mInp6eqiZCpSVTrhtV9Eq98PzjzfwUcdAnr4peqRcZM/SiKkipC614MwzmqZ2xSr3IlKFHFb1SJ7x2lGuipA+23RG19EqdyJShV0Wv1AtPXTfT0AftuvY3KfUiY4ZeFb1SH4ruF2ya6aNX143SKDJl6EUVvVIniiVF3/w8o34rSq1kytCrolfqRbkdNdFHr6NulAaRKUMvIuw8ZLj46/fUPe3vP7CRT/54tW/fyvU7+ONv/d756ElG+Kdfr+Nv73i61cVoOZ6NbaaiD9r1Q4Mj/NE37+exF3c3rxCvcn6zdhvv+t6DmesfyZahB57YMcKz2/rqnvYXfr6Gnz66xbfv0z95nEdf3MPL+/rrnl+r+Obv1vPdeza0uhgtpzWdsX7j8kTvXp7cspe/+aU+eJvFld9fxQMbdmZuxFOmDH0zb0qAnCv3itkR9IqLZ3Sb2xnr/z3kvinmm9yuX8149j1bZj5zhr65+eU9Q5+x1zylVePo/e1oeMR9q8jUXTo+yNotnakmJM1W9G5+I1lrFUp5aGMLl0AYcl8V881WMErmxFvGDH1z8/Puv2LG/HnK2PDRDw17hj5Tt6nSAjLVgsLuyUb2nntKSxV99vAuaVO1Q4WP3tlRUEXfdFTRj2HC1Fcjr1fJdaOKPnN4/vJWrnUz6HbGNnuQgaI++jFNqKFvYH6eos9ao1BaswRCUEV6nbH5TN2l44Os3dKZakJh92QjX8FU0WcXr9008yFeYejdp01BffRNR103Y5hwH33j8supjz6zmNLf5l3bYDMquW7UR990snZLZ8rQh7tuGtgZq6Nusot7SZt5aYPGpeS6UTvffDJ2S2fK0Ddb0Xs++mE19Jmj7LpppqIPDK8c0eGVrUJdN2MYHXWj1IuSoW9qnv7fOryydWTtjs6UoQ+bGduMzlhV9NmjWHbSNzHPcEWvPvrmo4p+DBN2OzRjeOWIrmqWOVrSGRv4PVxy3TStCGOa5rrRmpZVU8hUEwpzZTaycXhKy+s0UzKE226a+QyvWL2y6HXGqqKH5hrfZj7gm0G2DH2o66aR+Tl/s+Kj19FDZVqxXG1QlAxrZ6yP5l6LJmbWBAqtLkA98cx8nhFyGIYoMDA8wsBwuhulDcNQzOom7QxhRoYZNE6YvBkGDP3DIzA8wIi0MZzQQtrMMDnBF7adEQQDhQ6GRoqR/kEpFmnLSyl/j+Gi8ZUripwIQvS4f+fNxFBghMHhYs2qRhBEnPxGisZJxxjaGWYk186IMRRyufKxGhgqGgaGR2LDFCgikmMoZRZ5DCI5ho1haKRIgWFGRkZC8xED7bkigyZPzgw79SGHMUUKFBmSQqKfVxDaGGaQPOBcxwLD5DAM0kb/kGPoi8aE1jcHtDEMCANuGs2mLZcrrbJpU8jlKBpTam8563vOIk6d8iLOMZwhpPZ1ctJ16uzlkSsOU2CYYQpQHMEYw6AR33UDaCsOkcsJRSmkuvbB/HMUGRgqVp5vUyQvEmsj0pyb0nEzgskVfDajUf19MtY+mbV8+XKzatWqmuK+/dsr2fniWu5ov4Z2hvno0Me4vXh2qrgfzP+SL7T9kDcM/APPmzkVx6/K/zefafsx+/NTOfPA1zlFXuDmjuv42ci5PFecy1+1/Yg7ZQUfOvTRyDzem7+T69r+E4Cf8zqu7v8Q5+TW8IP2vyWP0yD+dfiNfGX4PRVxcxR5qOMjdDLIsoHvMEB76dinCz/iw/lfcPbA9exgSmT+T3T8JXcVz+BTQx+JDPMPhe/wp4V7uWLw8zxYPCkyXBwbO9/Nj4a7eWehhw8OforfFpfxzbZv8Ef5B/mnkSv40dBreajzKv7H4Ce5q7i8pjySmMY+Hu68ipdys3ntwb9PFee+jqt5oXgk7x36LEtkA7/o+Dx3jiznQ0OfrAj7pcK/877CXVw39Odc2/Z9AG4rruBIdrA89yyfGv4ItwyfF5vfJwo/4erCz7hq8OP8sng25+TW8P22v6UgRf5l+G38+/ClrO78EB8fvIpbi+dWxP9m2zf5o/wDAFwz9JfcNPL6VPWsFx/L/5RPtd3Mwv4bffun0MfjnVdy9eBH+Hkx/hwA/KD9b5nPy5w/+C8AfLHwn3ygcCcL+28snaN3D36O77d/lREjbGcqc2Qnh3KTWHrweno6PskzxXl8YOivuTp/C59ouwWArfk5rDjwD4n539j+FY5iB92DX+ed+bv5u7Z/5Y8G/oYnzeJSmE4GeKTjwxykk7MGrsckOEOOli38tuMzvH3gWlaZEyqOnyAv8quOa1gpp/PuQ58p7V88JcfvPntZYpnDEJFHjDGhN1SmFP3n3nQiv/rJSjr3DwGwQF7hM5ccnyruxSu/BENwdMc+/vh1lTfM7N+9BMDkkT2cOsPwpslD8DKsyK1Bcm0AzBnZysUnzeK0eVND81j00E0MHGwjN3UOc3a/xBuXHMlxvSvJHypSJEeOIv+jcDvbzv4C0ya1++LmRvqZef8+AJbMEC5YXq7X+3rupCBFTpx8kLNXnBWa9/b9Axz26EH+JH8/j5zxVeZMnRAa7qy7nwFgvrzCay95W9wpi+YeeGehB4Ar8j2ccdG7Oe7ebWBgnnmJS6Zvg4PwrvzvWHrRn9WUxQsbNrBo8eLI473rHqXw8gjzir2cuXAa3ccfEZvexh0HmLdmO/Py23nD0Udw9sCz8BJckHuMS06exalz/dd06d3PA3BW7pnSvjfnVrLXTARgPi/z4dcdzeTO6FvsmLudT1MumbiLk849no4nH6Gwq8iwybFIXuZTy/KwBt5fuJP2Bd2++h4YGGbRypfYO2khXQde5MT27Xzm/HRtvV5cdc/NAJw+fyoXnjirtH/vcw/AVvhA4U5+Pngebzp1Nr984iVf3Dctmc0vn3T2nZd70pfOB+65E4DjpuW4+tDPAKc95imSF5jDTgAmFA8wJT/AbNnF7PwuLjzmCJZu2cHewS6mLDqDo164l9PmTuHik4+MrMOeg4OseHgNAMsWTOONO56EEZgjO7j04rLBlb6XmfTIAJMYYOlRXVy4ZF7suZn42H2wD97W/hAXdL+l4vjux9bBPlhhHuMNJxzBGQumOfu3vhCbbq1kytCfMX8ae2fnYb/3ewoXXXBMqrhbVxVgCLo68lwVEmfN2i7Y7mwvmDGRJYcfBi+DQegoCIyAYHj9CUdwxVnzQ/N4+Ol2+g+2037YPGT3y7zhhFmM7O+EQ1DMtZErDgDw3nMWMn/GRF/c4sBBuL+cv13GAz3O35ld7aFlB1j38n541Nn+02VzOX3+tNBwO1Y656GQk8i0Egl8m/2qC45hw/3lczRn2gQ4WD5WCz3SS3d3dNwfHXweXna2z5g/LTGf+5/bAc79TvcJR3DByJHwknN933DCLN5xZvnGNsbwxN3Odg7/q3mxpPQM71+xkCOndEbmeVeP83dKZ4F3XXAMG4YOh5UwRIGpE9q48Iy5pTK9+eh2X3139A2wbaVh38SFTDi4lYnted5X6/WqFfc6L58/1Xd+7xh4GraWg1168pEVhv7ik2eVDL3HaXPddNx0j5mah0POtkS4+Drbyi6r8487nCk729g3NJkp81fAC/eyZM5hsdd+084D8LCzvXTeVI6WrlK7sePt3tYOjzjbpySkCfC7FyfCPmjPh99HN26eBI5u43XHH857z1kIQE9Pb2y6tZK5Xh67QUQ1joiIsXFsr1xexHfivOFvQvySsjm8DiVBMIhAwZ3fbqwc8iFz3kXK5cpFlDHuYtrFSrPsbb2Hbnvld3z39U07DPscpfnymF2mQk787SgQ3U4v2F6kdIVN8sqXgTbn/S0ikde4XF5xowsGSek1bgwdBX/LC9Y7bMJX2DWJa5dRR9pz4gsjXq+Pm1bS8hH2mbOLGbyu9vVoq8JqRrU9e8hsM65d9gy972JVEc/9G9Uw7AufF+P7XbBu2Pib22CsGzMnQpu31LGUL0XojWFvS8TDKCZv+1CaGyrJ0FRLzmcAG9+07VOY5sFilymfE+xTHP/wjjL0ye2vdK4DBr9IDsTExs+JZdQQchFtohl0FvwlDZ6vsAlfYdckuM/X5iPaY1ve2i/OeTCmfPaTrn2UAKp8gJdJ92lHqUjfJu+/oVOkNzqyZ+hNjYq+FCdqv6WoBd+NVb7wJt4oiJuDlBW99+bpU/RhDcnYij680PmYm92nQlO0q5pVd9SIoXKApnxIw3+9qlf0tqUPG91YfiAWQ/ena3ueMfAreoPzoIl9cItQFg6tvZE7C/G5hwmXsGsSfCD4RVv4+Wy3LKZn3m1FHyWKQvMQKf0Ols6+3wspmm9SEFvRN+cNN3PUOiQwPr7/iV752wsTN+RZMBTxjLp/HZMkRW+XK8oAxLWX1K4br6HX2dBjKd1mz+hPk59tZBxFn+5BUfnmYxntlPUsXXlvxUwESaXoKb8htlDRd7QFDHTgeJhwCbsmtbS5DtsFUnrLKSv6fMJFsAVQvOumTKq1hyIeGB55X15jRNGLyKUisk5E1ovINSHHPywiT4rIahG5X0ROcvcvFJFD7v7VIvKdelcgiP3krcVHjwkf9+pz3RAw9Nard7xbxJSUu+A0Ms/fV52ij/LRR9fXLlea+Te1G+OoB2XZAHpGtZHN265iKh+97YrL5SqUXhRRr/iOqUkwMqX0vb9lH31S2825b4XlPp/WEVT0wdKEtec0Pnr7V/DNyaPdmj4gSPkeEy/NpPPoz9/u+YgKl/AC48aPJ+/LNzm90ZI46kZE8sD1wEVAL/CwiNxqjFlrBbvRGPMdN/zlwNeAS91jzxtjlta32DHl9W2nN/Rl50sUtqsmYBgsQx9vFAKdsUBbqTO23HraQhc3MRHbVvrJQh1I6cqo1Uef4LoRDLkkuVMHqnXd2EEKeSHoqqtM3w0rQUNfRWesl771tgOOj17sHWFxXENf9Fw3LfXRB9proNzhij5kX5xQiXTdBLIWfGez9s7YYDi7jy4+zYoChZDPJQapK2kU/VnAemPMBmPMIHAT4BsYaozZZ/2cRAtX+fSPuqkuZjB+5VGHnPgvjn/UTXIOL+w8WFL/3mtgcTQ++pAyVhyrUkE0TtGne6MYLbbhS1Vfa7uQxnUjXtjRdMb6DbyXp0mh6KXkunHCt9IH25HQGRu2Vk+azlj7BKYx9OVzUr5Bk4xoxZtb6Xd0Z2w1in6suG7SjKOfA2y2fvcCrwkGEpGrgE8C7YA942iRiDyGM2r088aY+0LiXglcCTBr1ix6enrSlr8C099f2t6/b2/qtBYPOPGGBgZC40w70Ffa3rn9Fbbs34w3323QzVMwPL12LV27ng3No7NvHwbh5X0DHCmwdu0aTtmxDfBPfb7v3nsqbpbCUB/eHMNdO3f4ynim+/dA377I+m4/WGSBu/3wQw/T2xXeWk9yp30XR4Zrug5SHOJ1gX09PT0cPeKkKxh27XQmvGCo+Vr39fXFxt28+cXS9saNL9DTsyU2vY17BvFeO9c89SQTD67Hm2K1ds0aJu5c5ws/3QDiTIvHd9N6GFauXMnk9uib2Lhx+w8dpKenh47NLzIX56E/MjTE44+vxpv+FqzvcNGwEENf30GKBgYj2m0j6Xb/PvP0Gtp3byzt37TJP+nnicdXV8R96qknK/Zt3rSRnp5tpXSHBgdLxyTCddPft7+0/ey6dRx/6CAFAxs2vMBiYGvvi/T07I6sw56BIm91t1/c+AL79+1z8zO+89l24CW8uclbNm+kp2dvZJoAu3btAmB4eCj0uryy7eXS9rp1z9BzwJmAl9SuayWNoQ9rqRWPV2PM9cD1IvJu4PPA+4CXgPnGmJ0isgz4bxE5OfAGgDHme8D3wFkCobu7u7paWDz40h9K21MOm8xrU6b1yqOdMAhtbW2E5f/8mm+WJvkcOesI5k/e69QOmDjBiSsYlpxyMt2nzA7NY+0zN1Dsk5JiO+Xkk5n9zCrYAblcAa8tv/6CCyojH9wFv3c2Z86c4SvjwR63vpMnh5YdYPOug/CQs3322a9h0cxJoeF2rczDILQX8pFpxTI8APf6d3V3d/PS/TkYds7REYfPhD2Ogqr1Wvf09MTGPdDfV5q0c/TRi2MnVwE8tXkHuPbojKVLOWbbFnDt1ZIlp9AdmF35pDthqpAT391gu27OPfdcpgdmOPvqcM/fgIFJEyfQ3d3N1oHHoddx3bS1FTht6dJSmbq6unz1HR4psqnHMGlSF9IvdHa213wua6bH+bPk5JPpXrKwtNuMHPRJwzOXL4M//N4X9bRTT4VHHvbtW7RoAd3dJ5XS7Wgvn7soRT9j6mRwtBInnHA8E3d2YvqFxUcfDS/Agnnz6e4+LbIK2/cPgLOKBIsXLeSwDYdBn2P07PNZ3LGhNLHqmEWLY9MEuLf3ftgDhUK4PenZta40AfPEE0+ke9lcZ39Cu66VNG98vYA933cuvnlvFdwEzkPSGDNgjNnpbj8CPA8cV1tR0zK64ZXRXie/jy6qLyDZR1/upnMmD7kdcJL+5Tsqhzg/bdNcN5E+envUTeNfVdOOmimF8fXBBH300fGD57ymcfSlvPydsXGv9F6ZvFFc9Z73UA3BET/BUqcdXhk3QiaV68Y9Y7ZDLKnvIuiCtfuS/OH8fXRpSee6aTxpivwwcKyILBKRduAK4FY7gIgca/18E/Ccu/9wtzMXEVkMHAtsqEfBo6jVV1l2zSWPaMmL/8L7OhoTR904DVHc/8udwAklTzHqJs6e+UbdpDJ8tZJiHH2uYmfdqfbBZt+8hbykjp+PGUef6B92z1VpwpTYPvqEznXx2lPrZ8YGuikqypK2MzZoQH3XIKJd+boHAufEySeq1JXlsIfExk2YqmrUTUT+vlE3TehgSXTdGGOGReSjwJ04IwtvMMasEZHrgFXGmFuBj4rIhcAQsBvHbQNwPnCdiAwDI8CHjTG7GlERq8SlrZqGV6aIkxN/w8tZE17iO2PtRmh8ij5+1LS/XDM9QkYAACAASURBVJEzY2OK7u90SsgqJo9EEhV9edRNI42TT5GnCO9f0kL8D9aQEyaRhsQadZNQw9I58dqPN47epOmMLYcpC4cWEVT0gWqHK/qQZGLeDKJ89H5Fjzvqxpp9HlPsYB6O8Y1om1Z7SKfovXTC24B/hM/Y6IzFGHM7cHtg37XW9tUR8W4BbhlNAavFN366ini24gw/bit6v1qze9hjFb3bCIteI7TWzEk09L4Zv+HEvaamVvTusforenvUTeMljH8cfYrw1rlry+UC7rjoeJWK3nIcJCp6/1/v3I2UB6DGkhPHn2/INX0Smk3FQybFEghhLs64FfUjXTe+YYrukFMjGK8dJ46jt+8L65pUxLOGU6dR9AnXo+Ard3J6oyXjM2OrUTnu2U5QpOC8aoUtnpb0uu6b4u55671sE692skJNHtrphYtzL3lh6qXoK33YwbVdGoHP95qiLraqyuf8M01DFb17PJh2Ta4bq/2AN44+3RuB3xXYIiJdN86BtIq+or8jhevGXmBMsM+JEzlRfVe46PzXooSt6NPMyyj9jXAF+96wG2/pM2foax1HnxRWAuPY/a4B23UTb0SN8dYmMSU/K6R4JKVYwyf2Zq/SZ90oRZ+zffQNfGUNXq8kfDMf89UsgRCl6FM8XCTw191fNvQJ8fG7KVpFnIGGCB99SuNfPhbuumkLKGOB0iQySHFf+x4mltAJBrRmzNfbR9+Ma5dBQ29v1+CjT6Ho8wEffXlRqviV7Wy14Sk+L3g9fPRxF9O/BEIKRVJr6xsrPvqERcmCxI66iYkfvXplCkNt/A+FsqJP7oz1wjvCQVrrujHBc+AvTNq1biqWQEghbtrz9n1h3WPe5z4TzoudZ16szthKJ31pK42hL6UTmW86IVEvsmfoa1zrpvSqlbAoF/h9eb64kuS6sYdXOuY+l1Z7pPDRx3WgpnXdlMPU6gqIMvTlv7lcwl1QB+yk00xZj1uPPrwz1jsW57pJcL24h8uDkMqGPrZn3crLGV7ZWtdNRbtLoehD17oJ1MH38I2onz3qxl6pxtPfyUsgWPnFDK+0779Uhj4Bn6JXH30NjHKZ4lSrV4pfs6Qdc10edeP+FstHX0W5Ig19TOyoVfqiqLlhJL4RpV8DZjRUO+rG98YWOEHVrF6Zs97ukl0v4W4e47lukh4UlEdxtVbR+38Hz3ch5JUodK2bGBUd1c8S/AiId05G3ODVLFNsJxW1KqlTljQ++vi3Vv+wzsaTqU8JQnDUTTWum5LvJvywz5iXzbXtH00/jl5KN3Jp1E1SUWMfYE6e8a4bK3RsQ3UbaM2tL7xsvmGH7uSwRmpQ/xtMck5+RV/+FhgRRrQ0TjumvVQ9jj7guvFqEeUEEvG3p9YRVPT+iRJp17qp6NiW6GMelT5655x4K4okPeSDo26ImrhYraJ3040aZGHXRztja2K0nbEpXTf22HlfZ2xMHmJ3nnlOHFM+GEu0oS8bjDjXTTpFHxwJUjWJq1eme6MYLRK4Xkn4FjXzdcbGK+uo5XPTjZrx/w3OjI0cAWLF8zr3W2noo2YHe4R9GjOMYCg7neAqoR7tFYvKuUOYPUNfhQvSv2RxnKJPTivpeviFV4rCjZLMGXp7YkXUJIvY+IlfSHKexv7OWOdvLsEoiCmWXDfixvPSSR5HX65LVOONM862UEnjo08zJDGUyPNXdP+W33oa2b5tA5zmoWWHr/TRV4Yv+egjDX36MpbOjSkb+lziK55TrzGxBEK8iz5U0Yc9BIPt2r8UeNSoG78yFoquoffeJuJKHuiMtdaQrTifJvmhE0ZU9nntjB0dErGdPl6KD49IMJ+Uit79W1b05W99VuO6CU45L6Vfx87Y2ptevOtLMNWt510j/iUMUhhN605wRt3Y8cMMVfybTzrXjZe+P03jfjM2CbvPp4Uu+hBLH+jjCPsUY0iBg5/os9tz1Of7fBOP8BQ9lo8+PF5YOcImQZapUtEnPmDi8qo/GTT0dqOrQeVEGdEK1419rPw3XWdseXhluTO2CtdN1BIIMbFTfzO29HZSIylcN5KTwN76Y7+ZJX1ODgKum8DM2LgJU9Gv6OkMtZO3P60iEjP6yx+/5KNv4YdHkhR9WsUaDOb/QHuUj97/Zu3dY2UffUJnrF1O7HYao+jjpvBWpBvlo7fCquumemqeMBVQVZVYNz4mkI+t6OMMPQRdN17oRCeTSTb0aTtj031xqVbDkazoy4t41ZhFCvxKLU1nrPVgyHm6sDKt0j4vXozrJm1nbNC4ON+MTSyy1Z5aO2EqeH6DCj78QVmZTrD92kEKEe2qcnila+jdfdW4bnL2OPqK/GxFn/5sRwX1jfBR1031+E9ZLYo+hY8+8CnBtEMHPQUG3sefJb2P3s4volr16IwNy68qEj8OHv8wrBd+10t14QtVuG7iZimn74wttx9wZ8amVfRun20rffQVy1wEyh7ex5Hsow+OdAujUKHoHUaK8fHsOOU8YnS4bwmE2CR9CUcF9Z0TVfTVE6a008XziFek4H/FA/ttIL3rxotX8stW4aOvRdFHNejKMnpp1VvRh5elUVQ7jt43UzGg6EN9zIk++ioUfeB6llwxCY1CMPTu6Weo2BRbEUlFx3GFrz1d6YIPBH+/WJSi97/Be/dYz7M7wopSgW9+ifVwjht1U53rJhydGTtKan5QJoyjt2+6tuCrva1WY85o6VXbUDL36ZdAKBP9zdgYRd8sn2DUG5G735mD0HjSqEGbSrdBgo++9De58z6SQH9IyXVjxH1rS07j0FDRcQW20kdf4VtP8TYS6rqJjpd2HD04y0I8scX5iF01Q3mdcfTer6CP3i5L+jSjyMe9PTSAzBn6uPHm6aInK/r2gt+Har+CVzthquyXTV+uyJs6pesmjcKqvfEluW7KZWlkA6/adVOhJuPjlx7uMe0lUU0GXR6Wj56Uit7u3G8VFfWo4XxDgqJP4aP3WpbrzXLSrOK8xC5qVqWPvmQTonz0vglTKQs4CjJo6C1SKAuPZNdNmfZ8uI/eVugRBcL23tpr5iQXNcZHH1CGYVTriqn/hCnL1dGUhm1Ct6OI63wLezCW6xOh6CX5gVox6sZ4OXujbpIMvWfUWtwZGyhnuvMd4qOv2JPCdRMx6ibtF6Z8+Yd8Na5cFMt1U8WiZlGN3feFKXXd1MLoFH20KLZcN3n/hyFs1038N2Ptcc/l1SuLJkVJU6zhEzthKmVbSnrgJZNsnBLugbrgX08+OXy1rpuwcMH9yYre/9c7dyXDnVLRA5hi9ZMD60WwnlX0VfqIc7FF++iDeRvfFammifnf0qMf/NV27odR6weSaiVzhj7N0qah8UpnO+qGsVw3ef/v9K4bb61sKZl7wTiv6sm9sVZZg6/8wTqE5J367Sa+kzE5eryit1f4bGgDt4qR7mPogXNqEm5sb4lhE91equ2MFUxpRqezL73rxlTx9lp/wl1Q1RIUSf5vCqRQ9G5Zalb01sM5dhx9FYY+KqiOuqkj9XwjspNyFH31rpvyIlSusvW9aiaQ5lOCMdHTdtYFx3ZXT7KPPvk2GD1SpQ80zm1Q2/DK9K4bO42SK8ak8dF7cYRiSw29nzSGPuzMxK8YmfwW6/R5eQMeanHdlAsWt5JmujTj1YyOuhk1VoOoxUefpjM2F3z18o6l6Yz1uiO9LffmrsJHHznqJuUSCPHZuGk06OPgzfLR+zvyUoSP+TB16DdPS0Z6FKNuvFNtxbHVaHpFDybyzaLxxLk5IuOk6oy1jkU+UO21rcpl8UJXs2aTvbRJvI8+vaRPo+jVdVMTzgUpmlpHIkQrUu+1ur2Qw1ZjduOI+3qTGKwb2V2mWAzJ3lwCBjRaRaaLH02pLjULxIiyeUZNmtOwfUaiJp9qOgUXN+omOc+gm8zfh1PNqJtWum4qRw+lixWkctiiX9F7959NcHHB0XfG2q6ziLJELTZlkeijtztjm7Cca+YMvb0CYFWnrzSTLcpQmdLadu3Wx8FtFeH46OMy8btuyqNuhKGRJEUW7aMv7Y81LtX56Gserhf5cXBTOh7pB60j/glTadR1tJ859C3NeCtOjkTknyZLz0dfzrPkuim1lIQ03PCm2LhzmUSwrrngNQ+LE3KCKt+q7GtgrLUlrTDWm4y9blT5ewHpsb+SEOejr25mbAqXUxVlrJXMGXqPIkJnW/pTmBSy1GkKdHXkSx0y7XkpTdoQDF0d0d9yac97jwUh5z6K2vIpzZ3V0A4NDIeXMU6Gp1R8XiOeMqHWb9LEP4SMKX+6ubFr3ZTLMW1SW4oYASNjna9JYdfURBgEl6hhlzZDI95DwkmjLVduH4V8cge99zZogGkT09SxMeQCbqO06/QEmR5ThwkFCTX0kzvKjjnBuRftR+TUienb8bRJbbTnnZv5xCMn+w8a/zLWSZQHSISH9fXFNsHSZ+4LU6WbplBg4YyJVceOvHHFYMgBI0x0BtIDjkEUt7FNbM8jndGNtasjz8lzpvLE5vLHn9tyOIvnhNtui3K5RiKG0sU/tdMZ+gltOeiH7uMOTxW+MpvwfPI5oOiZscarT/uZd8zhk5IjVKzP4vxuL+ToCDH0yT76FGV005gzpRNwxmebQp4V82bS2b+NpGvWUcjxzqXzmdi7kfz06tt6/QhX4p2FPOu/eFnqVI6f1RWaDsCsye20HSjAiP8NamK739nd1Z5nxTEzOeOEU+AOOHn2YQlFL+dx3BFdpam2F580KxiwtFWfZbb9nciNJrOGXiRX1VDwpNUrHTvlvRuW/acS3I4tmqEtnyv7YL20qvXR1+IXTuvDtZYqqCuljkffV3Prm4eF7+0mVd2Dr+puOlHpe+0sZnhlEhUuLOP020xoL0B/Ch+9MRw2oQ1yabqbG0fUDF+AQj5cfoQat0i3n3OeJeQzf/7h1E6cjkKejokdEWnG5Bk3nDPF/ecrV1LTTjGKrp5kznVTur/F/u5nFfGj9otl6H0vh8HtODwTX16PvpR4IsbaqsUIV+ejr2bEkj96/EPIGsHW0Abuf+hW76NPHvGSkH8VnbHltNyHvoibfbr25PTtjx0ffTUPubh49rNaMIR9z9Xvo3fdXb77Kc05TNpOOlZJchtvrqLPnKEvS7FcVY0/qYPQ+Wybe7rsMc7B7diiOY2wvASC0zCrHXUTGTou/yoVfS0Pyfh4tk+7Ca4b371eQ35Jajpp+dsUWfgNPJaRcgfdJtqoQPgWUcuom/L1iVPKdpsvhhv6ik5N62EZmmYwi4j8K4pS7Ruir1Cx+TbjG8rZNvRVNf6EXnIB//jm2hW9t+2ttpdyjIa1GeUuiOsAbK2itx8gTfHRV6nAKm/k0ZWxOkVvfHvxlGlqRZ/ccdtM0tU9/n5zsNR6hVL30gmMujFYDz9olaIvly8532asVJRBQ+9SZeNPmpZvj7qpl6IXwl41Y+KWfwTKliL7qhV9rSQpeuscN3LUje90palTwNCnGMMefzwNAYHgawvJZRgzij5qslnMSQi93yqGuNrbxdAEK/vF6qXoTbpwEZTdMREnwX5DV0VfPaULX7OPPjyOUA8fvZeD7aOvRdFHBYm19CnysMLV20dvDUcc/TILyfiNT5WKPoV7KdnQp1G1/r+VCn2cKPqIOQjVjDxyEwomXA5njJugP1X/zFhbONWi6OP216bo0+Srhr4m3BOYy1en6IPxA+QEy0ePpeLt7WoUvesIMim7Vn3tLMJFEzcNfgz56JsxykCqVGCRij6yczkh/1pcN8Y4AsUTKanakxW+RQTPRTWuOQme94hjJR99wE8vFcrYNfRi9afFkVrRR8SJoPRd5BT5NuObMRk09C6SpzZFH7Xf6oyteLqnNY5lBSb4G2ZV34yNyic2+9Yq+vIEo8pX/Ybg9wkkh49U9FGGfvSuG6k415ZqTavoPfXa0lE30S6XyDihhjC6Ds7oGsslU4oS8OMbEwhXjaJP93ZRb0WfS7GkwmjJoKG3XDc19I7HjaOfPKHdzSKg+Er3aTpFD+UvTHkNM1EFWWlHZzP2Ff0xR0yqYsnk2olTiuFUq+hrdQnYaQTS8hmplIreDt8i4pYu8PjhX76G2z/+WitOSGdsrKK3Hmo29lust7SzHa5aRR913eNG5ISQ2E9hpdEM3ZO5CVO1+uhDG54Pw4T2NuiHSsVXjaIHI5brphYffSCfUkp1aTD1VvT+unXm7evSOCdO1SlXreiT8k9j6ENUo0+hu+0lzlqMBUUfyFpCyn3uMTMDYfxhcWP48BnXNIreizMaRR913atU9EmdsT4fvSr6GqhR0SPW/2HJGr/fL2zUTWLRTKkBOC6M2kbdBBVxUv9CMH58PinSSpdARN7N/zh4KxR9Na6bmhW9l9MYU/Tp4oTsjB11k6zopWmKPrm+iUGsAMUmfB0sg4bepcrGH64wbGyDHKXoSbjCnnp3VK2n6NOZvhSKInZN8rTnot6KnoqbZMyPo0/1lpZk6Ktpe1ZeIYo+PHtP0LRe0VfmXUvdw+LZ4iZZ0edKD8cxoOhdou9sNfSjpFZF70aLTDaloo/L01PvAqXhlTUo+prUW0t99EFF7yrZRkp7X5ajUPQR1Nd1U4OiLx0bA4o+6EpMsWRy6ISpxFE3CYre2TE2FL2/ULH5NuNbApkz9DX76IOv0RVYhj5O0cfm6Sl6awmEapU2RCuocaPoG4//i0ujUfTBYw51dd2UkgpX9OF5jR1FH7WoWdw5SDPqxue6SeOjl7Gk6JPOQTmNkcRvUYyeVIZeRC4VkXUisl5Ergk5/mEReVJEVovI/SJyknXss268dSJyST0LH85oFX1EHJ+iL1pP/mLAkMWNfHHGApc/LFHel4hPucSUMUX8VPnU+mm6sHgBoxu1tG898Rn6NHUJhk+4pvWYMFVeIdE+566RMsXktuTm1PIJU0FSnG/PAPrW7Q+ua+9bAmEkXNEXR6wwxr2falX0gfs6LlwSRev6hOZbTmOkCZ+BTLQwIpIHrgcuA04C3mUbcpcbjTFLjDFLgb8HvubGPQm4AjgZuBT4lpteA6nN0CctU+yoLbfotv806EtN5bqxZsZ6CiSJVK+OaV710+bTINdNkxR9ta/aldcwSdHHU/uEKc9IpXTdCOXwLSJ09FByJPuPGy2pvikUPYFwyb2igTyi3mhrbE9pXDdjRNGfBaw3xmwwxgwCNwFvsQMYY/ZZPydRPitvAW4yxgwYY14A1rvpNYzRL1OcQtH7bsLgDZnedSOu66Z+nbFJeadhtK6bsH3+sjdjCYSq+zSC4RPi16NDuVR/23VTUujh+VaWaSwo+kDe1QismHbtX2s+hY/eEHhYhpQtSOR1j6tTcv1Kn4mMDlHaivqQUD1JM45+DrDZ+t0LvCYYSESuAj4JtAOvt+I+GIg7JyTulcCVALNmzaKnpydFscKZPTgAQN/Bg/QXt/NUyrRO37+fKTgXJiz/sw4dpJgbpgtY89RTTN2zhTmAKRY5dPAA3vd97r3nHor59tA8lu3bx2B/jmKxi1zO8OADD7DipZeYNOz/vFRY/lN3P8FSd3v/vn2+MCtcQTdD+iLPXUf/Ds6JSd/j/JERcsDWl7bybA3XYfK+dSwL7Lv33ns4390+eOAAmzZtZCEwPDJS87Xu64uuK0Bx82aOcbcffvhhDnRtTyj3c6Vy33/ffSzYvJl57u977unB5PxfDjs9hesmqW7HuKpk164drO3p4fitW5k+OMjul7cxtf8QG9aswXt1DtY3NzLI+cCGFzYybc8exIywehT3TS10u3+fXrOW9TutAxufZz4wUoy+vg+sfMDdKp/HR1atYv9he0vpDg4Nlo71HzwAZoDCyIjPaG3atJEF7vbjqx/jhP5D7N22jW08wWnAo48+wr7nD0bWoTC0j/Pc7VWrVrF4106mA5tf3MzzVtlnbn+KU9zt1Y89xp6N8Z+EG972MkuAQwcPhp6DRZs2lcq9c8NT9Ly0AUhu17WSxtCHjnit2GHM9cD1IvJu4PPA+6qI+z3gewDLly833d3dKYoVzgsbbwKgq+swuqbMIG1a5tnDYL9zg4bGebwT2rvgAJx88kmwYTtsdcTDxAkT4JAT7PzzXwttE8IzWdcFXTPJ7S6AgRUrzmH2wM0c2tsO5TYdnv8G4HFnc/LkLl+Y4fucvxctOx7Oiqjv3t7SIzf2nNwnMAJHHXkkR9VyHTZPgkf9u85/7WvBLePEiRNYMH8BbIZCoZD6+gTp6emJjfvswSdhq7N95vJlcOSS+AR7J5fKfd5558LISkeWAK87/3wodPiC77s7PrnIdmRn6aYxY/p0J+zen8CBTo6cPRsOPctJJ50ETzthurr815yhQ3AfLF68GDZsguHBms9lzfQ4f04++USOWlLOe9M9L8JGyOfzlWX61S8BOPfcFXD3b3wGYtmyM2DOslK6HYXyw3XChE46ikD/EFhfE1wwby686GwvPf00JmzuZMKRszlyyWnwBJxx+ukw/+zoOhzYCb93NpcvOwN2/wJ2w7x5c5lnl33NHljj5rP0NFh0fkVSNk9tvx+2w4SJE3ld2HUZ7imV+9ILzoNO55OHSe26VtK4bnqhJG4A5lK6hUK5CXhrjXHrR7Wvs57PMHLyh/dKyOh99C45d1/1Hx6p4TW9ZT76sPPjvKo2cjy9vzO2/j76pPNTzaibcluiBh+9Fb5FVE7gc90WMUUKnbdSKQGtPLyO6mCQwFo3Y8RH7y1VmG7gROOvXRpD/zBwrIgsEpF2nM7VW+0AInKs9fNNwHPu9q3AFSLSISKLgGOBh0Zf7GhqHl6Z5FPzjY4xVgMzBEeVROM0QmOP3sGkdFanaGh19dGnDJ6mDFEjGxrJqHz0JF7Tim+KVnkcQjpjS0bKK8/48NFXGLMUZQlfciT8geEcKlodz/j3l9KkBh994Drb93VcuCSq8NE349olum6MMcMi8lHgTiAP3GCMWSMi1wGrjDG3Ah8VkQuBIWA3jtsGN9yPgbXAMHCVMWYkNKO6YSmdqk5ggpI1EDphyvsdth2ahlhiw0unXhOmUijA1PnUS9EH9xlL7TSQ0Y66SYifOLwyxbIAJVVbOuW2kRpHij6Qd5oJQBL460aMDm+NWAtk5g9TraL3XWfrd8WDv8r25Ls+Cfk24dqlWtTMGHM7cHtg37XW9tUxcb8CfKXWAlaPpXSqOYGlJ3CMEfWNd4+6UCkUvdu8nanPKQ19Laq02vh2uJpH3SQp+gQDVidMtTdSRfj4+PUcXukXGbZCHx+KPtLlkqJZp1b0pW/GRiv6XEnR25knnZda7+Mkxpaiz9zMWIdaGn/ChbGHVxoTaBNpFb2jSrzp30XXjWFSLYEQkV9koJC809AMRd9sQ98CRZ+G0CUQ7HHx41TRpylKmk8J2gmlW4/ei1OrorfO+SgVfWIbb/KDOXOGvvwR4UYq+oDaqspHT8mwO2uC1KLoI/IYF4re+t28xW5SBK9W0cenWdWnBH0P13Go6CvKmabuaXz09qEU4+i9JRBG9XHwKKFTW3tK1cRV0ddC8GapJl5CL3mkjz7lCI+wRliDjz72YZQifjoar+gbauaDD5fkGHbkFIo+npoXNcuAjz6dpA8JGzF6pxwuXtGXDXWjFX18kqkCjcFRN+OPmhS982dKZ1S3Rb0UvTB7qjO9qrPgjAwyTRl1kyaL6l5PU5chkG4zvjA1ucNeaaP+ij4pzXQPsaBRGZ+KPmh7J7U598mEtujVTtJ9StASN2kUvfdwHEOKPlW+Y2HUzfhjdIr+7csqJu66h41fJYxC0V+2ZDbcDYd3tVuKPr0CaJiir4vKSG7gKT+HPirmTbMmrTXAR9+el9gvN1bjuhn3ij5QzpldzszwOdMqJw4+8NnXMzxSnjkSu0yxrzkm++ibp+jTtyeJeuSPxVE344nR+ugdlR0aIKWij80EENrywXTSlHW0ir4GY1cLVYy6adrwyjHrox+Noi+n0mpFX1FOtyxhd9LsKY7x398/BMT76G1BkEbRm6Iq+iiy6boZhaKPNaL19tEbu2EmFS9NQxurij7iZmqspbc266/ok9JMU7XQiUbjUNHHG8VwyhOm7Ggx6XhvvnHj6MeQoi/1Q0U1BPXRj5bgEz1ttKgnuZ1ufXz0wU8Sjp3VK5uj6JsxvLK+ij40QuzRqlw3dfHRJ2bXMCpab4rrG+q6CVTCn24KRe8TTi1W9PV4Q68j2TT0TVf0KS9alKKvctRNdBsaJ4q+Ga6bFiv6VKo2aFTGqaKvZdRN6PcfYhV9Ch996eFoK/qEgjTKR1/Nm4Qq+uoRw6h89DEBGqboUw62Tc5jnCj6mr9eVXM5Rqvokx5elVTluglV9El5WMdaPeomzihGxfHG0ft9N4Ew5d+pfPTew3EMKfpUAydU0ddCKxT96Hz0qUqZIR99c0zSaBU9/t9V0txRN1YaraBiXZ8a7jtIUd9aFH0VyroBin48rV45zjC1Nf5R++jT5Bmm6KFCpUTG9UKPZUUfts+qp2nOOPqGKvqE8heNpDL0leIiKFLSXM8xMOqmFkUf5rqJUfRpZsaWHtBVKXpfYlb4ein6+OPOZuOvXXaGVx7aAzd/gMO3P0mp8W9bC99/W7r4+7Y4f5/+BWx/pvL4wP5y63zgW3Bod/nY8IDzEDAjcPNfVHykosT+l/2N8Ed/Dq88DW0zGLIvRViZ+14pbb6p7xb4/uOl34WRfmdj9Q9h0+/D8x7oi08ffB9a5sUH0p87m4M7fT/Pya2FWz7o/JAc9O9h9vPOx2FOGHiitjyAU3ftgs3TowPs3lTe/vXnYcK0+ATtcv/sw7DrhfLvn3wACtZXw5IMPcJC2ZZYt4k4X0PjlaedsC8/CZMOBwSGDsAfvgvAGbn17Hr8i/76DrtfqvHa054Xaz6Xo2XS7/8Onvz38o697r209dHIMrUZw//ftoNOsb6485v/F1Z+s/Tz8t3/UT423E+oO3bjfaXN+T1XvxOn3wAADTJJREFUw2CfE86zsL/7G/jDd6ILP2h9fequL8LO553t9b/1l92rE0DP38GqG6LTBBa/tA6A4/f9PvwcbF9X3v7pldDWCcAx/ROhAR8eyY6hx8DAfgY6ptN5QjcccYLzFZ6B/emizzrZMQ6TjwyPc9QZsPTPnBtr/8vOF2HmnukY/OIwnPBGeO4uGBl0/oVx5BI4/jKYvhjmr3Aa7/RFTDj2Mn7/7CSWbvlrmLYoPP+2CeyZfR5P9O7lyLYhX5i9hx3PlJFdMHFGcn0nz44PM/8cmDAdDryS/tzZuJ9RXF88imNyW3nOzOX0kUFYcC4cexE8czsTTBH2vwBHnFRbHkB+JOHaTpwO0xY6D9/BA8n55Nth6nzomOJcz6nzYM4Z0L8XRgacfzbzzoZJM6FvG0w6whEHE6ZCexdfe3YWF+Yf5YyEPFebY9henMJlh+OUb9pCOO5SJ98tq0pqdXVxMYvC6rvgXKcc7V2w/6Waz2WtPFucw3G5LY6wsfN2v5bEUadHlkmMoUucz7Lt6DqOCcUDTMq3w8B+dnfMYdrAForkSu2oOGcZ+RPf7Bjm1T90hN38s2FgH9sOCTuGJ7CwOARzl8OxF8KMY+GYC53rl3ReZp3ihMm3OXZj9yaYMreyTke/3nnID/Ylpjlx2mw4tIWJM+eHhz3sKMceDPQ5bWvAmVeQH2mMk0WaMtStCpYvX25WrVpVc/xGfYprLPDghp1c8b0HOWvRdH78oXNK+8danRde80vf741ffVPd8xhrdbbx6p9U7zThvDD/cemkMVdfr2yPfP5CZnRFvMVGMDhc5LjP3wFU1v+rdzzDd+55nrcf18bNzzoG8JkvX0pnxJIKb7n+9zy+eQ8/+8gKTp+f8OY2xhlNuxaRR4wxy8OOZdBH/ypgbD2blVc5kmrUWDBO/cPrbRGNGvpxRGPHnStKbTSjXUauGdOk/Mc7aujHEZ5yatYARUVpFHHGOWzQXC4mQurvgL+KUUM/jvAadFEbtDKGqOX7MdW6e3Ix4UvPBbX0kaihH0foK6oyFolzq0THqTJ8rKLXOyMJNfTjEFUuypiiJkVfbfjkCHpXRKOGfhyRdp0mRWkmzXDdxKbl/lX9E40a+nHEUVOdjzZcdNKsFpckPYtnTmp1EcYsxx7RlSqc98WmsUq9HSdnLnTGwi+emufNp85ODO/dD0dN7axzSbJDhmbGZp/ZUyaw+tqLmDKhrdVFScWaL11CIa/+0yhu+/h5DI/Ey9C1111CToQHf39fbLgs8foTZvHYFy7i8YdXcuVrl/K//3hJbPgrz1/MO8+cx9SJY/uB2ErU0I8zxlNjntShzSuOjkKepFM0sX3sn8NGdIZOm+S080I+x2H5eMeDiIyr+6IVqOtGUZRRoe9sYx819IqijAod3Tj2UUOvKMqoqGUcvdJc1NArijIqVNGPfdTQK4qiZBw19IqiKBlHDb2iKKNiNK6bfNyylErdGPuDdBVlnPGTD59DX/9wq4vRNGrtjP3HPz2N0+dPrXNplDDU0CtKnTlzYcxHyzNIrYr+7cvm1rcgSiTqulEURck4augVRRkV6mUf+6ihVxRlVOiHP8Y+augVRRkVaubHPqkMvYhcKiLrRGS9iFwTcvyTIrJWRJ4Qkd+KyALr2IiIrHb/3VrPwiuK0npU0I99EkfdiEgeuB64COgFHhaRW40xa61gjwHLjTEHReT/Af4eeKd77JAxZmmdy60oyhhBXTdjnzSK/ixgvTFmgzFmELgJeIsdwBhztzHmoPvzQUDHTSmKoowR0oyjnwNstn73Aq+JCf9B4A7rd6eIrAKGga8aY/47GEFErgSuBJg1axY9PT0pihVOX1/fqOKPR8ZqnRtZprFa50YxFuv79mPbuPm5oYaVayzWudE0rM7GmNh/wJ8C/2b9/nPgmxFh34Oj6DusfUe5fxcDG4Gj4/JbtmyZGQ133333qOKPR8ZanRf89W1mwV/f1tA8xlqdG82rrb7GaJ2rBVhlIuxqGtdNLzDP+j0X2BoMJCIXAv8LuNwYM2A9SLa6fzcAPcDpqZ9CiqIoyqhJY+gfBo4VkUUi0g5cAfhGz4jI6cB3cYz8K9b+aSLS4W7PBM4F7E5cRVEUpcEk+uiNMcMi8lHgTiAP3GCMWSMi1+G8KtwK/APQBfzE7YF/0RhzOXAi8F0RKeI8VL5q/KN1FEVRlAaTalEzY8ztwO2Bfdda2xdGxFsJLBlNARVFUZTRoTNjFUVRMo4aekVRlIyjhl5RFCXjqKFXFEXJOGroFUVRMo4aekVRlIyjhl5RFCXjqKFXFEXJOGroFUVRMo4aekVRlIyjhl5RFCXjqKFXFEXJOGroFUVRMo4aekVRlIyjhl5RFCXjqKFXFEXJOGroFUVRMo4aekVRlIyjhl5RFCXjqKFXFEXJOGroFUVRMo4aekVRlIyjhl5RFCXjqKFXFEXJOGroFUVRMo4aekVRlIyjhl5RFCXjqKFXFEXJOGroFUVRMo4aekVRlIyjhl5RFCXjqKFXFEXJOIVWF0DJHj/44GvYeWCg1cVQFMVFDb1Sd847dmari6AoioW6bhRFUTKOGnpFUZSMo4ZeURQl46ihVxRFyTipDL2IXCoi60RkvYhcE3L8kyKyVkSeEJHfisgC69j7ROQ599/76ll4RVEUJZlEQy8ieeB64DLgJOBdInJSINhjwHJjzKnAzcDfu3GnA18EXgOcBXxRRKbVr/iKoihKEmkU/VnAemPMBmPMIHAT8BY7gDHmbmPMQffng8Bcd/sS4C5jzC5jzG7gLuDS+hRdURRFSUOacfRzgM3W714chR7FB4E7YuLOCUYQkSuBKwFmzZpFT09PimKF09fXN6r44xGtc/Z5tdUXtM71JI2hl5B9JjSgyHuA5cDrqolrjPke8D03je0XXHDBphTlimImsGMU8ccjWufs82qrL2idq2VB1IE0hr4XmGf9ngtsDQYSkQuB/wW8zhgzYMXtDsTticvMGHN4ijJFIiKrjDHLR5PGeEPrnH1ebfUFrXM9SeOjfxg4VkQWiUg7cAVwa6BwpwPfBS43xrxiHboTuFhEprmdsBe7+xRFUZQmkajojTHDIvJRHAOdB24wxqwRkeuAVcaYW4F/ALqAn4gIwIvGmMuNMbtE5Ms4DwuA64wxuxpSE0VRFCWUVIuaGWNuB24P7LvW2r4wJu4NwA21FrAGvtfEvMYKWufs82qrL2id64YYE9qvqiiKomQEXQJBURQl46ihVxRFyTiZMfRJ6/GMV0RknojcLSJPi8gaEbna3T9dRO5y1xC6y1taQhy+4Z6HJ0TkjNbWoHZEJC8ij4nIbe7vRSLyB7fOP3JHgSEiHe7v9e7xha0sd62IyFQRuVlEnnGv9zlZv84i8gm3XT8lIv8lIp1Zu84icoOIvCIiT1n7qr6uo1k3LBOGPuV6POOVYeBTxpgTgbOBq9y6XQP81hhzLPBb9zc45+BY99+VwLebX+S6cTXwtPX774Cvu3XejTMLG/fvbmPMMcDX3XDjkX8BfmWMOQE4Dafumb3OIjIH+DjOOlmn4Izqu4LsXef/oHLpl6qu66jXDTPGjPt/wDnAndbvzwKfbXW5GlTXnwMXAeuA2e6+2cA6d/u7wLus8KVw4+kfzuS63wKvB27DmWW9AygErznO0N9z3O2CG05aXYcq63sY8EKw3Fm+zpSXSJnuXrfbcNbHytx1BhYCT9V6XYF3Ad+19vvCJf3LhKIn5Zo64x33VfV04A/ALGPMSwDu3yPcYFk5F/8M/BVQdH/PAPYYY4bd33a9SnV2j+91w48nFgPbgX933VX/JiKTyPB1NsZsAf4ReBF4Cee6PUK2r7NHtdd1VNc7K4Y+9Xo84xUR6QJuAf6nMWZfXNCQfePqXIjIm4FXjDGP2LtDgpoUx8YLBeAM4NvGmNOBA5Rf58MY93V2XQ9vARYBRwGTcFwXQbJ0nZOIquOo6p4VQ59qPZ7xioi04Rj5Hxpjfuru3iYis93jswFv6YksnItzgctFZCPOstivx1H4U0XEm+Rn16tUZ/f4FGC8zcDuBXqNMX9wf9+MY/izfJ0vBF4wxmw3xgwBPwVWkO3r7FHtdR3V9c6KoU9cj2e8Is6aEv8HeNoY8zXr0K2A1/P+Phzfvbf/vW7v/dnAXu8VcbxgjPmsMWauMWYhzrX8nTHmz4C7gbe7wYJ19s7F293w40rpGWNeBjaLyPHurjcAa8nwdcZx2ZwtIhPddu7VObPX2aLa6zq6dcNa3UlRx86ONwLPAs8D/6vV5aljvc7DeUV7Aljt/nsjjm/yt8Bz7t/pbnjBGYH0PPAkzoiGltdjFPXvBm5ztxcDDwHrgZ8AHe7+Tvf3evf44laXu8a6LgVWudf6v4FpWb/OwJeAZ4CngO8DHVm7zsB/4fRBDOEo8w/Wcl2Bv3Drvh74QDVl0CUQFEVRMk5WXDeKoihKBGroFUVRMo4aekVRlIyjhl5RFCXjqKFXFEXJOGroFUVRMo4aekVRlIzzfwEL96hbqS+xuAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title('Accuracy')\n",
    "plt.plot(history.history['accuracy'], label='train')\n",
    "plt.plot(history.history['val_accuracy'], label='test')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.33647555, 0.30768162, 0.3558429 ],\n",
       "       [0.33647555, 0.30768162, 0.3558429 ],\n",
       "       [0.33647555, 0.30768162, 0.3558429 ],\n",
       "       [0.33647555, 0.30768162, 0.3558429 ],\n",
       "       [0.33647555, 0.30768162, 0.3558429 ]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = model.predict(val_input)\n",
    "preds[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_outputs[:5]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
